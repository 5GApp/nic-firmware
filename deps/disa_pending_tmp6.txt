# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498063017 -7200
# Node ID 05bf790c06610e8685f120875c8c23434ef449b6
# Parent  1b8f7ef80f642251e155d40ec51efffb91e0d90e
[cfg] Fix nfd_flr QC control queue init for NFD_MAX_PFS > 1
* The code in nfd_flr_init_cfg_queue() was technically buggy and would not
  have handled PF FLRs correctly if NFD_MAX_PFS > 1.  PF FLRs are fairly
  uncommon however, so this bug was probably not impacting any projects.

diff --git a/me/blocks/vnic/shared/nfd_flr.c b/me/blocks/vnic/shared/nfd_flr.c
--- a/me/blocks/vnic/shared/nfd_flr.c
+++ b/me/blocks/vnic/shared/nfd_flr.c
@@ -147,9 +147,9 @@ nfd_flr_init_cfg_queue(unsigned int pcie
     nfd_cfg_queue.event_data = NFD_EVENT_DATA;
     nfd_cfg_queue.event_type = event_type;
     nfd_cfg_queue.ptr        = 0;
 
-    qc_init_queue(pcie_isl, NFD_CFG_QUEUE + (4 * NFD_MAX_VF_QUEUES * vnic),
+    qc_init_queue(pcie_isl, NFD_NATQ2QC(NFD_BUILD_NATQ(vnic, 0), NFD_CFG_QUEUE),
                   &nfd_cfg_queue);
 }
 
 
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498063018 -7200
# Node ID 2bdc56ae2cb907d3c81337368f9114aac4ab43d3
# Parent  05bf790c06610e8685f120875c8c23434ef449b6
[cfg] Fix NFP_NET_CFG_BPF settings, ensuring it is only populated for the PFs
* Previously it would have been populated for VFs and PF0 only
* Not required for VFs
* May be used from PFs other than 0
* Currently BPF capable projects are only using one PF, so these "bugs" aren't
  encountered

diff --git a/me/blocks/vnic/shared/nfd_cfg_internal.c b/me/blocks/vnic/shared/nfd_cfg_internal.c
--- a/me/blocks/vnic/shared/nfd_cfg_internal.c
+++ b/me/blocks/vnic/shared/nfd_cfg_internal.c
@@ -451,14 +451,8 @@ static void
                                    NFD_NATQ2QC(q_base, NFD_OUT_FL_QUEUE)};
     __xwrite unsigned int exn_lsc = 0xffffffff;
     __xwrite unsigned int cfg2[] = {NFD_OUT_RX_OFFSET,
                                     NFD_RSS_HASH_FUNC};
-#ifdef NFD_BPF_CAPABLE
-    __xwrite unsigned int bpf_cfg[] =
-        { NFP_NET_BPF_ABI | (8 * 1024 - NFD_BPF_START_OFF) << 16,
-          NFD_BPF_START_OFF | NFD_BPF_DONE_OFF << 16,
-          30 << 8 /* CTM buf size / 64 */ };
-#endif
 
     mem_write64(&cfg, NFD_CFG_BAR_ISL(PCIE_ISL, vnic) + NFP_NET_CFG_VERSION,
                 sizeof cfg);
 
@@ -467,14 +461,8 @@ static void
 
     mem_write8(&cfg2,
                NFD_CFG_BAR_ISL(PCIE_ISL, vnic) + NFP_NET_CFG_RX_OFFSET,
                sizeof cfg2);
-
-#ifdef NFD_BPF_CAPABLE
-    mem_write8(&bpf_cfg,
-        NFD_CFG_BAR_ISL(PCIE_ISL, NFD_MAX_VFS) + NFP_NET_CFG_BPF_ABI,
-        sizeof bpf_cfg);
-#endif
 #endif
 }
 
 
@@ -512,9 +500,9 @@ static void
                sizeof cfg2);
 
 #ifdef NFD_BPF_CAPABLE
     mem_write8(&bpf_cfg,
-               NFD_CFG_BAR_ISL(PCIE_ISL, NFD_MAX_VFS) + NFP_NET_CFG_BPF_ABI,
+               NFD_CFG_BAR_ISL(PCIE_ISL, vnic) + NFP_NET_CFG_BPF_ABI,
                sizeof bpf_cfg);
 #endif
 #endif
 }
diff --git a/me/blocks/vnic/shared/nfd_flr.c b/me/blocks/vnic/shared/nfd_flr.c
--- a/me/blocks/vnic/shared/nfd_flr.c
+++ b/me/blocks/vnic/shared/nfd_flr.c
@@ -193,9 +193,9 @@ nfd_flr_init_pf_ctrl_bar(__emem char *is
                NFD_CFG_BAR(isl_base, vnic) + NFP_NET_CFG_RX_OFFSET,
                sizeof cfg2);
 #ifdef NFD_BPF_CAPABLE
     mem_write8(&bpf_cfg,
-               NFD_CFG_BAR_ISL(PCIE_ISL, NFD_MAX_VFS) + NFP_NET_CFG_BPF_ABI,
+               NFD_CFG_BAR(isl_base, vnic) + NFP_NET_CFG_BPF_ABI,
                sizeof bpf_cfg);
 #endif
 #endif
 }
@@ -229,14 +229,8 @@ nfd_flr_init_vf_ctrl_bar(__emem char *is
     __xwrite unsigned int cfg2[] = {NFD_OUT_RX_OFFSET,
                                     NFD_RSS_HASH_FUNC};
     __xread unsigned int vf_cfg_rd[2];
     __xwrite unsigned int vf_cfg_wr[2];
-#ifdef NFD_BPF_CAPABLE
-    __xwrite unsigned int bpf_cfg[] = { NFP_NET_BPF_ABI | (8 * 1024 - NFD_BPF_START_OFF) << 16,
-                                        NFD_BPF_START_OFF | NFD_BPF_DONE_OFF << 16,
-                                        30 << 8 /* CTM buf size / 64 */ };
-#endif
-
 
     mem_write64(&cfg, NFD_CFG_BAR(isl_base, vf) + NFP_NET_CFG_VERSION,
                 sizeof cfg);
 
@@ -251,13 +245,8 @@ nfd_flr_init_vf_ctrl_bar(__emem char *is
     reg_cp(vf_cfg_wr, vf_cfg_rd, sizeof vf_cfg_rd);
     mem_write8(&vf_cfg_wr, NFD_CFG_BAR(isl_base, vf) + NFP_NET_CFG_MACADDR,
               NFD_VF_CFG_MAC_SZ);
 
-#ifdef NFD_BPF_CAPABLE
-    mem_write8(&bpf_cfg,
-               NFD_CFG_BAR_ISL(PCIE_ISL, NFD_MAX_VFS) + NFP_NET_CFG_BPF_ABI,
-               sizeof bpf_cfg);
-#endif
 #endif
 }
 
 
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498063019 -7200
# Node ID b169cd1f197ef44cd49eaac929d649d011ba9e6a
# Parent  2bdc56ae2cb907d3c81337368f9114aac4ab43d3
[PCI.IN] Fix issues in nfd_in_pkt_meta()
* Typo BL_L fixed
* bitfield_insert() doesn't handle constant "before" values, so just
  use an ALU op

diff --git a/me/blocks/vnic/nfd_in.uc b/me/blocks/vnic/nfd_in.uc
--- a/me/blocks/vnic/nfd_in.uc
+++ b/me/blocks/vnic/nfd_in.uc
@@ -339,15 +339,15 @@
 
     bitfield_extract(len, BF_AML(in_nfd_meta, NFD_IN_DATALEN_fld))
 
 #if (NFD_IN_BLM_REG_BLS == NFD_IN_BLM_JUMBO_BLS)
-    bitfield_insert(v, 0, NFD_IN_BLM_REG_BLS, BF_ML(PKT_META_BUFLIST_bf))
+    alu[v, --, b, NFD_IN_BLM_REG_BLS, <<(BF_L(PKT_META_BUFLIST_bf))]
 #else
    move(bls, NFD_IN_BLM_JUMBO_BLS)
-   .if (BIT(BF_A(in_nfd_meta, NFD_IN_JUMBO_fld), BL_L(in_nfd_meta, NFD_IN_JUMBO_fld)) == 0)
+   .if (BIT(BF_AL(in_nfd_meta, NFD_IN_JUMBO_fld)) == 0)
        move(bls, NFD_IN_BLM_REG_BLS)
    .endif
-    bitfield_insert(v, 0, bls, BF_ML(PKT_META_BUFLIST_bf))
+    alu[v, --, b, bls, <<(BF_L(PKT_META_BUFLIST_bf))]
 #endif
 
     bitfield_extract(off, BF_AML(in_nfd_meta, NFD_IN_OFFSET_fld))
     alu[len, len, -, off]
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498063020 -7200
# Node ID 728db586e345fba5f89a7c9eac54c27d12aa6ee5
# Parent  b169cd1f197ef44cd49eaac929d649d011ba9e6a
[nfd] Fix typo in nfd_build_pf_q()

diff --git a/me/blocks/vnic/nfd_common.uc b/me/blocks/vnic/nfd_common.uc
--- a/me/blocks/vnic/nfd_common.uc
+++ b/me/blocks/vnic/nfd_common.uc
@@ -134,9 +134,9 @@
 .begin
     #if (isnum(in_pf) && isnum(in_pfq))
         move(out_q, (_NFD_TOTAL_VFQS + in_pfq))
     #else
-        alu[out_q, _NFD_TOTAL_VQFS, +, in_pfq]
+        alu[out_q, _NFD_TOTAL_VFQS, +, in_pfq]
     #endif
 .end
 #endm
 
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498063020 -7200
# Node ID 5d5090d7cf3d8a882d346eeef8c1b6469a977757
# Parent  728db586e345fba5f89a7c9eac54c27d12aa6ee5
[PCI.IN] Fix LSO data_len info for the case when "offset" is non-zero
* lso_hdr_len already accounts for "offset" (meta len) so don't add it a
  second time

diff --git a/me/blocks/vnic/pci_in/issue_dma.c b/me/blocks/vnic/pci_in/issue_dma.c
--- a/me/blocks/vnic/pci_in/issue_dma.c
+++ b/me/blocks/vnic/pci_in/issue_dma.c
@@ -1252,9 +1252,9 @@ do {                                    
             issued_tmp.buf_addr = curr_buf;                                  \
             issued_tmp.__raw[2] = tx_desc.pkt##_pkt##.__raw[2];              \
             issued_tmp.l4_offset = lso_seq_cnt;                              \
             issued_tmp.__raw[3] = tx_desc.pkt##_pkt##.__raw[3];              \
-            issued_tmp.data_len = (offset + lso_hdr_len + lso_payload_len);  \
+            issued_tmp.data_len = (lso_hdr_len + lso_payload_len);           \
             /* if last of LSO segment set lso end flag and we have no */     \
             /* more dma data */                                              \
             if ((lso_dma_index == dma_len) && tx_desc.pkt##_pkt##.eop) {     \
                 issued_tmp.lso_end = 1;                                      \
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498063020 -7200
# Node ID e30ef99023cd4d7ae8b05bfa3dbeb51d70fcbbbe
# Parent  5d5090d7cf3d8a882d346eeef8c1b6469a977757
[cfg] Remove the one remaining case of USE_SVC_ME, making it default
* USE_SVC_ME was a valid option around the time MSIX interrupts were
  getting introduced.  Now use of the service ME it is essentially a
  requirement, but the USE_SVC_ME has not be cleaned up.  Fix that.

diff --git a/me/apps/loopback/Makefile.netro b/me/apps/loopback/Makefile.netro
--- a/me/apps/loopback/Makefile.netro
+++ b/me/apps/loopback/Makefile.netro
@@ -103,9 +103,8 @@ ng-nfd_loopback_NFCCFLAGS_common +=  $(n
 				-Qnctx_mode=8 \
 				-Ob2 \
 				-Qspill=7 \
 				-mIPOPT_expose_intrinsics \
-				-DUSE_SVC_ME \
 				-Zi
 
 
 ng-nfd_loopback_NFCCFLAGS_common += \
diff --git a/me/blocks/vnic/shared/nfd_cfg.h b/me/blocks/vnic/shared/nfd_cfg.h
--- a/me/blocks/vnic/shared/nfd_cfg.h
+++ b/me/blocks/vnic/shared/nfd_cfg.h
@@ -284,15 +284,11 @@ struct nfd_cfg_msg {
  * @param _msg              message struct to fill
  * @param _sig              signal to check for messages
  * @param _pci              PCIe island
  */
-#ifdef USE_SVC_ME
 #define nfd_cfg_master_chk_cfg_msg(_msg, _sig, _pci)                    \
     nfd_cfg_check_cfg_msg((_msg), (_sig), NFD_CFG_RING_NUM(_pci, 5))
-#else
-#define nfd_cfg_master_chk_cfg_msg(_msg, _sig, _pci)                    \
-    nfd_cfg_check_cfg_msg((_msg), (_sig), NFD_CFG_RING_NUM(_pci, 4))
-#endif
+
 
 /**
  * Notify the host that a cfg_msg has been processed
  * @param pcie_isl      PCIe island that the message relates to
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498063021 -7200
# Node ID f5e9169a7df4d5663550f516249d5cc7dfd3ddd6
# Parent  e30ef99023cd4d7ae8b05bfa3dbeb51d70fcbbbe
[svc] Restructure MSIX code to provide a header file
* rename svc_cfg_bar[] to more generic msix_cfg_bar[]
* fix inconsistency in the pcie_isl parameter for msix
  functions

diff --git a/me/blocks/vnic/svc/msix.c b/me/blocks/vnic/svc/msix.c
--- a/me/blocks/vnic/svc/msix.c
+++ b/me/blocks/vnic/svc/msix.c
@@ -45,48 +45,13 @@
 #include <nfp6000/nfp_pcie.h>
 #include <nfp/mem_bulk.h>
 #include <nfp/pcie.h>
 #include <vnic/shared/nfd_cfg.h>
+#include <vnic/svc/msix.h>
 
-/* Imports this variable in the event this file is compiled separate from
- * svc_me.c */
-__shared __lmem volatile uint64_t svc_cfg_bars[NFD_MAX_ISL];
 
-/*
- * MSI-X definitions:
- * @PCI_MSIX_TBL_ENTRY_SZ          Size in Bytes for a MSI-X table entry
- * @PCI_MSIX_TBL_ENTRY_SZ32        Size in 32bit words for a MSI-X table entry
- * @PCI_MSIX_TBL_ENTRY_OFF         Offset in MSI-X table for a given vector
- *
- * @PCI_MSIX_TBL_MSG_FLAGS_IDX32   Word index for flags in an entry
- * @PCI_MSIX_TBL_MSG_DATA_IDX32    Word index for message data in an entry
- * @PCI_MSIX_TBL_MSG_ADDR_HI_IDX32 Word index for message address in an entry
- * @PCI_MSIX_TBL_MSG_ADDR_LO_IDX32 Word index for message address in an entry
- *
- * @PCI_MSIX_FLAGS_MASKED          Bit the flags to mask an entry
- *
- * Note, the order for the TBL entries seems wrong, but that's how
- * they pop up in the read transfer registers.
- */
-#define PCI_MSIX_TBL_ENTRY_SZ           (4 * 4)
-#define PCI_MSIX_TBL_ENTRY_SZ32         (PCI_MSIX_TBL_ENTRY_SZ / 4)
-#define PCI_MSIX_TBL_ENTRY_OFF(_x)      (PCI_MSIX_TBL_ENTRY_SZ * (_x))
+MSIX_DECLARE;
 
-#define PCI_MSIX_TBL_MSG_ADDR_LO        (0)
-#define PCI_MSIX_TBL_MSG_ADDR_LO_IDX32  (PCI_MSIX_TBL_MSG_ADDR_LO / 4)
-#define PCI_MSIX_TBL_MSG_ADDR_HI        (4)
-#define PCI_MSIX_TBL_MSG_ADDR_HI_IDX32  (PCI_MSIX_TBL_MSG_ADDR_HI / 4)
-#define PCI_MSIX_TBL_MSG_DATA           (8)
-#define PCI_MSIX_TBL_MSG_DATA_IDX32     (PCI_MSIX_TBL_MSG_DATA / 4)
-#define PCI_MSIX_TBL_MSG_FLAGS          (12)
-#define PCI_MSIX_TBL_MSG_FLAGS_IDX32    (PCI_MSIX_TBL_MSG_FLAGS / 4)
-
-#define PCIE_MSIX_FLAGS_MASKED          (1 << 0)
-
-/*
- * Offset of the MSI-X table in the VF control BAR
- */
-#define NFD_VF_MSIX_TABLE_OFF   0x2000
 
 /* Global variable to cache the current CPP 2 PCIe BAR */
 __gpr static unsigned int msix_cur_cpp2pci_addr = 0;
 
@@ -94,10 +59,10 @@
 /*
  * Calculate the CPP2PCIe bar value (should be somewhere else)
  */
 __intrinsic static unsigned int
-pcie_c2p_barcfg_addr(unsigned int addr_hi,
-                     unsigned int addr_lo, unsigned int req_id)
+_pcie_c2p_barcfg_addr(unsigned int addr_hi,
+                      unsigned int addr_lo, unsigned int req_id)
 {
     unsigned int tmp;
 
     __asm dbl_shf[tmp, addr_hi, addr_lo, >>27];
@@ -116,9 +81,9 @@ pcie_c2p_barcfg_addr(unsigned int addr_h
  * Send MSI-X interrupt for a PF and optionally mask the interrupt
  *
  * Returns 0 on success and non-zero when the entry is masked.
  *
- * @param pcie_nr     PCIe island number
+ * @param pcie_nr     PCIe island number (0 to 3)
  * @param bar_nr      CPP2PCIe bar to use
  * @param entry_nr    MSI-X table entry number
  * @param mask_en     Boolean, should interrupt be masked after sending.
  * @return            0 on success, else the interrupt was masked.
@@ -191,9 +156,9 @@ msix_pf_send(unsigned int pcie_nr, unsig
     if (flags & PCIE_MSIX_FLAGS_MASKED)
         goto out;
 
     /* Check if we need to re-configure the CPP2PCI BAR */
-    bar_addr = pcie_c2p_barcfg_addr(addr_hi, addr_lo, 0);
+    bar_addr = _pcie_c2p_barcfg_addr(addr_hi, addr_lo, 0);
     if (bar_addr != msix_cur_cpp2pci_addr) {
         pcie_c2p_barcfg_set(pcie_nr, bar_nr, addr_hi, addr_lo, 0);
         msix_cur_cpp2pci_addr = bar_addr;
     }
@@ -225,11 +190,11 @@ out:
 
 
 /**
  * Send MSI-X interrupt for specified virtual function and optionally mask
- * @param pcie_nr     PCIe cluster number
+ * @param pcie_nr     PCIe island number (0 to 3)
  * @param bar_nr      CPP2PCIe bar to use
- * @param vf_nr       Virtual function number (0 to 15)
+ * @param vf_nr       Virtual function number (0 to 63)
  * @param entry_nr    MSI-X table entry number
  * @param mask_en     Boolean, should interrupt be masked after sending.
  * @return            0 on success, else the interrupt was masked.
  *
@@ -273,9 +238,9 @@ msix_vf_send(unsigned int pcie_nr, unsig
 
     int ret = 1;
 
     msix_table_addr =
-        (__emem char *)NFD_CFG_BAR(svc_cfg_bars[pcie_nr - 4], vf_nr);
+        (__emem char *)NFD_CFG_BAR(msix_cfg_bars[pcie_nr], vf_nr);
     msix_table_addr += NFD_VF_MSIX_TABLE_OFF;
 
     /* Read the full table entry */
     mem_read8(tmp,
@@ -289,9 +254,9 @@ msix_vf_send(unsigned int pcie_nr, unsig
     if (flags & PCIE_MSIX_FLAGS_MASKED)
         goto out;
 
     /* Check if we need to re-configure the CPP2PCI BAR */
-    bar_addr = pcie_c2p_barcfg_addr(addr_hi, addr_lo, (vf_nr + 64));
+    bar_addr = _pcie_c2p_barcfg_addr(addr_hi, addr_lo, (vf_nr + 64));
     if (bar_addr != msix_cur_cpp2pci_addr) {
         pcie_c2p_barcfg_set(pcie_nr, bar_nr,
                             addr_hi, addr_lo, (vf_nr + 64));
         msix_cur_cpp2pci_addr = bar_addr;
diff --git a/me/blocks/vnic/svc/msix.h b/me/blocks/vnic/svc/msix.h
new file mode 100644
--- /dev/null
+++ b/me/blocks/vnic/svc/msix.h
@@ -0,0 +1,134 @@
+/*
+ * Copyright (C) 2015-2016,  Netronome Systems, Inc.  All rights reserved.
+ *
+ * @file   msix.h
+ * @brief  MSI-X library
+ */
+
+#ifndef _BLOCKS__VNIC_SVC_MSIX_H_
+#define _BLOCKS__VNIC_SVC_MSIX_H_
+
+/*
+ * MSI-X definitions:
+ * @PCI_MSIX_TBL_ENTRY_SZ          Size in Bytes for a MSI-X table entry
+ * @PCI_MSIX_TBL_ENTRY_SZ32        Size in 32bit words for a MSI-X table entry
+ * @PCI_MSIX_TBL_ENTRY_OFF         Offset in MSI-X table for a given vector
+ *
+ * @PCI_MSIX_TBL_MSG_FLAGS_IDX32   Word index for flags in an entry
+ * @PCI_MSIX_TBL_MSG_DATA_IDX32    Word index for message data in an entry
+ * @PCI_MSIX_TBL_MSG_ADDR_HI_IDX32 Word index for message address in an entry
+ * @PCI_MSIX_TBL_MSG_ADDR_LO_IDX32 Word index for message address in an entry
+ *
+ * @PCI_MSIX_FLAGS_MASKED          Bit the flags to mask an entry
+ *
+ * Note, the order for the TBL entries seems wrong, but that's how
+ * they pop up in the read transfer registers.
+ */
+#define PCI_MSIX_TBL_ENTRY_SZ           (4 * 4)
+#define PCI_MSIX_TBL_ENTRY_SZ32         (PCI_MSIX_TBL_ENTRY_SZ / 4)
+#define PCI_MSIX_TBL_ENTRY_OFF(_x)      (PCI_MSIX_TBL_ENTRY_SZ * (_x))
+
+#define PCI_MSIX_TBL_MSG_ADDR_LO        (0)
+#define PCI_MSIX_TBL_MSG_ADDR_LO_IDX32  (PCI_MSIX_TBL_MSG_ADDR_LO / 4)
+#define PCI_MSIX_TBL_MSG_ADDR_HI        (4)
+#define PCI_MSIX_TBL_MSG_ADDR_HI_IDX32  (PCI_MSIX_TBL_MSG_ADDR_HI / 4)
+#define PCI_MSIX_TBL_MSG_DATA           (8)
+#define PCI_MSIX_TBL_MSG_DATA_IDX32     (PCI_MSIX_TBL_MSG_DATA / 4)
+#define PCI_MSIX_TBL_MSG_FLAGS          (12)
+#define PCI_MSIX_TBL_MSG_FLAGS_IDX32    (PCI_MSIX_TBL_MSG_FLAGS / 4)
+
+#define PCIE_MSIX_FLAGS_MASKED          (1 << 0)
+
+#define PCIE_MSIX_MAX_ISL               4
+
+/*
+ * Offset of the MSI-X table in the VF control BAR
+ */
+#define NFD_VF_MSIX_TABLE_OFF   0x2000
+
+
+#if defined(__NFP_LANG_MICROC)
+
+/* Declare array of NFD CFG BAR pointers and a global variable to
+ * cache the current CPP 2 PCIe BAR */
+#define MSIX_DECLARE                                                    \
+    __shared __lmem volatile uint64_t msix_cfg_bars[PCIE_MSIX_MAX_ISL];
+
+
+/* Initialise the value of msix_cfg_bars[] for the specified island.
+ * This macro must be called for each PCIe island in use, and
+ * NFD_CFG_BASE_DECLARE(_isl) must have been called previously
+ * within the compilation block. */
+#define MSIX_INIT_ISL_IND(_isl)                                 \
+do {                                                            \
+    msix_cfg_bars[_isl] = (uint64_t)NFD_CFG_BASE_LINK(_isl);    \
+} while (0)
+
+#define MSIX_INIT_ISL(_isl) MSIX_INIT_ISL_IND(_isl)
+
+
+/**
+ * Send MSI-X interrupt for a PF and optionally mask the interrupt
+ *
+ * Returns 0 on success and non-zero when the entry is masked.
+ *
+ * @param pcie_nr     PCIe island number (0 to 3)
+ * @param bar_nr      CPP2PCIe bar to use
+ * @param entry_nr    MSI-X table entry number
+ * @param mask_en     Boolean, should interrupt be masked after sending.
+ * @return            0 on success, else the interrupt was masked.
+ *
+ * For a given PCI Island and CPP2PCIe BAR this function is only safe
+ * to be called from within a single context. If multiple contexts (or
+ * MEs) are used to send MSI-X interrupts from the same PCIe Island
+ * they must use separate CPP2PCIe BARs.
+ *
+ * Note, there is a race potential race between reading the status and
+ * generating the interrupt, but this race can only happen if the
+ * driver masks the interrupt in between the ME reading the MSI-X
+ * control word and attempting to send the interrupt.  Since the
+ * driver is not masking the interrupt the race should not happen.
+ */
+__intrinsic int msix_pf_send(unsigned int pcie_nr, unsigned int bar_nr,
+                             unsigned int entry_nr, unsigned int mask_en);
+
+
+/**
+ * Send MSI-X interrupt for specified virtual function and optionally mask
+ * @param pcie_nr     PCIe island number (0 to 3)
+ * @param bar_nr      CPP2PCIe bar to use
+ * @param vf_nr       Virtual function number (0 to 63)
+ * @param entry_nr    MSI-X table entry number
+ * @param mask_en     Boolean, should interrupt be masked after sending.
+ * @return            0 on success, else the interrupt was masked.
+ *
+ * For a given PCI Island and CPP2PCIe BAR this function is only safe
+ * to be called from within a single context. If multiple contexts (or
+ * MEs) are used to send MSI-X interrupts from the same PCIe Island
+ * they must use separate CPP2PCIe BARs.
+ *
+ * Note, there is a race potential race between reading the status and
+ * generating the interrupt, but this race can only happen if the
+ * driver masks the interrupt in between the ME reading the MSI-X
+ * control word and attempting to send the interrupt.  Since the
+ * driver is not masking the interrupt the race should not happen.
+ */
+__intrinsic int msix_vf_send(unsigned int pcie_nr, unsigned int bar_nr,
+                             unsigned int vf_nr, unsigned int entry_nr,
+                             unsigned int mask_en);
+
+#endif /* __NFP_LANG_MICROC */
+
+#endif /* !_BLOCKS__VNIC_SVC_MSIX_H_ */
diff --git a/me/blocks/vnic/svc/msix_qmon.c b/me/blocks/vnic/svc/msix_qmon.c
--- a/me/blocks/vnic/svc/msix_qmon.c
+++ b/me/blocks/vnic/svc/msix_qmon.c
@@ -33,18 +33,19 @@
 #include <std/reg_utils.h>
 
 #include <nfp6000/nfp_me.h>
 
+#include <vnic/nfd_common.h>
+#include <vnic/pci_out.h>
 #include <vnic/shared/nfd_cfg.h>
-#include <vnic/pci_out.h>
 #include <vnic/shared/nfd_internal.h>
+#include <vnic/svc/msix.h>
+#include <vnic/svc/msix.c>
 #include <vnic/utils/qcntl.h>
 
+
 #include <nfp_net_ctrl.h>
 
-#include "nfd_common.h"
-
-#include "msix.c"
 
 /*
  * TODO:
  * - any other operation when link comes down?
@@ -71,9 +72,8 @@
  * core MSI-X logic is only dealing with "queues" and configuration
  * logic translates from "rings" to queues.
  */
 
-
 #define MAX_QUEUE_NUM (NFD_MAX_VFS * NFD_MAX_VF_QUEUES + \
                        NFD_MAX_PFS * NFD_MAX_PF_QUEUES - 1)
 #define MAX_NUM_PCI_ISLS 4
 
@@ -171,8 +171,10 @@
  * - sets usec delay to 0
  */
 #define MSIX_IRQC_DEFAULT_CFG (1 << 16)
 
+MSIX_DECLARE;
+
 /*
  * Initialise the state (executed by context 0)
  *
  * Global variables are initialised to zero so init only the ones
@@ -849,9 +851,9 @@ msix_send_q_irq(const unsigned int pcie_
     NFD_NATQ2VNIC(fn, qnum);
 
     /* If we don't use auto-masking, check (and update) the ICR */
     if (!automask) {
-        cfg_bar = NFD_CFG_BAR(svc_cfg_bars[pcie_isl], fn);
+        cfg_bar = NFD_CFG_BAR(msix_cfg_bars[pcie_isl], fn);
         cfg_bar += NFP_NET_CFG_ICR(entry);
         mem_read32_le(&mask_r, (__mem void *)cfg_bar, sizeof(mask_r));
         if (mask_r & 0x000000ff) {
             ret = 1;
@@ -861,11 +863,11 @@ msix_send_q_irq(const unsigned int pcie_
         mem_write8_le(&mask_w, (__mem void *)cfg_bar, 1);
     }
 
     if (NFD_VNIC_IS_PF(fn))
-        ret = msix_pf_send(pcie_isl + 4, PCIE_CPP2PCIE_QMON, entry, automask);
+        ret = msix_pf_send(pcie_isl, PCIE_CPP2PCIE_QMON, entry, automask);
     else
-        ret = msix_vf_send(pcie_isl + 4, PCIE_CPP2PCIE_QMON, fn,
+        ret = msix_vf_send(pcie_isl, PCIE_CPP2PCIE_QMON, fn,
                            entry, automask);
 
     /* IRQ issued, cleanup interrupt moderation state */
     if (!ret)
diff --git a/me/blocks/vnic/svc_me.c b/me/blocks/vnic/svc_me.c
--- a/me/blocks/vnic/svc_me.c
+++ b/me/blocks/vnic/svc_me.c
@@ -24,21 +24,17 @@
 #include <nfp/mem_bulk.h>
 
 #include <nfp6000/nfp_me.h>
 
-#include "shared/nfd_cfg.h"
+#include <vnic/shared/nfd_cfg.h>
 #include <vnic/shared/nfd_flr.c>
 #include <vnic/shared/nfd_vf_cfg_iface.h>
+#include <vnic/svc/msix.h>
 
 
-/* A global array with base addresses for the configuration
- * bars. Marked as volatile so the compiler doesn't optimise them
- * out... */
-__shared __lmem volatile uint64_t svc_cfg_bars[NFD_MAX_ISL];
-
 /* Signal used for reconfiguration synchronisation */
 #define SVC_RECONFIG_SIG_NUM    15
-#include "svc/msix_qmon.c"
+#include <vnic/svc/msix_qmon.c>
 
 
 /*
  * The service ME performs a number of different functions.
@@ -145,27 +141,27 @@ main(void)
         int ncfg = 0;
 
         /* Initialisation */
 #ifdef NFD_PCIE0_EMEM
-        svc_cfg_bars[0] = (uint64_t)NFD_CFG_BASE_LINK(0);
+        MSIX_INIT_ISL(0);
         nfd_cfg_init_cfg_msg(&nfd_cfg_sig_svc_me0, &cfg_msg0);
         msix_qmon_init(0);
 #endif
 
 #ifdef NFD_PCIE1_EMEM
-        svc_cfg_bars[1] = (uint64_t)NFD_CFG_BASE_LINK(1);
+        MSIX_INIT_ISL(1);
         nfd_cfg_init_cfg_msg(&nfd_cfg_sig_svc_me1, &cfg_msg1);
         msix_qmon_init(1);
 #endif
 
 #ifdef NFD_PCIE2_EMEM
-        svc_cfg_bars[2] = (uint64_t)NFD_CFG_BASE_LINK(2);
+        MSIX_INIT_ISL(2);
         nfd_cfg_init_cfg_msg(&nfd_cfg_sig_svc_me2, &cfg_msg2);
         msix_qmon_init(2);
 #endif
 
 #ifdef NFD_PCIE3_EMEM
-        svc_cfg_bars[3] = (uint64_t)NFD_CFG_BASE_LINK(3);
+        MSIX_INIT_ISL(3);
         nfd_cfg_init_cfg_msg(&nfd_cfg_sig_svc_me3, &cfg_msg3);
         msix_qmon_init(3);
 #endif
 
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498063021 -7200
# Node ID 385bfc074a705e4e1cff2a6a562210bc0efbb5d8
# Parent  f5e9169a7df4d5663550f516249d5cc7dfd3ddd6
[svc_me] Use flowenv provided pcie_c2p_barcfg_val()
* MSIX functions previously defined their own flowenv style function
  to compute the value, and called pcie_c2p_barcfg_set() that repeated
  the computation to actually change the BAR

diff --git a/me/blocks/vnic/svc/msix.c b/me/blocks/vnic/svc/msix.c
--- a/me/blocks/vnic/svc/msix.c
+++ b/me/blocks/vnic/svc/msix.c
@@ -55,29 +55,8 @@ MSIX_DECLARE;
 /* Global variable to cache the current CPP 2 PCIe BAR */
 __gpr static unsigned int msix_cur_cpp2pci_addr = 0;
 
 
-/*
- * Calculate the CPP2PCIe bar value (should be somewhere else)
- */
-__intrinsic static unsigned int
-_pcie_c2p_barcfg_addr(unsigned int addr_hi,
-                      unsigned int addr_lo, unsigned int req_id)
-{
-    unsigned int tmp;
-
-    __asm dbl_shf[tmp, addr_hi, addr_lo, >>27];
-    tmp = tmp & NFP_PCIE_BARCFG_C2P_ADDR_msk;
-
-    /* Configure RID if req_id is non-zero or not constant */
-    if ((!__is_ct_const(req_id)) || (req_id != 0)) {
-        tmp |= NFP_PCIE_BARCFG_C2P_ARI_ENABLE;
-        tmp |= NFP_PCIE_BARCFG_C2P_ARI(req_id);
-    }
-
-    return tmp;
-}
-
 /**
  * Send MSI-X interrupt for a PF and optionally mask the interrupt
  *
  * Returns 0 on success and non-zero when the entry is masked.
@@ -156,11 +135,11 @@ msix_pf_send(unsigned int pcie_nr, unsig
     if (flags & PCIE_MSIX_FLAGS_MASKED)
         goto out;
 
     /* Check if we need to re-configure the CPP2PCI BAR */
-    bar_addr = _pcie_c2p_barcfg_addr(addr_hi, addr_lo, 0);
+    bar_addr = pcie_c2p_barcfg_val(addr_hi, addr_lo, 0);
     if (bar_addr != msix_cur_cpp2pci_addr) {
-        pcie_c2p_barcfg_set(pcie_nr, bar_nr, addr_hi, addr_lo, 0);
+        pcie_c2p_barcfg_set_expl(pcie_nr, bar_nr, bar_addr);
         msix_cur_cpp2pci_addr = bar_addr;
     }
 
     /* Send the MSI-X and automask.  We overlap the commands so that
@@ -254,12 +233,11 @@ msix_vf_send(unsigned int pcie_nr, unsig
     if (flags & PCIE_MSIX_FLAGS_MASKED)
         goto out;
 
     /* Check if we need to re-configure the CPP2PCI BAR */
-    bar_addr = _pcie_c2p_barcfg_addr(addr_hi, addr_lo, (vf_nr + 64));
+    bar_addr = pcie_c2p_barcfg_val(addr_hi, addr_lo, (vf_nr + 64));
     if (bar_addr != msix_cur_cpp2pci_addr) {
-        pcie_c2p_barcfg_set(pcie_nr, bar_nr,
-                            addr_hi, addr_lo, (vf_nr + 64));
+        pcie_c2p_barcfg_set_expl(pcie_nr, bar_nr, bar_addr);
         msix_cur_cpp2pci_addr = bar_addr;
     }
 
     /* Send the MSI-X and automask.  We overlap the commands so that
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498063022 -7200
# Node ID c17a2565cf5ec3e22c70b6525b94d20ecebd67ba
# Parent  385bfc074a705e4e1cff2a6a562210bc0efbb5d8
[PCI.IN] Rename l4_offset in LSO word to lso_hdrlen
* lso_hdr_len was previously used in the code, this has been renamed
  to lso_offhdr to avoid confusion.  It already held the meta data
  length (as called offset) as well as the lso_hdrlen.

diff --git a/me/blocks/vnic/nfd_in.uc b/me/blocks/vnic/nfd_in.uc
--- a/me/blocks/vnic/nfd_in.uc
+++ b/me/blocks/vnic/nfd_in.uc
@@ -101,11 +101,11 @@
  *    0  |S|    offset   |           reserved            |itf|   q_num   |
  *       +-+-+-+---------+-------------------------------+---+-----------+
  *    1  |I|J|S|                       buf_addr                          |
  *       +-+-+-+---------+---------------+-+-+---------------------------+
- *    2  |     flags     |   l4_offset   |L|S|           mss             |
+ *    2  |     flags     |  lso_seq_cnt  |L|S|           mss             |
  *       +---------------+---------------+-+-+---------------------------+
- *    3  |            data_len           |              vlan             |
+ *    3  |            data_len           |       vlan [L3/L4 off]        |
  *       +-------------------------------+-------------------------------+
  *
  *       Flag bits (31-24) expanded:
  *          31       30      29      28      27      26      25     24
@@ -142,9 +142,8 @@
 #define NFD_IN_FLAGS_TX_VLAN_fld        2, 27, 27
 #define NFD_IN_FLAGS_TX_LSO_fld         2, 26, 26
 #define NFD_IN_FLAGS_TX_ENCAP_VXLAN_fld 2, 25, 25
 #define NFD_IN_FLAGS_TX_ENCAP_GRE_fld   2, 24, 24
-#define NFD_IN_L4OFF_fld        2, 23, 16
 #define NFD_IN_LSO_fld          2, 23, 0
 #define NFD_IN_LSO_SEQ_CNT_fld  2, 23, 16
 #define NFD_IN_LSO_END_fld      2, 15, 15
 #define NFD_IN_LSO_MSS_fld      2, 13, 0
diff --git a/me/blocks/vnic/pci_in.h b/me/blocks/vnic/pci_in.h
--- a/me/blocks/vnic/pci_in.h
+++ b/me/blocks/vnic/pci_in.h
@@ -193,9 +193,9 @@
  *    0  |E|   offset    |            dma_len            |  dma_addr_hi  |
  *       +-+-------------+-------------------------------+---------------+
  *    1  |                          dma_addr_lo                          |
  *       +---------------+---------------+---+---------------------------+
- *    2  |     flags     |   l4_offsets  |sp0|           mss             |
+ *    2  |     flags     |   lso_hdrlen  |sp0|           mss             |
  *       +---------------+---------------+---|---------------------------+
  *    3  |           data_len            |              vlan             |
  *       +-------------------------------+-------------------------------+
  *
@@ -215,9 +215,9 @@ struct nfd_in_tx_desc {
 
             unsigned int dma_addr_lo:32; /**< Bits[31:0] of the host address */
 
             unsigned int flags:8;       /**< Flags for the packet */
-            unsigned int l4_offset:8;   /**< Offset of L4 header in packet */
+            unsigned int lso_hdrlen:8;  /**< LSO, TCP payload offset */
             unsigned int sp0:2;
             unsigned int mss:14;        /**< Info for Large Segment Offload */
 
             unsigned int data_len:16;   /**< Length of the entire packet */
@@ -236,9 +236,9 @@ struct nfd_in_tx_desc {
  *    0  |S|    offset   |            seq_num            |itf|   q_num   |
  *       +-+-+-+---------+-------------------------------+---+-----------+
  *    1  |I|J|S|                       buf_addr                          |
  *       +-+-+-+---------+---------------+-+-+---------------------------+
- *    2  |     flags     |   l4_offset   |L|S|           mss             |
+ *    2  |     flags     |  lso_seq_cnt  |L|S|           mss             |
  *       +---------------+---------------+-+-+---------------------------+
  *    3  |            data_len           |              vlan             |
  *       +-------------------------------+-------------------------------+
  *
@@ -265,9 +265,9 @@ struct nfd_in_pkt_desc {
             unsigned int sp2:1;         /**< Spare bit (unused) */
             unsigned int buf_addr:29;   /**< Bits [39:11] of the MU buffer */
 
             unsigned int flags:8;       /**< Flags for the packet */
-            unsigned int l4_offset:8;   /**< Offset of L4 header in packet */
+            unsigned int lso_seq_cnt:8; /**< LSO index/count for this series */
             unsigned int lso_end:1;     /**< Last packet in a series of LSO packets */
             unsigned int sp1:1;         /**< Spare bit (unused) */
             unsigned int mss:14;        /**< Info for Large Segment Offload */
 
diff --git a/me/blocks/vnic/pci_in/issue_dma.c b/me/blocks/vnic/pci_in/issue_dma.c
--- a/me/blocks/vnic/pci_in/issue_dma.c
+++ b/me/blocks/vnic/pci_in/issue_dma.c
@@ -414,9 +414,9 @@ issue_dma_vnic_setup(struct nfd_cfg_msg 
 
     } else if (cfg_msg->up_bit && !queue_data[bmsk_queue].up) {
         /* Initialise queue state */
         queue_data[bmsk_queue].sp0 = 0;
-        queue_data[bmsk_queue].lso_hdr_len = 0;
+        queue_data[bmsk_queue].lso_offhdr = 0;
         queue_data[bmsk_queue].lso_seq_cnt = 0;
         queue_data[bmsk_queue].rid = 0;
         if (NFD_VNIC_IS_VF(cfg_msg->vnic)) {
             queue_data[bmsk_queue].rid = cfg_msg->vnic + NFD_CFG_VF_OFFSET;
@@ -453,9 +453,9 @@ issue_dma_vnic_setup(struct nfd_cfg_msg 
         }
 
         /* Clear queue state */
         queue_data[bmsk_queue].sp0 = 0;
-        queue_data[bmsk_queue].lso_hdr_len = 0;
+        queue_data[bmsk_queue].lso_offhdr = 0;
         queue_data[bmsk_queue].lso_seq_cnt = 0;
         /* Leave RID configured after first set */
         /* "cont" is used as part of the "up" signalling,
          * to move the "up" test off the fast path. */
@@ -581,12 +581,12 @@ issue_dma_cleanup_lso_state()
     unsigned int curr_buf;
     /* XXX leave CONT bit untouched, it gets cleared on EOP descriptors */
 
     /* clear LSO specific state */
-    __asm { alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_HDR_LEN_wrd],   \
-                NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_HDR_LEN_wrd],   \
-                AND~, NFD_IN_DMA_STATE_LSO_HDR_LEN_msk,                 \
-                <<NFD_IN_DMA_STATE_LSO_HDR_LEN_shf] }
+    __asm { alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_OFFHDR_wrd],    \
+                NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_OFFHDR_wrd],    \
+                AND~, NFD_IN_DMA_STATE_LSO_OFFHDR_msk,                  \
+                <<NFD_IN_DMA_STATE_LSO_OFFHDR_shf] }
     __asm { alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_SEQ_CNT_wrd],   \
                 NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_SEQ_CNT_wrd],   \
                 AND~, NFD_IN_DMA_STATE_LSO_SEQ_CNT_msk,                 \
                 <<NFD_IN_DMA_STATE_LSO_SEQ_CNT_shf] }
@@ -748,13 +748,13 @@ do {                                    
     unsigned int mode;                                                       \
     unsigned int header_to_read;                                             \
     unsigned int hdr_remainder;                                              \
     __gpr unsigned int curr_buf;                                             \
-    __gpr unsigned int lso_hdr_len;                                          \
+    __gpr unsigned int lso_offhdr;                                           \
     __gpr unsigned int lso_payload_len;                                      \
     unsigned int data_len;                                                   \
     unsigned int offset;                                                     \
-    unsigned int l4_offset;                                                  \
+    unsigned int lso_hdrlen;                                                 \
     unsigned int mss;                                                        \
     unsigned int lso_req_wrd;                                                \
     unsigned int lso_seq_cnt;                                                \
     unsigned int bytes_dmaed;                                                \
@@ -796,9 +796,9 @@ do {                                    
             alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_DATA_LEN_wrd],           \
                 NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_DATA_LEN_wrd],           \
                 or, data_len, <<NFD_IN_DMA_STATE_DATA_LEN_shf] }             \
                                                                              \
-        l4_offset = tx_desc.pkt##_pkt##.l4_offset;                           \
+        lso_hdrlen = tx_desc.pkt##_pkt##.lso_hdrlen;                         \
         mss = tx_desc.pkt##_pkt##.mss;                                       \
         lso_req_wrd = tx_desc.pkt##_pkt##.__raw[2];                          \
         /* Copy aside the LSO request parameters for consistency checks */   \
         /* Mask out the reserved bits during copy to avoid false positives */ \
@@ -807,12 +807,12 @@ do {                                    
                 lso_req_wrd, and~,                                           \
                 NFD_IN_DMA_STATE_LSO_RES_msk,                                \
                 <<NFD_IN_DMA_STATE_LSO_RES_shf] }                            \
                                                                              \
-        __asm { alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_HDR_LEN_wrd],    \
-                    NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_HDR_LEN_wrd],    \
-                    AND~, NFD_IN_DMA_STATE_LSO_HDR_LEN_msk,                  \
-                    <<NFD_IN_DMA_STATE_LSO_HDR_LEN_shf] }                    \
+        __asm { alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_OFFHDR_wrd],     \
+                    NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_OFFHDR_wrd],     \
+                    AND~, NFD_IN_DMA_STATE_LSO_OFFHDR_msk,                   \
+                    <<NFD_IN_DMA_STATE_LSO_OFFHDR_shf] }                     \
         __asm { alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_SEQ_CNT_wrd],    \
                     NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_SEQ_CNT_wrd],    \
                     AND~, NFD_IN_DMA_STATE_LSO_SEQ_CNT_msk,                  \
                     <<NFD_IN_DMA_STATE_LSO_SEQ_CNT_shf] }                    \
@@ -829,18 +829,18 @@ do {                                    
             __asm { alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_INVALID_wrd],    \
                         NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_INVALID_wrd],    \
                         or, 1, <<NFD_IN_DMA_STATE_INVALID_shf] }             \
         }                                                                    \
-        if (l4_offset < NFD_IN_MIN_LSO_HDR_SZ) {                             \
-            /* The lso_hdr_len is too small for TCP */                       \
+        if (lso_hdrlen < NFD_IN_MIN_LSO_HDR_SZ) {                            \
+            /* The lso_hdrlen is too small for TCP */                        \
             __asm { alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_INVALID_wrd],    \
                         NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_INVALID_wrd],    \
                         or, 1, <<NFD_IN_DMA_STATE_INVALID_shf] }             \
         }                                                                    \
-        hdr_len_chk = l4_offset + offset;                                    \
+        hdr_len_chk = offset + lso_hdrlen;                                   \
         if (data_len <= hdr_len_chk) {                                       \
             /* The total length doesn't leave any data after accounting */   \
-            /* for lso_hdr_len and meta data length */                       \
+            /* for lso_hdrlen and meta data length */                        \
             __asm { alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_INVALID_wrd],    \
                         NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_INVALID_wrd],    \
                         or, 1, <<NFD_IN_DMA_STATE_INVALID_shf] }             \
         }                                                                    \
@@ -853,9 +853,9 @@ do {                                    
             __asm { alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_INVALID_wrd],    \
                         NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_INVALID_wrd],    \
                         or, 1, <<NFD_IN_DMA_STATE_INVALID_shf] }             \
         }                                                                    \
-        if ((mss + l4_offset) >                                              \
+        if ((mss + lso_hdrlen) >                                             \
             (NFD_IN_BLM_JUMBO_SIZE - NFD_IN_DATA_OFFSET)) {                  \
             /* The generated packets won't fit in the available packets. */  \
             /* This might mean that the host didn't respect the MTU that */  \
             /* the device advertised. */                                     \
@@ -875,11 +875,11 @@ do {                                    
                 >>NFD_IN_DMA_STATE_OFFSET_shf] }                             \
         __asm { ld_field_w_clr[                                              \
             data_len, 7, NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_DATA_LEN_wrd]] } \
         __asm {                                                              \
-            alu[l4_offset, NFD_IN_DMA_STATE_L4OFFSET_msk, and,               \
-                NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_L4OFFSET_wrd],           \
-                >>NFD_IN_DMA_STATE_L4OFFSET_shf] }                           \
+            alu[lso_hdrlen, NFD_IN_DMA_STATE_LSO_HDRLEN_msk, and,            \
+                NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_HDRLEN_wrd],         \
+                >>NFD_IN_DMA_STATE_LSO_HDRLEN_shf] }                         \
         __asm { alu[mss, mss_msk, and,                                       \
                     NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_MSS_wrd],        \
                     >>NFD_IN_DMA_STATE_LSO_MSS_shf] }                        \
                                                                              \
@@ -963,21 +963,21 @@ do {                                    
                                                                              \
     /* get queue_data[queue].curr_buf */                                     \
     __asm { alu[curr_buf, --, B,                                             \
                 NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_CURR_BUF_wrd]] }         \
-    /* get the queue_data[queue].lso_hdr_len */                              \
-    __asm { alu[lso_hdr_len, NFD_IN_DMA_STATE_LSO_HDR_LEN_msk, AND,          \
-                NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_HDR_LEN_wrd],        \
-                >>NFD_IN_DMA_STATE_LSO_HDR_LEN_shf] }                        \
+    /* get the queue_data[queue].lso_offhdr */                               \
+    __asm { alu[lso_offhdr, NFD_IN_DMA_STATE_LSO_OFFHDR_msk, AND,            \
+                NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_OFFHDR_wrd],         \
+                >>NFD_IN_DMA_STATE_LSO_OFFHDR_shf] }                         \
     /* 1. Load the header to CTM buffer */                                   \
-    if ((lso_hdr_len != (l4_offset + offset)) &&                             \
+    if ((lso_offhdr != (lso_hdrlen + offset)) &&                             \
         !(curr_buf & NFD_IN_DMA_STATE_INVALID_shf)) {                        \
         /* We use the DMA slot granted to this tx_descp. We are issuing */   \
         /* a "signal" based DMA since we must wait for the header loading */ \
         /* to complete.*/                                                    \
                                                                              \
         buf_addr = &lso_hdr_data[(queue << __log2(NFD_IN_MAX_LSO_HDR_SZ)) +  \
-                                 lso_hdr_len];                               \
+                                 lso_offhdr];                                \
         /*cpp_hi_word = NFP_PCIE_DMA_CMD_CPP_ADDR_HI(__ISLAND | (2 << 6));*/ \
         cpp_hi_word = 0;                                                     \
         cpp_addr_lo = buf_addr & 0xFFFFFFFF;                                 \
         pcie_hi_word = pcie_hi_word_part |                                   \
@@ -985,11 +985,11 @@ do {                                    
         pcie_addr_lo = tx_desc.pkt##_pkt##.dma_addr_lo;                      \
         cpp_hi_word |= NFP_PCIE_DMA_CMD_CPP_TOKEN(NFD_IN_DATA_DMA_TOKEN);    \
         cpp_hi_word |= NFP_PCIE_DMA_CMD_DMA_CFG_INDEX(NFD_IN_DATA_CFG_REG);  \
                                                                              \
-        if (dma_len >= (l4_offset + offset - lso_hdr_len)) {                 \
+        if (dma_len >= (offset + lso_hdrlen - lso_offhdr)) {                 \
             /* we have full header in this TX descriptor */                  \
-            dma_length = l4_offset + offset - lso_hdr_len;                   \
+            dma_length = offset + lso_hdrlen - lso_offhdr;                   \
         } else {                                                             \
             /* not enough header available */                                \
             dma_length = dma_len;                                            \
         }                                                                    \
@@ -1006,14 +1006,14 @@ do {                                    
         dma_out.pkt##_pkt##.__raw[2] = pcie_addr_lo;                         \
         dma_out.pkt##_pkt##.__raw[3] = pcie_hi_word;                         \
         __pcie_dma_enq(PCIE_ISL, &dma_out.pkt##_pkt##, NFD_IN_DATA_DMA_QUEUE,\
                        sig_done, &lso_hdr_enq_sig);                          \
-        lso_hdr_len += dma_length;                                           \
-        /* set queue_data[queue].lso_hdr_len */                              \
-        ctassert(NFD_IN_DMA_STATE_LSO_HDR_LEN_shf == 16);                    \
-        ctassert(NFD_IN_DMA_STATE_LSO_HDR_LEN_msk == 0xFF);                  \
-        __asm { ld_field[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_HDR_LEN_wrd], \
-                         4, lso_hdr_len, <<NFD_IN_DMA_STATE_LSO_HDR_LEN_shf] } \
+        lso_offhdr += dma_length;                                            \
+        /* set queue_data[queue].lso_offhdr */                               \
+        ctassert(NFD_IN_DMA_STATE_LSO_OFFHDR_shf == 16);                     \
+        ctassert(NFD_IN_DMA_STATE_LSO_OFFHDR_msk == 0xFF);                   \
+        __asm { ld_field[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_OFFHDR_wrd], \
+                         4, lso_offhdr, <<NFD_IN_DMA_STATE_LSO_OFFHDR_shf] } \
         /* update bytes_dmaed */                                             \
         __asm { alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_BYTES_DMAED_wrd],    \
                     NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_BYTES_DMAED_wrd], +, \
                     dma_length] }                                            \
@@ -1070,9 +1070,9 @@ do {                                    
                 /* 3. Copy the header */                                     \
                 hdr_pkt_ptr = (((uint64_t)curr_buf << 11) |                  \
                                (NFD_IN_DATA_OFFSET - offset));               \
                                                                              \
-                header_to_read = ((lso_hdr_len + 0x3F) & ~0x3F);             \
+                header_to_read = ((lso_offhdr + 0x3F) & ~0x3F);              \
                 __mem_pe_dma_ctm_to_mu(                                      \
                     (__mem void *)hdr_pkt_ptr,                               \
                     (__ctm void *)&lso_hdr_data[                             \
                         (queue << __log2(NFD_IN_MAX_LSO_HDR_SZ))],           \
@@ -1115,9 +1115,9 @@ do {                                    
             issued_tmp.sp1 = 0;                                              \
             issued_tmp.offset = offset;                                      \
             issued_tmp.buf_addr = curr_buf;                                  \
             issued_tmp.__raw[2] = tx_desc.pkt##_pkt##.__raw[2];              \
-            issued_tmp.l4_offset = lso_seq_cnt;                              \
+            issued_tmp.lso_seq_cnt = lso_seq_cnt;                            \
             issued_tmp.__raw[3] = tx_desc.pkt##_pkt##.__raw[3];              \
             /* send the lso pkt desc to the lso ring */                      \
             batch_out.pkt##_pkt## = issued_tmp;                              \
             __mem_ring_journal(nfd_in_issued_lso_ring_num,                   \
@@ -1146,12 +1146,12 @@ do {                                    
                             NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_CONT_wrd],   \
                             AND~, 1, <<NFD_IN_DMA_STATE_CONT_shf] }          \
                 /* clear LSO specific state */                               \
                 __asm {                                                      \
-                    alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_HDR_LEN_wrd], \
-                        NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_HDR_LEN_wrd], \
-                        AND~, NFD_IN_DMA_STATE_LSO_HDR_LEN_msk,              \
-                        <<NFD_IN_DMA_STATE_LSO_HDR_LEN_shf] }                \
+                    alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_OFFHDR_wrd], \
+                        NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_OFFHDR_wrd], \
+                        AND~, NFD_IN_DMA_STATE_LSO_OFFHDR_msk,               \
+                        <<NFD_IN_DMA_STATE_LSO_OFFHDR_shf] }                 \
                 lso_seq_cnt = 0;                                             \
                 __asm {                                                      \
                     alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_FLAGS_wrd],      \
                         --, b, 0] }                                          \
@@ -1194,9 +1194,9 @@ do {                                    
                     +, dma_length] }                                         \
                                                                              \
         cpp_addr_lo = curr_buf << 11;                                        \
         cpp_addr_lo -= offset;                                               \
-        cpp_addr_lo += lso_hdr_len;                                          \
+        cpp_addr_lo += lso_offhdr;                                           \
         cpp_addr_lo += lso_payload_len;                                      \
         pcie_hi_word = (pcie_hi_word_part |                                  \
              NFP_PCIE_DMA_CMD_PCIE_ADDR_HI(tx_desc.pkt##_pkt##.dma_addr_hi));\
         pcie_addr_lo = tx_desc.pkt##_pkt##.dma_addr_lo;                      \
@@ -1250,11 +1250,11 @@ do {                                    
             issued_tmp.sp1 = 0;                                              \
             issued_tmp.offset = offset;                                      \
             issued_tmp.buf_addr = curr_buf;                                  \
             issued_tmp.__raw[2] = tx_desc.pkt##_pkt##.__raw[2];              \
-            issued_tmp.l4_offset = lso_seq_cnt;                              \
+            issued_tmp.lso_seq_cnt = lso_seq_cnt;                            \
             issued_tmp.__raw[3] = tx_desc.pkt##_pkt##.__raw[3];              \
-            issued_tmp.data_len = (lso_hdr_len + lso_payload_len);           \
+            issued_tmp.data_len = lso_offhdr + lso_payload_len;              \
             /* if last of LSO segment set lso end flag and we have no */     \
             /* more dma data */                                              \
             if ((lso_dma_index == dma_len) && tx_desc.pkt##_pkt##.eop) {     \
                 issued_tmp.lso_end = 1;                                      \
@@ -1268,12 +1268,12 @@ do {                                    
                             NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_CONT_wrd],   \
                             AND~, 1, <<NFD_IN_DMA_STATE_CONT_shf] }          \
                 /* clear LSO specific state */                               \
                 __asm {                                                      \
-                    alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_HDR_LEN_wrd], \
-                        NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_HDR_LEN_wrd], \
-                        AND~, NFD_IN_DMA_STATE_LSO_HDR_LEN_msk,              \
-                        <<NFD_IN_DMA_STATE_LSO_HDR_LEN_shf] }                \
+                    alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_OFFHDR_wrd], \
+                        NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_LSO_OFFHDR_wrd], \
+                        AND~, NFD_IN_DMA_STATE_LSO_OFFHDR_msk,               \
+                        <<NFD_IN_DMA_STATE_LSO_OFFHDR_shf] }                 \
                 lso_seq_cnt = 0;                                             \
                 __asm {                                                      \
                     alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_FLAGS_wrd],      \
                         --, b, 0] }                                          \
@@ -1333,12 +1333,12 @@ do {                                    
     NFD_IN_LSO_CNTR_ADD(nfd_in_lso_cntr_addr,                                \
                        NFD_IN_LSO_CNTR_X_ISSUED_LAST_LSO_MSS,                \
                        mss);                                                 \
     NFD_IN_LSO_CNTR_CLR(nfd_in_lso_cntr_addr,                                \
-                        NFD_IN_LSO_CNTR_X_ISSUED_LAST_LSO_L4_OFFSET);        \
+                        NFD_IN_LSO_CNTR_X_ISSUED_LAST_LSO_HDRLEN);           \
     NFD_IN_LSO_CNTR_ADD(nfd_in_lso_cntr_addr,                                \
-                        NFD_IN_LSO_CNTR_X_ISSUED_LAST_LSO_L4_OFFSET,         \
-                        l4_offset);                                          \
+                        NFD_IN_LSO_CNTR_X_ISSUED_LAST_LSO_HDRLEN,            \
+                        lso_hdrlen);                                         \
                                                                              \
     /* Save running variables back to LM */                                  \
     /* set queue_data[queue].curr_buf */                                     \
     __asm { alu[NFD_IN_Q_STATE_PTR[NFD_IN_DMA_STATE_CURR_BUF_wrd],           \
diff --git a/me/blocks/vnic/shared/nfd_internal.h b/me/blocks/vnic/shared/nfd_internal.h
--- a/me/blocks/vnic/shared/nfd_internal.h
+++ b/me/blocks/vnic/shared/nfd_internal.h
@@ -169,9 +169,9 @@ enum NFD_IN_LSO_CNTR_IDX {
     NFD_IN_LSO_CNTR_T_ISSUED_LSO_ALL_PKT_TO_NOTIFY_RING,
     NFD_IN_LSO_CNTR_T_ISSUED_LSO_END_PKT_TO_NOTIFY_RING,
     NFD_IN_LSO_CNTR_T_ISSUED_LSO_EXC_PKT_TO_NOTIFY_RING,
     NFD_IN_LSO_CNTR_X_ISSUED_LAST_LSO_MSS,
-    NFD_IN_LSO_CNTR_X_ISSUED_LAST_LSO_L4_OFFSET,
+    NFD_IN_LSO_CNTR_X_ISSUED_LAST_LSO_HDRLEN,
     NFD_IN_LSO_CNTR_T_NOTIFY_ALL_PKT_DESC,
     NFD_IN_LSO_CNTR_T_NOTIFY_NON_LSO_PKT_DESC,
     NFD_IN_LSO_CNTR_T_NOTIFY_LSO_PKT_DESC,
     NFD_IN_LSO_CNTR_T_NOTIFY_OTHER_PKT_DESC,
@@ -207,9 +207,9 @@ static const char *nfd_in_lso_cntr_names
     "NFD_IN_LSO_CNTR_T_ISSUED_LSO_ALL_PKT_TO_NOTIFY_RING",
     "NFD_IN_LSO_CNTR_T_ISSUED_LSO_END_PKT_TO_NOTIFY_RING",
     "NFD_IN_LSO_CNTR_T_ISSUED_LSO_EXC_PKT_TO_NOTIFY_RING",
     "NFD_IN_LSO_CNTR_X_ISSUED_LAST_LSO_MSS",
-    "NFD_IN_LSO_CNTR_X_ISSUED_LAST_LSO_L4_OFFSET",
+    "NFD_IN_LSO_CNTR_X_ISSUED_LAST_LSO_HDRLEN",
     "NFD_IN_LSO_CNTR_T_NOTIFY_ALL_PKT_DESC",
     "NFD_IN_LSO_CNTR_T_NOTIFY_NON_LSO_PKT_DESC",
     "NFD_IN_LSO_CNTR_T_NOTIFY_LSO_PKT_DESC",
     "NFD_IN_LSO_CNTR_T_NOTIFY_OTHER_PKT_DESC",
@@ -357,11 +357,11 @@ struct nfd_in_queue_info {
 #define NFD_IN_DMA_STATE_CONT_wrd           0
 #define NFD_IN_DMA_STATE_LOCKED_msk         1
 #define NFD_IN_DMA_STATE_LOCKED_shf         29
 #define NFD_IN_DMA_STATE_LOCKED_wrd         0
-#define NFD_IN_DMA_STATE_LSO_HDR_LEN_msk    0xFF
-#define NFD_IN_DMA_STATE_LSO_HDR_LEN_shf    16
-#define NFD_IN_DMA_STATE_LSO_HDR_LEN_wrd    0
+#define NFD_IN_DMA_STATE_LSO_OFFHDR_msk     0xFF
+#define NFD_IN_DMA_STATE_LSO_OFFHDR_shf     16
+#define NFD_IN_DMA_STATE_LSO_OFFHDR_wrd     0
 #define NFD_IN_DMA_STATE_LSO_SEQ_CNT_msk    0xFF
 #define NFD_IN_DMA_STATE_LSO_SEQ_CNT_shf    8
 #define NFD_IN_DMA_STATE_LSO_SEQ_CNT_wrd    0
 #define NFD_IN_DMA_STATE_RID_msk            0xFF
@@ -380,11 +380,11 @@ struct nfd_in_queue_info {
 
 #define NFD_IN_DMA_STATE_FLAGS_msk          0xFF
 #define NFD_IN_DMA_STATE_FLAGS_shf          24
 #define NFD_IN_DMA_STATE_FLAGS_wrd          2
-#define NFD_IN_DMA_STATE_L4OFFSET_msk       0xFF
-#define NFD_IN_DMA_STATE_L4OFFSET_shf       16
-#define NFD_IN_DMA_STATE_L4OFFSET_wrd       2
+#define NFD_IN_DMA_STATE_LSO_HDRLEN_msk     0xFF
+#define NFD_IN_DMA_STATE_LSO_HDRLEN_shf     16
+#define NFD_IN_DMA_STATE_LSO_HDRLEN_wrd     2
 #define NFD_IN_DMA_STATE_LSO_RES_msk        3
 #define NFD_IN_DMA_STATE_LSO_RES_shf        14
 #define NFD_IN_DMA_STATE_LSO_RES_wrd        2
 #define NFD_IN_DMA_STATE_LSO_MSS_msk        0x3FFF
@@ -410,21 +410,23 @@ struct nfd_in_dma_state {
             unsigned int up:1;
             unsigned int cont:1;
             unsigned int locked:1;
             unsigned int sp0:5;
-            unsigned int lso_hdr_len:8; /* length of header and if we have a header
-                                         * non-zero used in issue_dma */
-            unsigned int lso_seq_cnt:8; /* last sequence count for lso segments sent
-                                           to NFP. Used in notify. */
+            unsigned int lso_offhdr:8;  /* length of offset + header
+                                           if zero indicates no header
+                                           in progress. Used in issue_dma */
+            unsigned int lso_seq_cnt:8; /* last sequence count for
+                                           lso segments sent to NFP.
+                                           Used in notify. */
             unsigned int rid:8;
 
             unsigned int invalid:1;
             unsigned int jumbo:1;
             unsigned int sp1:1;
             unsigned int curr_buf:29;
 
             unsigned int flags:8;       /* Original flags for the packet */
-            unsigned int l4_offset:8;   /* Original LSO l4_offset */
+            unsigned int lso_hdrlen:8;  /* Original LSO header len */
             unsigned int res:2;         /* Not tested for consistency */
             unsigned int mss:14;        /* Original LSO MSS */
 
             unsigned int offset:8;      /* Original TX desc offset (meta len) */
@@ -461,9 +463,9 @@ struct nfd_in_batch_desc {
  *    0  |E|    offset   | lso_issued_cnt|   num_batch   |sp1|   q_num   |
  *       +-+-------------+---------------+---------------+---+-----------+
  *    1  |                           buf_addr                            |
  *       +---------------+---------------+-+-+---------------------------+
- *    2  |     flags     |   l4_offset   |L|S|           mss             |
+ *    2  |     flags     |  lso_seq_cnt  |L|S|           mss             |
  *       +---------------+---------------+-+-+---------------------------+
  *    3  |            data_len           |              vlan             |
  *       +-------------------------------+-------------------------------+
  *
@@ -484,9 +486,9 @@ struct nfd_in_issued_desc {
 
             unsigned int buf_addr:32;
 
             unsigned int flags:8;
-            unsigned int l4_offset:8;
+            unsigned int lso_seq_cnt:8;
             unsigned int lso_end:1;
             unsigned int sp2:1;
             unsigned int mss:14;
 
diff --git a/me/dbg/nfd_dbg.c b/me/dbg/nfd_dbg.c
--- a/me/dbg/nfd_dbg.c
+++ b/me/dbg/nfd_dbg.c
@@ -414,10 +414,10 @@ int display_pci_in_dma_queue_status(stru
         printf("data_len:                %6x\n",
                _DMA_QUEUE_VAL(NFD_IN_DMA_STATE_DATA_LEN));
         printf("bytes_dmaed:          %10d | lso_payload_len:     %10d\n",
                status->bytes_dmaed, status->lso_payload_len);
-        printf("lso_hdr_len:                  %2x | ",
-               _DMA_QUEUE_VAL(NFD_IN_DMA_STATE_LSO_HDR_LEN));
+        printf("lso_offhdr:                   %2x | ",
+               _DMA_QUEUE_VAL(NFD_IN_DMA_STATE_LSO_OFFHDR));
         printf("lso_seq_cnt:                %3d\n",
                _DMA_QUEUE_VAL(NFD_IN_DMA_STATE_LSO_SEQ_CNT));
         printf("LSO word:               %08x\n",
                mem[NFD_IN_DMA_STATE_LSO_MSS_wrd]);
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498063022 -7200
# Node ID 3386a7335b1d239ebc2d206a34f65a9ce5403b2a
# Parent  c17a2565cf5ec3e22c70b6525b94d20ecebd67ba
[PCI.IN] Provide microC access to LSOv2 l3/l4 offsets
* Minor fixes and documentation changes to microcode APIs too

diff --git a/me/blocks/vnic/nfd_in.uc b/me/blocks/vnic/nfd_in.uc
--- a/me/blocks/vnic/nfd_in.uc
+++ b/me/blocks/vnic/nfd_in.uc
@@ -103,9 +103,9 @@
  *    1  |I|J|S|                       buf_addr                          |
  *       +-+-+-+---------+---------------+-+-+---------------------------+
  *    2  |     flags     |  lso_seq_cnt  |L|S|           mss             |
  *       +---------------+---------------+-+-+---------------------------+
- *    3  |            data_len           |       vlan [L3/L4 off]        |
+ *    3  |            data_len           |       vlan [L4/L3 off]        |
  *       +-------------------------------+-------------------------------+
  *
  *       Flag bits (31-24) expanded:
  *          31       30      29      28      27      26      25     24
@@ -148,10 +148,10 @@
 #define NFD_IN_LSO_END_fld      2, 15, 15
 #define NFD_IN_LSO_MSS_fld      2, 13, 0
 #define NFD_IN_DATALEN_fld      3, 31, 16
 #define NFD_IN_VLAN_fld         3, 15, 0
+#define NFD_IN_LSO2_L4_OFFS_fld 3, 15, 8
 #define NFD_IN_LSO2_L3_OFFS_fld 3, 7, 0
-#define NFD_IN_LSO2_L4_OFFS_fld 3, 15, 8
 #define NFD_IN_META_SIZE        16
 #define NFD_IN_META_SIZE_LW     4
 
 
diff --git a/me/blocks/vnic/pci_in.h b/me/blocks/vnic/pci_in.h
--- a/me/blocks/vnic/pci_in.h
+++ b/me/blocks/vnic/pci_in.h
@@ -195,9 +195,9 @@
  *    1  |                          dma_addr_lo                          |
  *       +---------------+---------------+---+---------------------------+
  *    2  |     flags     |   lso_hdrlen  |sp0|           mss             |
  *       +---------------+---------------+---|---------------------------+
- *    3  |           data_len            |              vlan             |
+ *    3  |           data_len            |        vlan [L4/L3 off]       |
  *       +-------------------------------+-------------------------------+
  *
  *      E -> End of packet
  */
@@ -219,10 +219,16 @@ struct nfd_in_tx_desc {
             unsigned int lso_hdrlen:8;  /**< LSO, TCP payload offset */
             unsigned int sp0:2;
             unsigned int mss:14;        /**< Info for Large Segment Offload */
 
-            unsigned int data_len:16;   /**< Length of the entire packet */
-            unsigned int vlan:16;       /**< VLAN to prepend to this packet */
+            unsigned short data_len;    /**< Length of the entire packet */
+            union {
+                struct {
+                    unsigned char l4_offset;    /**< LSO, L4 data start */
+                    unsigned char l3_offset;    /**< LSO, L3 data start */
+                };
+                unsigned short vlan;    /**< VLAN to prepend to this packet */
+            };
         };
         unsigned int __raw[4];          /**< Direct access to struct words */
     };
 };
@@ -238,9 +244,9 @@ struct nfd_in_tx_desc {
  *    1  |I|J|S|                       buf_addr                          |
  *       +-+-+-+---------+---------------+-+-+---------------------------+
  *    2  |     flags     |  lso_seq_cnt  |L|S|           mss             |
  *       +---------------+---------------+-+-+---------------------------+
- *    3  |            data_len           |              vlan             |
+ *    3  |            data_len           |       vlan [L4/L3 off]        |
  *       +-------------------------------+-------------------------------+
  *
  *    itf -> intf
  *    L -> Last packet in a series of LSO packets
@@ -270,10 +276,16 @@ struct nfd_in_pkt_desc {
             unsigned int lso_end:1;     /**< Last packet in a series of LSO packets */
             unsigned int sp1:1;         /**< Spare bit (unused) */
             unsigned int mss:14;        /**< Info for Large Segment Offload */
 
-            unsigned int data_len:16;   /**< Total packet length */
-            unsigned int vlan:16;       /**< VLAN to prepend to the packet */
+            unsigned short data_len;    /**< Length of the entire packet */
+            union {
+                struct {
+                    unsigned char l4_offset;    /**< LSO, L4 data start */
+                    unsigned char l3_offset;    /**< LSO, L3 data start */
+                };
+                unsigned short vlan;    /**< VLAN to prepend to this packet */
+            };
         };
         unsigned int __raw[4];          /**< Direct access to struct words */
     };
 };
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498063023 -7200
# Node ID 80d0103eae622f018bbf8bacda3c7bdc6e3256b3
# Parent  3386a7335b1d239ebc2d206a34f65a9ce5403b2a
[apps] Add uc version loopback app ME to loopback FW
* Provide an NFD test app that uses the microcode APIs

diff --git a/me/apps/loopback/Makefile.netro b/me/apps/loopback/Makefile.netro
--- a/me/apps/loopback/Makefile.netro
+++ b/me/apps/loopback/Makefile.netro
@@ -18,12 +18,12 @@ ng-nfd_loopback_LIST = \
 		mei1.me2:mei1_me2.c@$(ng-nfd_loopback_absdir)/loopback_main.c \
 		mei1.me3:mei1_me3.c@$(ng-nfd_loopback_absdir)/loopback_main.c \
 		mei1.me4:mei1_me4.c@$(ng-nfd_loopback_absdir)/loopback_main.c \
 		mei1.me5:mei1_me5.c@$(ng-nfd_loopback_absdir)/loopback_main.c \
-		mei4.me1:mei4_me1.c@$(ng-nfd_loopback_absdir)/loopback_main.c \
-		mei4.me2:mei4_me2.c@$(ng-nfd_loopback_absdir)/loopback_main.c \
-		mei4.me3:mei4_me3.c@$(ng-nfd_loopback_absdir)/loopback_main.c \
-		mei4.me4:mei4_me4.c@$(ng-nfd_loopback_absdir)/loopback_main.c \
+		mei4.me1:mei4_me1.uc@$(ng-nfd_loopback_absdir)/loopback_main.uc \
+		mei4.me2:mei4_me2.uc@$(ng-nfd_loopback_absdir)/loopback_main.uc \
+		mei4.me3:mei4_me3.uc@$(ng-nfd_loopback_absdir)/loopback_main.uc \
+		mei4.me4:mei4_me4.uc@$(ng-nfd_loopback_absdir)/loopback_main.uc \
 		mei4.me0:mei4_me0.c@$(ng-nfd_loopback_absdir)/app_master.c \
 		mei3.me2:mei3_me2.c@$(nfd_vnic_absdir)/svc_me.c \
 		mei3.me0:pcie0_sb.uc@$(nfd_vnic_absdir)/pci_out_sb.uc \
 		mei3.me3:pcie0_pd0.uc@$(nfd_vnic_absdir)/pci_out_pd.uc \
@@ -118,8 +118,9 @@ ng-nfd_loopback_NFCCFLAGS_common += \
 	-I$(nfp-sdk-stdlib-absdir)/microc/include
 
 ng-nfd_loopback_NFASFLAGS_common += $(ng-nfd_loopback_APPDEFS) \
 	-I$(ng-nfd_loopback_absdir) \
+	-I$(ng-nfd-me-blocks_absdir) \
 	-I$(nfd_vnic_absdir) \
 	-I$(nfd_vnic_absdir)/shared \
 	-I$(ng-nfd-shared_absdir) \
 	-I$(nfp-sdk-stdlib-absdir)/include \
@@ -235,19 +236,24 @@ ng-nfd_loopback_NFCCFLAGS_common_mei1_me
 
 ng-nfd_loopback_NFCCFLAGS_common_mei4_me0.c += \
 	-DPCIE_ISL=0
 
-ng-nfd_loopback_NFCCFLAGS_common_mei4_me1.c += \
-	-DPCIE_ISL=0
+ng-nfd_loopback_NFASFLAGS_common_mei4_me1.uc += \
+	-DPCIE_ISL=0 \
+	-I$(flowenv-me-include_absdir)
 
-ng-nfd_loopback_NFCCFLAGS_common_mei4_me2.c += \
-	-DPCIE_ISL=0
+ng-nfd_loopback_NFASFLAGS_common_mei4_me2.uc += \
+	-DPCIE_ISL=0 \
+	-I$(flowenv-me-include_absdir)
 
-ng-nfd_loopback_NFCCFLAGS_common_mei4_me3.c += \
-	-DPCIE_ISL=0
+ng-nfd_loopback_NFASFLAGS_common_mei4_me3.uc += \
+	-DPCIE_ISL=0 \
+	-I$(flowenv-me-include_absdir)
 
-ng-nfd_loopback_NFCCFLAGS_common_mei4_me4.c += \
-	-DPCIE_ISL=0
+ng-nfd_loopback_NFASFLAGS_common_mei4_me4.uc += \
+	-DPCIE_ISL=0 \
+	-I$(flowenv-me-include_absdir)
+
 
 
 # For generality, provide values for all PCIe islands,
 # even if not all are used.  User Makefiles only need to specify
diff --git a/me/apps/loopback/deps/pktutil.h b/me/apps/loopback/deps/pktutil.h
new file mode 100755
--- /dev/null
+++ b/me/apps/loopback/deps/pktutil.h
@@ -0,0 +1,357 @@
+/**
+ * Copyright (C) 2013-2015 Netronome Systems, Inc.  All rights reserved.
+ *
+ * File:        pktutil.uc
+ * Description: NBI ingress/egress macros, constants and utilities.
+ *
+ */
+
+#ifndef __PKTUTIL_H
+#define __PKTUTIL_H
+
+
+#ifndef PKT_NBI_OFFSET
+#warning "No PKT_NBI_OFFSET given: assuming 64 for NOP rewrite scripts"
+#define PKT_NBI_OFFSET 64
+#endif /* PKT_NBI_OFFSET */
+
+#ifndef INGRESS_MAC_PREPEND_BYTES
+#warning "No INGRESS_MAC_PREPEND_BYTES given; assuming 8"
+#define INGRESS_MAC_PREPEND_BYTES 8
+#endif
+
+/**
+ * Packet Metadata Format with Catamaran Pico Engine load:
+ * Bit    3 3 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
+ * -----\ 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0
+ * Word  +-----------+-------------------+---+---------------------------+
+ *    0  | CTM Number| Packet Number     |Bls|     Packet Length         |
+ *       +-+---+-----+-------------------+---+---------------------------+
+ *    1  |S|Rsv|                   MU Pointer                            |
+ *       +-+---+-------------------------+---+-----+-----+-+-----+-+-----+
+ *    2  |      Sequence Number          |NFP|  R  | Seq |P|MType|V| BP  |
+ *       +-------------------------+-+---+---+---+-+-----+-+-----+-+-----+
+ *    3  |        Reserved         |E|TLD|  OL4  |  OL3  |   OL2   |  R  |
+ *       +---------------+---------+-+---+---+---+-------+---------+-----+
+ *    4  |     Port      |    HP-Off1    |    HP-Off0    |     Misc      |
+ *       +-+-+-+-+-+-+-+-+---------------+---------------+---------------+
+ *    5  |P|I|P|S|Tag|I|T|     O-Off     |       LIF+Mode / Match        |
+ *    5  |E|E|W|p|Cnt|T|S|               |                               |
+ *       +-+-+-+-+-+-+-+-+---------------+-------------------------------+
+ *
+ *      S -> 1 if packet is split between CTM and MU data
+ *      Bls -> Buffer List
+ *
+ */
+
+/**
+ * Packet Metadata Format with null pico engine load
+ * Bit    3 3 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
+ * -----\ 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0
+ * Word  +-----------+-------------------+---+---------------------------+
+ *    0  | CTM Number| Packet Number     |Bls|     Packet Length         |
+ *       +-+---+-----+-------------------+---+---------------------------+
+ *    1  |S|Rsv|                   MU Pointer                            |
+ *       +-+---+-----+-------------------+-----+---------+---------------+
+ *    2  |           | Sequence Number   |     | SeqRNum |               |
+ *       +---+-------+-------------------+-----+---------+---------------+
+ *    3  |                      Preclass Meta 1                          |
+ *       +---------------------------------------------------------------+
+ *    4  |                      Preclass Meta 2                          |
+ *       +---------------------------------------------------------------+
+ *    5  |                      Preclass Meta 3                          |
+ *       +---------------------------------------------------------------+
+ *
+ *      NOTE that Word 2 is actually defined by the NBI load so it can
+ *      easily change with a different load.
+ *
+ *      S -> 1 if packet is split between CTM and MU data
+ *      Bls -> Buffer ListI
+ */
+
+
+#define PKT_META_CTM_NUM_wrd    0
+#define PKT_META_CTM_NUM_MSB    31
+#define PKT_META_CTM_NUM_LSB    26
+#define PKT_META_CTM_NUM_bf     0, 31, 26
+
+
+#define PKT_META_PKTNUM_WRD     0
+#define PKT_META_PKTNUM_MSB     25
+#define PKT_META_PKTNUM_LSB     16
+#define PKT_META_PKTNUM_bf      0, 25, 16
+
+#define PKT_META_BUFLIST_wrd    0
+#define PKT_META_BUFLIST_bf     0, 15, 14
+
+#define PKT_META_LEN_WRD        0
+#define PKT_META_LEN_MSB        13
+#define PKT_META_LEN_LSB        0
+#define PKT_META_LEN_bf         0, 13, 0
+
+#define PKT_META_SPLIT_WRD      1
+#define PKT_META_SPLIT_MSB      31
+#define PKT_META_SPLIT_LSB      31
+#define PKT_META_SPLIT_bf       1, 31, 31
+
+#define PKT_META_MUPTR_WRD      1
+#define PKT_META_MUPTR_MSB      28
+#define PKT_META_MUPTR_LSB      0
+#define PKT_META_MUPTR_bf       1, 28, 0
+
+
+#define PKT_META_SEQNUM_WRD     2
+#define PKT_META_SEQNUM_MSB     31
+#define PKT_META_SEQNUM_LSB     16
+#define PKT_META_SEQNUM_bf      2, 31, 16
+
+#define PKT_META_SEQER_WRD      2
+#define PKT_META_SEQER_MSB      10
+#define PKT_META_SEQER_LSB      8
+#define PKT_META_SEQER_bf       2, 10, 8
+
+#define PKT_META_MTYPE_VALID_bf     2,  6,  3 /**< PKT_META_MTYPE_bf + PKT_META_VALID_bit - if 0x8, picoengine data present and valid */
+#define PKT_META_MTYPE_bf           2,  6,  4 /**< Type of metadata - 0 for NBI 0, 1 for NBI 1, 2-7 TBD */
+#define PKT_META_MTYPE_UPPER_bf     2,  6,  5 /**< Type of metadata - upper 2 bits */
+#define PKT_META_MTYPE_NBI_ID_bf    2,  4,  4 /**< Type of metadata - shortend mask to get only NBI ID from metadata type */
+#define PKT_META_VALID_bf           2,  3,  3 /**< Metadata is valid if set */
+#define PKT_META_PORT_bf            4, 31, 24 /**< Physical port number */
+#define PKT_META_ERROR_bf           5, 31, 31 /**< Error encountered that picoengine could handle gracefully if set */
+#define PKT_META_LIL_bf             5, 15,  8 /**< LS 8 bits of 10-bit Logical Interface */
+#define PKT_META_LIH_bf             5,  1,  0 /**< MS 2 bits of 10-bit Logical Interface */
+#define PKT_META_MATCH_bf           5, 15,  0  /** < 16 bit MAC match index */
+
+/** Format of the packet_free_and_return_pointer MU pointer push.
+ * Bit    3 3 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
+ * -----\ 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0
+ * Word  +-------------------------------+-------------------------------+
+ *    0  |                            unused                             |
+ *       +-+---+---------------------------------------------------------+
+ *    1  |R|BL |                  29 bit MU pointer                      |
+ *       +-+---+---------------------------------------------------------+
+ */
+
+#define PKT_FREE_MUPTR_WRD      1
+#define PKT_FREE_MUPTR_MSB      28
+#define PKT_FREE_MUPTR_LSB      0
+#define PKT_FREE_MUPTR_bf       1, 28, 0
+
+#define PKT_FREE_BLIST_WRD      1
+#define PKT_FREE_BLIST_MSB      30
+#define PKT_FREE_BLIST_LSB      29
+#define PKT_FREE_BLIST_bf       1, 30, 29
+
+
+/**
+ * Packet number to address translation port format see MU packet engine EAS, table 2.29
+ * Bit    3 3 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
+ * -----\ 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0
+ * Word  +-+---------+-------------------+-------------------------------+
+ *    0  |E|Reserved |  Packet Number    |       Offset into Packet      |
+ *       +-+---------+-------------------+-------------------------------+
+ */
+#define PKT_ADDR_ENABLE_shf     31
+#define PKT_ADDR_ENABLE_msk     1
+#define PKT_ADDR_ENABLE_bit     31
+
+#define PKT_ADDR_PKTNUM_shf     16
+#define PKT_ADDR_PKTNUM_msk     0x1FF
+
+#define PKT_ADDR_OFFSET_shf     0
+#define PKT_ADDR_OFFSET_msk     0xFFFF
+
+
+/**
+ * Packet address format for transmission
+ *
+ * Bit  3 3 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
+ * ---\ 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0
+ * Wrd +-------------+-----------------+---+---------------------------+
+ *  0  |  Unused     |  Packet Number  |Rsv|       Packet Length       |
+ *     +-------------+-----------------+---+---------------------------+
+ *
+ * Bit  3 3 3 3 3 3 3 3
+ * ---\ 9 8 7 6 5 4 3 2
+ * Wrd +---------------+
+ *  1  |  Unused       |
+ *     +---------------+
+ *
+ * Note that the packet length MUST include the initial packet offset
+ * as well as the packet data.  But the value that comes in from NBI
+ * does not include this offset.
+ */
+#define PKT_READY_PKTNUM_shf    8
+#define PKT_READY_NBI_shf       30
+#define PKT_READY_IID_shf       24
+#define PKT_READY_DM_shf        20
+
+#define PKT_SEND_PKTNUM_shf     16
+#define PKT_SEND_PKTNUM_msk     0x1FF
+
+#define PKT_SEND_PKTLEN_shf     0
+#define PKT_SEND_PKTLEN_msk     0x3FFF
+
+
+/* Packet engine Data Reference overrides within the data_ref field */
+#define PE_SEND_DR_NBI_shf       12
+#define PE_SEND_DR_NBI_msk       0x3
+
+#define PE_SEND_DR_RETRY_shf     10
+#define PE_SEND_DR_RETRY_msk     1
+
+#define PE_SEND_DR_TXQ_shf       0
+#define PE_SEND_DR_TXQ_msk       0x3FF
+
+
+
+/**
+ * MAC packet metadata prepended to the packet
+ *
+ * NB:  this is not well documented in the DB.  Diagrams imply that the
+ * timestamp will follow the parse information.  That may be true
+ * internally in the MAC block.  But then the CSR description for
+ * IgPrependEn specifies that the timestamp will come first as does
+ * the "Ingress Timestamp" section indirectly when it says:
+ *   "When the EOP for the packet is received and the parsing is
+ *   complete and the timestamp prepend is enabled, the 32-bit
+ *   timestamp is written to the first 256-bit word of the packet at a
+ *   32-bit offset with TBD written at the 0 offset."
+ * Empirical analysis shows that, indeed, the timestamp comes first.
+ *
+ * Bit    3 3 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
+ * -----\ 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0
+ * Word  +---------------------------------------------------------------+
+ *    0  |                          Timestamp                            |
+ *       +-----+-+-+-+-+-+-+-+---+---+---+-------------------------------+
+ *    1  | CS  |M|E|A|F|D|R|H| L3|MPL|VLN|           Checksum            |
+ *       +-----+-+-+-+-+-+-+-+---+---+---+-------------------------------+
+ *
+ *   CS - Checksum status
+ *   M - IPv6 Mobility extension header detected
+ *   E - IPv6 ESP extsneion header detected
+ *   A - IPV6 AH extension header detected
+ *   F - IPv6 Fragment extension header detected
+ *   D - IPv6 Destination extension header detected
+ *   R - IPv6 Routing extension header detected
+ *   H - IPv6 Hop-by-Hop extension header detected
+ *   L3 - Layer 3 indication
+ *   MPL - MPLS indication
+ *   VLN - VLAN indication
+ */
+
+
+#define MAC_META_TIMESTAMP_bf           0, 31, 0
+#define MAC_META_TIMESTAMP_wrd          0
+#define MAC_META_TIMESTAMP_shf          0
+#define MAC_META_TIMESTAMP_msk          0xFFFFFFFF
+
+#define MAC_META_CSUM_STATUS_bf         1, 31, 29
+#define MAC_META_CSUM_STATUS_wrd        1
+#define MAC_META_CSUM_STATUS_shf        29
+#define MAC_META_CSUM_STATUS_msk        0x7
+
+#define MAC_META_CALC_CSUM_bf           1, 15, 0
+
+
+#define MAC_META_V6_MOBILITY_bf         1, 28, 28
+#define MAC_META_V6_MOBILITY_wrd        1
+#define MAC_META_V6_MOBILITY_shf        28
+#define MAC_META_V6_MOBILITY_msk        0x1
+
+#define MAC_META_V6_ESP_bf              1, 27, 27
+#define MAC_META_V6_ESP_wrd             1
+#define MAC_META_V6_ESP_shf             27
+#define MAC_META_V6_ESP_msk             0x1
+
+#define MAC_META_V6_AH_bf               1, 26, 26
+#define MAC_META_V6_AH_wrd              1
+#define MAC_META_V6_AH_shf              26
+#define MAC_META_V6_AH_msk              0x1
+
+#define MAC_META_V6_FRAG_bf             1, 25, 25
+#define MAC_META_V6_FRAG_wrd            1
+#define MAC_META_V6_FRAG_shf            25
+#define MAC_META_V6_FRAG_msk            0x1
+
+#define MAC_META_V6_DEST_OPT_bf         1, 24, 24
+#define MAC_META_V6_DEST_OPT_wrd        1
+#define MAC_META_V6_DEST_OPT_shf        24
+#define MAC_META_V6_DEST_OPT_msk        0x1
+
+#define MAC_META_V6_ROUTE_OPT_bf        1, 23, 23
+#define MAC_META_V6_ROUTE_OPT_wrd       1
+#define MAC_META_V6_ROUTE_OPT_shf       23
+#define MAC_META_V6_ROUTE_OPT_msk       0x1
+
+#define MAC_META_V6_HOPBYHOP_OPT_bf     1, 22, 22
+#define MAC_META_V6_HOPBYHOP_OPT_wrd    1
+#define MAC_META_V6_HOPBYHOP_OPT_shf    22
+#define MAC_META_V6_HOPBYHOP_OPT_msk    0x1
+
+#define MAC_META_L3_INFO_bf             1, 21, 20
+#define MAC_META_L3_INFO_wrd            1
+#define MAC_META_L3_INFO_shf            20
+#define MAC_META_L3_INFO_msk            0x3
+
+#define MAC_META_MPLS_INFO_bf           1, 19, 18
+#define MAC_META_MPLS_INFO_wrd          1
+#define MAC_META_MPLS_INFO_shf          18
+#define MAC_META_MPLS_INFO_msk          0x3
+
+#define MAC_META_VLAN_INFO_bf           1, 17, 16
+#define MAC_META_VLAN_INFO_wrd          1
+#define MAC_META_VLAN_INFO_shf          16
+#define MAC_META_VLAN_INFO_msk          0x3
+
+#define MAC_META_CSUM_bf                1, 15, 0
+#define MAC_META_CSUM_wrd               1
+#define MAC_META_CSUM_shf               0
+#define MAC_META_CSUM_msk               0xFFFF
+
+#define MAC_CSUM_STATUS_UNKNOWN         0
+#define MAC_CSUM_STATUS_ESP             1
+#define MAC_CSUM_STATUS_TCP_SUMOK       2
+#define MAC_CSUM_STATUS_TCP_SUMFAIL     3
+#define MAC_CSUM_STATUS_UDP_SUMOK       4
+#define MAC_CSUM_STATUS_UDP_SUMFAIL     5
+#define MAC_CSUM_STATUS_AH              6
+#define MAC_CSUM_STATUS_FRAG            7
+
+#define MAC_L3_INFO_UNKNOWN             0
+#define MAC_L3_INFO_IPV6                1
+#define MAC_L3_INFO_IPV4_SUMFAIL        2
+#define MAC_L3_INFO_IPV4_SUMOK          3
+
+#define MAC_MPLS_INFO_NONE              0
+#define MAC_MPLS_INFO_1_LABLE           1
+#define MAC_MPLS_INFO_2_LABLE           2
+#define MAC_MPLS_INFO_3PLUS_LABLE       3
+
+#define MAC_VLAN_INFO_NONE              0
+#define MAC_VLAN_INFO_1_TAG             1
+#define MAC_VLAN_INFO_2_TAG             2
+#define MAC_VLAN_INFO_3PLUS_TAG         3
+
+#define MAC_EGR_CMD_L3_CSUM_EN_shf      31
+#define MAC_EGR_CMD_L3_CSUM_EN          (1 << MAC_EGR_CMD_L3_CSUM_EN_shf)
+#define MAC_EGR_CMD_L4_CSUM_EN_shf      30
+#define MAC_EGR_CMD_L4_CSUM_EN          (1 << MAC_EGR_CMD_L4_CSUM_EN_shf)
+
+/*
+ * Packet Metadata Format
+ * Bit    3 3 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
+ * -----\ 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0
+ * Word  +---------------------------------------------------------------+
+ *    0  |                        Output Port                            |
+ *       +---------------------------------------------------------------+
+ *    1  |                         Reserved                              |
+ *       +---------------------------------------------------------------+
+ */
+
+#define NFP_NET_PREPEND_META_SIZE_LW    2
+#define NFP_NET_PREPEND_META_SIZE       8
+#define NFP_NET_TX_META_OUT_PORT_fld    0, 31, 0
+
+
+#endif /* __PKTUTIL_H */
+
diff --git a/me/apps/loopback/loopback_main.uc b/me/apps/loopback/loopback_main.uc
new file mode 100644
--- /dev/null
+++ b/me/apps/loopback/loopback_main.uc
@@ -0,0 +1,482 @@
+/*
+ * Copyright (C) 2014 Netronome Systems, Inc.  All rights reserved.
+ *
+ * @file          blocks/vnic/dummy_loopback_me.uc
+ * @brief         Dummy code to loopback PCI.IN to PCI.OUT
+ */
+
+/* NB: This code enqueues one thread per PCI.IN work queue and returns
+ * packets received on each work queue to PCI.OUT, via the same queue
+ * that they were received on.
+ *
+ * As there is no ordering between PCI.IN work queues, and by allocating
+ * just one thread per work queue each work queue is implicitly ordered,
+ * no explicit ordering is performed in this code. */
+
+
+#include <aggregate.uc>
+#include <bitfields.uc>
+#include <stdmac.uc>
+#include <timestamp.uc>
+
+#include <nfd_user_cfg.h>
+
+#include <nfp6000/nfp_me.h>
+
+#include <deps/pktutil.h>
+
+#include <vnic/nfd_common.uc>
+#include <vnic/nfd_in.uc>
+#include <vnic/nfd_out.uc>
+
+
+#ifndef DUMMY_LOOPBACK_WQ
+#define DUMMY_LOOPBACK_WQ   0
+#endif
+
+
+
+/* XXX variables that app and/or BLM should expose */
+.declare_resource BLQ_EMU_RINGS global 4 emem0_queues+4
+.alloc_resource BLM_NBI8_BLQ0_EMU_QID BLQ_EMU_RINGS+0 global 1
+#define APP_BLM_RADDR __ADDR_EMEM0
+
+/* Must be 256/512/1024/2048 ONLY */
+#define CTM_PACKET_SIZE     512
+#define CTM_PACKET_SIZE_VAL (log2(CTM_PACKET_SIZE >> 8))
+
+#define NO_CREDIT_SLEEP         256
+#define NO_BUF_SLEEP            256
+#define COPY_CHUNK              64
+
+#define PCI_IN_LM_CTX           2
+#define PCI_OUT_LM_CTX          2
+
+#define MEM_CNTR_SZ             4
+.alloc_mem _ndown_drop/**/PCIE_ISL emem global \
+    (NFD_OUT_MAX_QUEUES * MEM_CNTR_SZ) (NFD_OUT_MAX_QUEUES * MEM_CNTR_SZ)
+.alloc_mem _ninv_drop/**/PCIE_ISL emem global \
+    (NFD_OUT_MAX_QUEUES * MEM_CNTR_SZ) (NFD_OUT_MAX_QUEUES * MEM_CNTR_SZ)
+
+
+
+#macro ctm_addr_hi(out_addr_hi, in_isl, in_pnum)
+.begin
+    move(out_addr_hi, 0x80800000)
+    alu[out_addr_hi, out_addr_hi, or, in_isl, <<24]
+    alu[out_addr_hi, out_addr_hi, or, in_pnum, <<8]
+.end
+#endm
+
+
+#macro mu_addr_hi(out_addr_hi, in_mubuf)
+    alu[out_addr_hi, --, b, in_mubuf, <<(11 - 8)]
+#endm
+
+
+#macro cp_ctm_data(in_ctm_base, in_mu_base, in_start, in_max_bytes, in_len)
+.begin
+    .reg read $data_rd[(COPY_CHUNK / 4)]
+    .xfer_order $data_rd
+    .reg write $data_wr[(COPY_CHUNK / 4)]
+    .xfer_order $data_wr
+    .sig cp_sig
+    .reg offset end_offset count
+
+    move(end_offset, in_max_bytes)
+    .if (in_len < in_max_bytes)
+        move(end_offset, in_len)
+    .endif
+    alu[end_offset, end_offset, +, in_start]
+
+    move(offset, in_start)
+    .while (offset < end_offset)
+        mem[read, $data_rd[0], in_mu_base, <<8, offset, (COPY_CHUNK / 8)],
+            ctx_swap[cp_sig]
+        aggregate_copy($data_wr, $data_rd, (COPY_CHUNK / 4))
+        mem[write, $data_wr[0], in_ctm_base, <<8, offset, (COPY_CHUNK / 8)],
+            ctx_swap[cp_sig]
+        alu[offset, offset, +, COPY_CHUNK]
+    .endw
+
+.end
+#endm
+
+
+#macro get_ctm_buf(out_ctm_buf,  PKT_SZ_VAL, SIGNAL, SIGTYPE)
+.begin
+
+    .reg addr_hi
+
+    move(addr_hi, 0)
+
+    #if (!strstr(out_ctm_buf, $))
+        #error "get_ctm_buf: out_ctm_buf must be xfer reg: " out_ctm_buf
+    #endif
+
+    #if (streq('SIGTYPE', 'SIG_DONE'))
+        alu[--, --, b, ((PKT_SZ_VAL << 1) | 1),
+            <<NFP_MECSR_PREV_ALU_OV_LEN_bit]
+        mem[packet_alloc_poll, out_ctm_buf, addr_hi, 0, 1], indirect_ref,
+            sig_done[SIGNAL]
+    #elif (streq('SIGTYPE', 'SIG_WAIT'))
+        alu[--, --, b, ((PKT_SZ_VAL << 1) | 1),
+            <<NFP_MECSR_PREV_ALU_OV_LEN_bit]
+        mem[packet_alloc_poll, out_ctm_buf, addr_hi, 0, 1], indirect_ref,
+            ctx_swap[SIGNAL]
+    #else
+        #error "Unknown signal handling type"
+    #endif
+
+.end
+#endm
+
+
+#macro drop_pkt(in_pkt_info)
+.begin
+    .reg isl pnum bls muptr
+    .reg rnum addr_hi
+
+    bitfield_extract__sz1(isl, BF_AML(in_pkt_info, PKT_META_CTM_NUM_bf))
+    .if (isl != 0)
+        bitfield_extract(pnum, BF_AML(in_pkt_info, PKT_META_PKTNUM_bf))
+
+        alu[isl, isl, or, 0x80]
+        alu[isl, --, b, isl, <<24]
+        mem[packet_free, --, isl, <<8, pnum]
+    .endif
+
+    move(addr_hi, (APP_BLM_RADDR >> 8))
+
+    bitfield_extract__sz1(bls, BF_AML(in_pkt_info, PKT_META_BUFLIST_bf))
+    bitfield_extract__sz1(muptr, BF_AML(in_pkt_info, PKT_META_MUPTR_bf))
+
+    alu[rnum, BLM_NBI8_BLQ0_EMU_QID, +, bls]
+    alu[--, NFP_MECSR_PREV_ALU_OVE_DATA(1), or, rnum,
+        <<NFP_MECSR_PREV_ALU_DATA16_shift]
+    mem[fast_journal, --, addr_hi, <<8, muptr], indirect_ref
+
+.end
+#endm
+
+
+#macro _get_bar_addr(out_hi, out_lo, in_vnic)
+.begin
+
+    .reg tmp_lo
+    .reg off
+
+    move(out_hi, ((nfd_cfg_base/**/PCIE_ISL >> 8) & 0xFF000000))
+    move(tmp_lo, (nfd_cfg_base/**/PCIE_ISL & 0xFFFFFFFF))
+    alu[off, --, B, in_vnic, <<(log2(NFP_NET_CFG_BAR_SZ))]
+    alu[out_lo, tmp_lo, +, off]
+
+.end
+#endm
+
+
+#macro test_enable(in_vnic, in_queue, DOWN_TGT)
+.begin
+    .reg addr_hi addr_lo_base addr_lo
+    .reg read $enables
+    .sig rd_sig
+
+    _get_bar_addr(addr_hi, addr_lo_base, in_vnic)
+
+    /* Check global enable */
+    alu[addr_lo, addr_lo_base, +, NFP_NET_CFG_CTRL]
+    mem[read32, $enables, addr_hi, <<8, addr_lo, 1], ctx_swap[rd_sig]
+
+    br_bclr[$enables, log2(NFP_NET_CFG_CTRL_ENABLE), DOWN_TGT]
+
+    /* Check per ring enable */
+    alu[addr_lo, addr_lo_base, +, NFP_NET_CFG_RXRS_ENABLE]
+    .if (in_queue & 32)
+        alu[addr_lo, addr_lo, +, 4]
+    .endif
+    mem[read32, $enables, addr_hi, <<8, addr_lo, 1], ctx_swap[rd_sig]
+
+    alu[--, in_queue, b, 0]
+    alu[--, 1, and, $enables, >>indirect]
+    beq[DOWN_TGT]
+
+    /* Fall through, queue is up */
+.end
+#endm
+
+
+#macro inc_cntr(io_cntr)
+    alu[io_cntr[0], io_cntr[0], +, 1]
+    alu[io_cntr[1], io_cntr[1], +carry, 0]
+#endm
+
+#macro show_cntr(in_cntr, MBOX_START)
+    #define_eval _MBOX (MBOX_START + 1)
+    local_csr_wr[Mailbox/**/MBOX_START, in_cntr[1]]
+    local_csr_wr[Mailbox/**/_MBOX, in_cntr[0]]
+    #undef _MBOX
+#endm
+
+#macro inc_mem_cntr(in_queue, CNTR_NAME)
+.begin
+    .reg addr_lo addr_hi cntr_off
+
+    move(addr_hi, ((CNTR_NAME >> 8) & 0xff000000))
+    move(addr_lo, (CNTR_NAME & 0xffffffff))
+
+    alu[cntr_off, --, b, in_queue, <<(log2(MEM_CNTR_SZ))]
+    alu[addr_lo, addr_lo, +, cntr_off]
+
+    mem[incr, --, addr_hi, <<8, addr_lo]
+
+.end
+#endm
+
+nfd_in_recv_init()
+nfd_out_send_init()
+
+main#:
+    .reg start_lock
+    .sig get_sig get_order_sig
+    .sig credit_sig credit_order_sig
+    .sig send_sig send_order_sig
+
+    .reg @nrecv[2]
+    .reg @nsent[2]
+
+    .reg read $nfd_in_meta[NFD_IN_META_SIZE_LW]
+    .xfer_order $nfd_in_meta
+    .reg nfd_out_desc[NFD_OUT_DESC_SIZE_LW]
+    .reg write $nfd_out_desc_wr[NFD_OUT_DESC_SIZE_LW]
+    .xfer_order $nfd_out_desc_wr
+
+    .reg pkt_info[2]
+    .reg qid
+    .reg is_pf vnic queue
+    .reg $credit
+    .reg ctm_isl ctm_pnum pkt_len meta_len
+    .reg muptr bls
+
+#ifndef LOOPBACK_MU_ONLY
+    .reg read $ctm_buf
+    .reg ctm_addr mu_addr
+    .sig ctm_buf_sig ctm_order_sig
+#endif
+
+    .if (ctx() == 0)
+        /* Kick off ordering */
+        local_csr_wr[SAME_ME_SIGNAL,
+                     (NFP_MECSR_SAME_ME_SIGNAL_CTX(0) |
+                      NFP_MECSR_SAME_ME_SIGNAL_SIG_NO(&get_order_sig))]
+        .set_sig get_order_sig
+        local_csr_wr[SAME_ME_SIGNAL,
+                     (NFP_MECSR_SAME_ME_SIGNAL_CTX(0) |
+                      NFP_MECSR_SAME_ME_SIGNAL_SIG_NO(&credit_order_sig))]
+        .set_sig credit_order_sig
+        local_csr_wr[SAME_ME_SIGNAL,
+                     (NFP_MECSR_SAME_ME_SIGNAL_CTX(0) |
+                      NFP_MECSR_SAME_ME_SIGNAL_SIG_NO(&send_order_sig))]
+        .set_sig send_order_sig
+        local_csr_wr[SAME_ME_SIGNAL,
+                     (NFP_MECSR_SAME_ME_SIGNAL_CTX(0) |
+                      NFP_MECSR_SAME_ME_SIGNAL_SIG_NO(&ctm_order_sig))]
+        .set_sig ctm_order_sig
+
+        /* Clear the manual delay flag */
+        local_csr_wr[Mailbox3, 0] /* Ensure usage shadow */
+
+        /* Clear counters */
+        local_csr_wr[Mailbox0, 0]
+        local_csr_wr[Mailbox1, 0]
+        local_csr_wr[Mailbox2, 0]
+
+        move(@nsent[0], 0)
+        move(@nsent[1], 0)
+        move(@nrecv[0], 0)
+        move(@nrecv[1], 0)
+
+    .else
+
+        .set_sig get_order_sig
+        .set_sig credit_order_sig
+        .set_sig send_order_sig
+        .set_sig ctm_order_sig
+
+    .endif
+
+    /* Manual delay to allow work queues
+     * to become configured! */
+    local_csr_rd[Mailbox3]
+    immed[start_lock, 0]
+    .while (start_lock == 0)
+        local_csr_rd[Mailbox3]
+        immed[start_lock, 0]
+    .endw
+
+    /* Reorder before starting the work loop */
+        ctx_arb[send_order_sig], all
+        local_csr_wr[SAME_ME_SIGNAL,
+                     (NFP_MECSR_SAME_ME_SIGNAL_NEXT_CTX |
+                      NFP_MECSR_SAME_ME_SIGNAL_SIG_NO(&send_order_sig))]
+        .set_sig send_order_sig
+
+    .while (1)
+        nfd_in_recv($nfd_in_meta, PCIE_ISL, DUMMY_LOOPBACK_WQ, PCI_IN_LM_CTX,
+                    get_sig, SIG_DONE)
+        ctx_arb[get_sig, get_order_sig], all
+        local_csr_wr[SAME_ME_SIGNAL,
+                     (NFP_MECSR_SAME_ME_SIGNAL_NEXT_CTX |
+                      NFP_MECSR_SAME_ME_SIGNAL_SIG_NO(&get_order_sig))]
+        .set_sig get_order_sig
+
+        inc_cntr(@nrecv)
+        show_cntr(@nrecv, 0)
+
+        nfd_in_pkt_meta(pkt_info, $nfd_in_meta)
+
+        nfd_in_get_qid(qid, $nfd_in_meta)
+
+        nfd_q_extract(is_pf, vnic, queue, qid)
+
+        /* Pick loopback queue and vNIC */
+#ifdef LOOPBACK_FLIP_QUEUE
+        alu[queue, queue, xor, 1]
+#endif
+#ifdef LOOPBACK_FLIP_VNIC
+
+        alu[vnic, vnic, xor, 1]
+
+        /* Mask queue into the range of queues supported */
+        .if (is_pf)
+            alu[queue, queue, and, (NFD_MAX_PF_QUEUES - 1)]
+        .else
+            alu[queue, queue, and, (NFD_MAX_VF_QUEUES - 1)]
+        .endif
+#endif
+
+        /* PCI.OUT transmit */
+        nfd_build_q(qid, is_pf, vnic, queue)
+
+        /* Get a credit, this does not need to be ordered provided that
+         * the number of credits that PCI.OUT issues per queue is
+         * much greater than the number of worker contexts */
+        nfd_out_get_credits($credit, PCIE_ISL, qid, 1, credit_sig, SIG_WAIT)
+        .while ($credit == 0)
+
+            test_enable(vnic, queue, queue_down_cont#)
+
+            /* Throttle credit polling
+             * XXX timestamp_sleep accepts ticks */
+            #define_eval _SLEEP_TICKS (NO_CREDIT_SLEEP / 16)
+            timestamp_sleep(_SLEEP_TICKS)
+            #undef _SLEEP_TICKS
+
+            nfd_out_get_credits($credit, PCIE_ISL, qid, 1, credit_sig,
+                                SIG_WAIT)
+        .endw
+    queue_down_cont#:
+
+        /* Reorder on exit */
+        .if (!SIGNAL(credit_order_sig))
+            ctx_arb[credit_order_sig]
+        .endif
+        local_csr_wr[SAME_ME_SIGNAL,
+                     (NFP_MECSR_SAME_ME_SIGNAL_NEXT_CTX |
+                      NFP_MECSR_SAME_ME_SIGNAL_SIG_NO(&credit_order_sig))]
+        .set_sig credit_order_sig
+
+
+        nfd_in_get_metalen(meta_len, $nfd_in_meta)
+        bitfield_extract(pkt_len, BF_AML(pkt_info, PKT_META_LEN_bf))
+        bitfield_extract(muptr, BF_AML(pkt_info, PKT_META_MUPTR_bf))
+        bitfield_extract(bls, BF_AML(pkt_info, PKT_META_BUFLIST_bf))
+
+
+#ifndef LOOPBACK_MU_ONLY
+        /* Delay allocating the CTM buffer until we know we have
+         * a PCI.OUT credit.  This means we are unlikely to leave
+         * CTM buffers used if the host app is killed or crashes. */
+
+        /* TODO copy packet into CTM buffer */
+        get_ctm_buf($ctm_buf,  CTM_PACKET_SIZE_VAL, ctm_buf_sig, SIG_WAIT)
+        .while ($ctm_buf < 0)
+            /* Throttle PE polling
+             * XXX timestamp_sleep accepts ticks */
+            #define_eval _SLEEP_TICKS (NO_BUF_SLEEP / 16)
+            timestamp_sleep(_SLEEP_TICKS)
+            #undef _SLEEP_TICKS
+            get_ctm_buf($ctm_buf,  CTM_PACKET_SIZE_VAL, ctm_buf_sig, SIG_WAIT)
+        .endw
+
+        move(ctm_isl, __ISLAND)
+        bits_set__sz1(BF_AL(pkt_info, PKT_META_CTM_NUM_bf), ctm_isl)
+        immed[ctm_pnum, 0x3ff]
+        alu[ctm_pnum, ctm_pnum, and, $ctm_buf, >>20]
+        bits_set__sz1(BF_AL(pkt_info, PKT_META_PKTNUM_bf), ctm_pnum)
+
+        .if (pkt_len > (CTM_PACKET_SIZE - NFD_IN_DATA_OFFSET))
+            bits_set__sz1(BF_AL(pkt_info, PKT_META_SPLIT_bf), 1)
+        .endif
+
+        ctm_addr_hi(ctm_addr, ctm_isl, ctm_pnum)
+        mu_addr_hi(mu_addr, muptr)
+        cp_ctm_data(ctm_addr, mu_addr, NFD_IN_DATA_OFFSET,
+                    (CTM_PACKET_SIZE - NFD_IN_DATA_OFFSET), pkt_len)
+
+        /* Reorder on exit */
+        .if (!SIGNAL(ctm_order_sig))
+            ctx_arb[ctm_order_sig]
+        .endif
+        local_csr_wr[SAME_ME_SIGNAL,
+                     (NFP_MECSR_SAME_ME_SIGNAL_NEXT_CTX |
+                      NFP_MECSR_SAME_ME_SIGNAL_SIG_NO(&ctm_order_sig))]
+        .set_sig ctm_order_sig
+
+#else /* MU only */
+    move(ctm_isl, 0)
+    move(ctm_pnum, 0)
+#endif
+
+        /* Return the packet */
+        .if ($credit != 0)
+
+            .if (!BIT(BF_AL($nfd_in_meta, NFD_IN_INVALID_fld)))
+
+                nfd_out_fill_desc(nfd_out_desc, ctm_isl, ctm_pnum,
+                                  CTM_PACKET_SIZE_VAL, bls, muptr,
+                                  NFD_IN_DATA_OFFSET,
+                                  pkt_len, meta_len)
+
+                nfd_out_send($nfd_out_desc_wr, nfd_out_desc, PCIE_ISL, qid,
+                             PCI_OUT_LM_CTX, send_sig, SIG_DONE)
+
+                ctx_arb[send_sig, send_order_sig]
+                inc_cntr(@nsent)
+
+            .else
+                /* Drop the packet as invalid
+                 * This is relatively late to test (ideally we would test
+                 * and drop immediately after receiving) but with the strictly
+                 * ordered execution model it is easier to drop later. */
+                drop_pkt(pkt_info)
+                inc_mem_cntr(qid, _ninv_drop/**/PCIE_ISL)
+                ctx_arb[send_order_sig]
+
+            .endif
+
+        .else
+            /* Drop and count the packet then participate in ordering */
+            drop_pkt(pkt_info)
+            inc_mem_cntr(qid, _ndown_drop/**/PCIE_ISL)
+            ctx_arb[send_order_sig]
+
+        .endif
+
+        local_csr_wr[SAME_ME_SIGNAL,
+                     (NFP_MECSR_SAME_ME_SIGNAL_NEXT_CTX |
+                      NFP_MECSR_SAME_ME_SIGNAL_SIG_NO(&send_order_sig))]
+        .set_sig send_order_sig
+
+        show_cntr(@nsent, 2)
+
+    .endw
\ No newline at end of file
diff --git a/me/apps/loopback/nfd_user_cfg.h b/me/apps/loopback/nfd_user_cfg.h
--- a/me/apps/loopback/nfd_user_cfg.h
+++ b/me/apps/loopback/nfd_user_cfg.h
@@ -131,5 +131,8 @@
 #define NFD_OUT_RING_SZ         (2 * 16 * 64 * 256)
 
 #define NFD_OUT_RX_OFFSET       NFP_NET_RX_OFFSET
 
+#define PKT_NBI_OFFSET          64
+#define INGRESS_MAC_PREPEND_BYTES   8
+
 #endif /* !_BLOCKS__VNIC_PCI_IN_H_ */
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498133713 -7200
# Node ID 3bd05ddd65517fd09e276c4b0ac6faf0b967904b
# Parent  80d0103eae622f018bbf8bacda3c7bdc6e3256b3
[cfg] Define a user settable _pfX_net_app_id
* NFD_NET_APP_ID can be defined by the developer to set the type advertised
* This changeset supports a new app ID feature in the driver
* Firmwares that define NFD_NET_APP_ID will automatically use ABI 5.x instead
  of ABI 4.x to ensure the host driver inspects the app_id

diff --git a/docs/ABI b/docs/ABI
--- a/docs/ABI
+++ b/docs/ABI
@@ -93,5 +93,10 @@ indicate that the firmware is able to up
 time, not just as part of the NFP_NET_CFG_CTRL_ENABLE /
 NFP_NET_CFG_UPDATE_GEN updates.
 
 NFP_NET_CFG_UPDATE_MACADDR indicates an update to the
-MAC address while up.
\ No newline at end of file
+MAC address while up.
+
+5.0:
+
+Advertise _pf##_isl##_net_app_id rtsym to notify host of advanced firmware
+capabilities.  Minor ABI versions are as for 4.x ABIs.
\ No newline at end of file
diff --git a/me/apps/loopback/nfd_user_cfg.h b/me/apps/loopback/nfd_user_cfg.h
--- a/me/apps/loopback/nfd_user_cfg.h
+++ b/me/apps/loopback/nfd_user_cfg.h
@@ -38,8 +38,10 @@
 #ifndef NFD_MAX_PFS
 #define NFD_MAX_PFS       NFD_MAX_PFS_DEFAULT
 #endif
 
+#define NFD_NET_APP_ID      10 * 5
+
 #define NFD_OUT_FL_BUFS_PER_QUEUE       1024
 
 #if defined(__NFP_LANG_ASM)
     #if __NFP_HAS_ISLAND("pcie0")
diff --git a/me/blocks/vnic/nfd_common.h b/me/blocks/vnic/nfd_common.h
--- a/me/blocks/vnic/nfd_common.h
+++ b/me/blocks/vnic/nfd_common.h
@@ -34,9 +34,14 @@
 /* NFD version numbers.  Increment major version number for each incompatible
  * ABI change.  Increment minor version number for each compatible ABI change
  * (e.g. a new feature flag).  Reset minor version number to zero for each
  * major version number change. */
+#ifdef NFD_NET_APP_ID
+/* Firmwares that advertise an app_id must advertise ABI 5 */
+#define NFD_CFG_MAJOR               5
+#else
 #define NFD_CFG_MAJOR               4
+#endif
 #define NFD_CFG_MINOR               4
 #define NFD_CFG_CLASS_DEFAULT       0
 
 /* Version number helper defines */
diff --git a/me/blocks/vnic/pci_in_me0.c b/me/blocks/vnic/pci_in_me0.c
--- a/me/blocks/vnic/pci_in_me0.c
+++ b/me/blocks/vnic/pci_in_me0.c
@@ -48,8 +48,13 @@ NFD_INIT_DONE_DECLARE;
 NFD_CFG_PF_DECLARE(PCIE_ISL);
 
 struct nfd_cfg_msg cfg_msg;
 
+
+/* Setup _pf%d_net_app_id */
+NFD_NET_APP_ID_DECLARE(PCIE_ISL);
+
+
 int
 main(void)
 {
     /*
diff --git a/me/blocks/vnic/shared/nfd_cfg_internal.c b/me/blocks/vnic/shared/nfd_cfg_internal.c
--- a/me/blocks/vnic/shared/nfd_cfg_internal.c
+++ b/me/blocks/vnic/shared/nfd_cfg_internal.c
@@ -143,8 +143,20 @@ NFD_CFG_RINGS_INIT(3);
 
 #define NFD_CFG_PF_DECLARE(_isl) NFD_CFG_PF_DECLARE_IND(_isl)
 
 
+#ifdef NFD_NET_APP_ID
+#define NFD_NET_APP_ID_DECLARE_IND(_isl) \
+    _NFP_CHIPRES_ASM(.alloc_mem _pf##_isl##_net_app_id ctm global 8 8) \
+    _NFP_CHIPRES_ASM(.init _pf##_isl##_net_app_id+0 (NFD_NET_APP_ID))
+#else
+#define NFD_NET_APP_ID_DECLARE_IND(_isl)
+#endif
+
+#define NFD_NET_APP_ID_DECLARE(_isl) NFD_NET_APP_ID_DECLARE_IND(_isl)
+
+
+
 /* /\* XXX temp defines that loosely match the BSP pcie_monitor_api.h *\/ */
 /* #define NFP_PCIEX_COMPCFG_CNTRLR3                            0x0010006c */
 /* #define NFP_PCIEX_COMPCFG_CNTRLR3_VF_FLR_DONE_CHANNEL_msk    0x3f */
 /* #define NFP_PCIEX_COMPCFG_CNTRLR3_VF_FLR_DONE_CHANNEL_shf    16 */
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498133719 -7200
# Node ID a611473bd9972034df79c7fa56ea5111f4a37ff5
# Parent  3bd05ddd65517fd09e276c4b0ac6faf0b967904b
[cfg] Move nfd_cfg_pf_bars.uc to nfd_cfg.uc API
* Move some functionality from pci_out_sb.uc to the new API file
* Previously NFD did not have a proper uc API for configuration, so
  pci_out_sb.uc implemented as much as it needed and used a legacy file
  nfd_cfg_pf_bars.uc for symbol names.  In preparation for the CTRL vNIC,
  create a formal uc configuration API.

diff --git a/me/apps/loopback/app_master.c b/me/apps/loopback/app_master.c
--- a/me/apps/loopback/app_master.c
+++ b/me/apps/loopback/app_master.c
@@ -10,8 +10,9 @@
 #include <nfp_chipres.h>
 
 #include <nfp/me.h>
 #include <nfp/mem_bulk.h>
+#include <nfp/mem_ring.h>
 
 #include <nfp6000/nfp_me.h>
 
 #include <vnic/shared/nfd_cfg.h>
diff --git a/me/apps/loopback/loopback_main.uc b/me/apps/loopback/loopback_main.uc
--- a/me/apps/loopback/loopback_main.uc
+++ b/me/apps/loopback/loopback_main.uc
@@ -27,8 +27,9 @@
 
 #include <vnic/nfd_common.uc>
 #include <vnic/nfd_in.uc>
 #include <vnic/nfd_out.uc>
+#include <vnic/shared/nfd_cfg.uc>
 
 
 #ifndef DUMMY_LOOPBACK_WQ
 #define DUMMY_LOOPBACK_WQ   0
@@ -159,30 +160,15 @@
 .end
 #endm
 
 
-#macro _get_bar_addr(out_hi, out_lo, in_vnic)
-.begin
-
-    .reg tmp_lo
-    .reg off
-
-    move(out_hi, ((nfd_cfg_base/**/PCIE_ISL >> 8) & 0xFF000000))
-    move(tmp_lo, (nfd_cfg_base/**/PCIE_ISL & 0xFFFFFFFF))
-    alu[off, --, B, in_vnic, <<(log2(NFP_NET_CFG_BAR_SZ))]
-    alu[out_lo, tmp_lo, +, off]
-
-.end
-#endm
-
-
 #macro test_enable(in_vnic, in_queue, DOWN_TGT)
 .begin
     .reg addr_hi addr_lo_base addr_lo
     .reg read $enables
     .sig rd_sig
 
-    _get_bar_addr(addr_hi, addr_lo_base, in_vnic)
+    nfd_cfg_get_bar_addr(addr_hi, addr_lo_base, in_vnic, PCIE_ISL)
 
     /* Check global enable */
     alu[addr_lo, addr_lo_base, +, NFP_NET_CFG_CTRL]
     mem[read32, $enables, addr_hi, <<8, addr_lo, 1], ctx_swap[rd_sig]
diff --git a/me/blocks/vnic/nfd_common.uc b/me/blocks/vnic/nfd_common.uc
--- a/me/blocks/vnic/nfd_common.uc
+++ b/me/blocks/vnic/nfd_common.uc
@@ -22,10 +22,10 @@
 
 #include <stdmac.uc>
 #include <nfd_user_cfg.h>
 
-#include "nfd_common.h"
-#include "shared/nfd_cfg_pf_bars.uc"
+#include <vnic/nfd_common.h>
+#include <vnic/shared/nfd_cfg.uc>
 
 #define NFD_MAX_ISL             4
 
 #define __NFD_EMU_BASE_ISL      24
diff --git a/me/blocks/vnic/pci_out_sb.uc b/me/blocks/vnic/pci_out_sb.uc
--- a/me/blocks/vnic/pci_out_sb.uc
+++ b/me/blocks/vnic/pci_out_sb.uc
@@ -25,9 +25,9 @@
 
 #include "wsm.uc"
 #include "nfd_common.h"
 #include "shared/nfd_internal.h"
-#include "shared/nfd_cfg_pf_bars.uc"
+#include "shared/nfd_cfg.uc"
 #include "nfd_out.uc"   /* for definitions only */
 #include "pci_out_sb.h"
 #include "pci_out_sb_iface.uc"
 
@@ -197,38 +197,8 @@
 // Debug state
 .alloc_mem nfd_out_sb_debug_state/**/PCIE_ISL emem0 global \
     (LM_QSTATE_SIZE * NFD_OUT_MAX_QUEUES + 16)
 
-// Config message field declarations
-#define NFD_CFG_MSG_VALID_bf            0, 31, 31
-#define NFD_CFG_MSG_VALID_wrd           0
-#define NFD_CFG_MSG_VALID_shf           31
-#define NFD_CFG_MSG_VALID_msk           0x1
-#define NFD_CFG_MSG_VALID_bit           31
-#define NFD_CFG_MSG_ERR_bf              0, 30, 30
-#define NFD_CFG_MSG_ERR_wrd             0
-#define NFD_CFG_MSG_ERR_shf             30
-#define NFD_CFG_MSG_ERR_msk             0x1
-#define NFD_CFG_MSG_ERR_bit             30
-#define NFD_CFG_MSG_INTERESTED_bf       0, 29, 29
-#define NFD_CFG_MSG_INTERESTED_wrd      0
-#define NFD_CFG_MSG_INTERESTED_shf      29
-#define NFD_CFG_MSG_INTERESTED_msk      0x1
-#define NFD_CFG_MSG_INTERESTED_bit      29
-#define NFD_CFG_MSG_UP_bf               0, 28, 28
-#define NFD_CFG_MSG_UP_wrd              0
-#define NFD_CFG_MSG_UP_shf              28
-#define NFD_CFG_MSG_UP_msk              0x1
-#define NFD_CFG_MSG_UP_bit              28
-#define NFD_CFG_MSG_QUEUE_bf            0, 15, 8
-#define NFD_CFG_MSG_QUEUE_wrd           0
-#define NFD_CFG_MSG_QUEUE_shf           8
-#define NFD_CFG_MSG_QUEUE_msk           0xFF
-#define NFD_CFG_MSG_VNIC_bf             0, 7, 0
-#define NFD_CFG_MSG_VNIC_wrd            0
-#define NFD_CFG_MSG_VNIC_shf            0
-#define NFD_CFG_MSG_VNIC_msk            0xFF
-
 
 #macro _reset_ticket_bitmap(in_qid)
 .begin
 
@@ -320,23 +290,8 @@
 .end
 #endm
 
 
-#macro _get_bar_addr(out_hi, out_lo, in_vnic)
-.begin
-
-    .reg tmp_lo
-    .reg off
-
-    move(out_hi, ((nfd_cfg_base/**/PCIE_ISL >> 8) & 0xFF000000))
-    move(tmp_lo, (nfd_cfg_base/**/PCIE_ISL & 0xFFFFFFFF))
-    alu[off, --, B, in_vnic, <<(log2(NFP_NET_CFG_BAR_SZ))]
-    alu[out_lo, tmp_lo, +, off]
-
-.end
-#endm
-
-
 #macro _check_vnic_state(in_vnic)
 .begin
 
     .reg bar_addr_hi
@@ -350,9 +305,9 @@
     .xfer_order $bar
 
     .sig read_sig
 
-    _get_bar_addr(bar_addr_hi, bar_addr_lo, in_vnic)
+    nfd_cfg_get_bar_addr(bar_addr_hi, bar_addr_lo, in_vnic, PCIE_ISL)
     mem[read32, $bar[0], bar_addr_hi, <<8, bar_addr_lo, 6], ctx_swap[read_sig]
 
     .if (NFD_VNIC_IS_VF(in_vnic))
         move(maxqs, NFD_MAX_VF_QUEUES)
diff --git a/me/blocks/vnic/shared/nfd.h b/me/blocks/vnic/shared/nfd.h
--- a/me/blocks/vnic/shared/nfd.h
+++ b/me/blocks/vnic/shared/nfd.h
@@ -19,15 +19,108 @@
 #ifndef _BLOCKS__VNIC_SHARED_NFD_H_
 #define _BLOCKS__VNIC_SHARED_NFD_H_
 
 #include <nfp_chipres.h>
-#include <nfp/mem_atomic.h>     /* TEMP */
-
 #include <nfd_user_cfg.h>
 
 /* Set defines */
 #define NFD_MAX_ISL     4   /* Maximum number of PCIe islands NFD may support */
 
+
+/* User define consistency checks */
+#ifndef NFD_MAX_VF_QUEUES
+#error "NFD_MAX_VF_QUEUES is not defined but is required"
+#endif
+
+#ifndef NFD_MAX_PF_QUEUES
+#error "NFD_MAX_PF_QUEUES is not defined but is required"
+#endif
+
+#ifndef NFD_MAX_VFS
+#error "NFD_MAX_VFS is not defined but is required"
+#endif
+
+#ifndef NFD_MAX_PFS
+#error "NFD_MAX_PFS is not defined but is required"
+#endif
+
+
+/* Require that at least some queues are used by NFD. */
+#if ((NFD_MAX_VF_QUEUES * NFD_MAX_VFS) + (NFD_MAX_PF_QUEUES * NFD_MAX_PFS)) == 0
+#error "PF and VF options imply that no queues are in use"
+#endif
+
+
+/* NFD_MAX_VFS is used to determine PF vNIC number, so must
+ * always be consistent with VFs in use.  The ambiguous case
+ * where N VFs with 0 queues are requested is illegal. */
+#if (NFD_MAX_VF_QUEUES == 0) && (NFD_MAX_VFS != 0)
+#error "NFD_MAX_VFS must be zero if NFD_MAX_VF_QUEUES equals zero"
+#endif
+
+/* Just for completeness */
+#if (NFD_MAX_PF_QUEUES == 0) && (NFD_MAX_PFS != 0)
+#error "NFD_MAX_PFS must be zero if NFD_MAX_PF_QUEUES equals zero"
+#endif
+
+/* Ensure that the user provides NFD_CFG_VF_CAP if they
+ * want to use VFs. */
+#if NFD_MAX_VF_QUEUES != 0
+#ifndef NFD_CFG_VF_CAP
+#error NFD_CFG_VF_CAP must be defined
+#endif
+#endif
+
+/* Ensure that the user provides NFD_CFG_PF_CAP if they
+ * want to use PFs. */
+#if NFD_MAX_PF_QUEUES != 0
+#ifndef NFD_CFG_PF_CAP
+#error NFD_CFG_PF_CAP must be defined
+#endif
+#endif
+
+
+/* NFP_NET_CFG_CTRL_LSO2 and NFP_NET_CFG_CTRL_TXVLAN use the same bits in the
+ * TX descriptor, so they can't be advertised for the same vNIC type. */
+#if (NFD_CFG_VF_CAP & NFP_NET_CFG_CTRL_LSO2) && \
+    (NFD_CFG_VF_CAP & NFP_NET_CFG_CTRL_TXVLAN)
+#error "NFP_NET_CFG_CTRL_LSO2 and NFP_NET_CFG_CTRL_TXVLAN are incompatible"
+#endif
+
+#if (NFD_CFG_PF_CAP & NFP_NET_CFG_CTRL_LSO2) && \
+    (NFD_CFG_PF_CAP & NFP_NET_CFG_CTRL_TXVLAN)
+#error "NFP_NET_CFG_CTRL_LSO2 and NFP_NET_CFG_CTRL_TXVLAN are incompatible"
+#endif
+
+
+/* For NFP6000 chips < revision B0 a software workaround is used
+ * to ensure that the final bytes of a packet that is not a 4B
+ * multiple in size are byte swapped correctly.  This workaround
+ * is incompatible with gather support.  If the capabilities
+ * advertise gather, throw an error. */
+#if __REVISION_MIN < __REVISION_B0
+#if (NFD_CFG_VF_CAP & NFP_NET_CFG_CTRL_GATHER) || \
+    (NFD_CFG_PF_CAP & NFP_NET_CFG_CTRL_GATHER)
+#error "NFP_NET_CFG_CTRL_GATHER not supported for A0 chips"
+#endif
+#endif
+
+/* Debug defines */
+#ifdef NFD_VNIC_DBG_CHKS
+
+/* A mask used to test whether a value may be a legal MU buffer.
+ * This provides very coarse checking for illegal MU buffers in NFD. */
+#ifndef NFD_MU_PTR_DBG_MSK
+#define NFD_MU_PTR_DBG_MSK 0x1f000000
+#endif
+
+#endif
+
+
+#if defined(__NFP_LANG_MICROC)
+
+#include <nfp/mem_atomic.h>     /* TEMP */
+
 /*
  * CPP2PCIe BAR allocation
  * XXX This should go into chip_res
  */
@@ -41,9 +134,9 @@ enum pcie_cpp2pcie_bar {
     PCIE_CPP2PCIE_FREE6,
     PCIE_CPP2PCIE_FREE7
 };
 
-/* Helper macros */
+/* microC helper macros */
 
 /* Expand a constant PCIe number (0..3) to an EMEM island (emem0..emem2),
  * using the customer defined mapping provided by the NFD_PCIEX_EMEM defines.
  */
@@ -101,72 +194,8 @@ enum pcie_cpp2pcie_bar {
 /* Stringify an EMEM name for use in _nfp_has_island() tests. */
 #define NFD_EMEM_CHK_IND(_emem) #_emem
 #define NFD_EMEM_CHK(_emem) NFD_EMEM_CHK_IND(_emem)
 
-/* User define consistency checks */
-#ifndef NFD_MAX_VF_QUEUES
-#error "NFD_MAX_VF_QUEUES is not defined but is required"
-#endif
-
-#ifndef NFD_MAX_PF_QUEUES
-#error "NFD_MAX_PF_QUEUES is not defined but is required"
-#endif
-
-#ifndef NFD_MAX_VFS
-#error "NFD_MAX_VFS is not defined but is required"
-#endif
-
-#ifndef NFD_MAX_PFS
-#error "NFD_MAX_PFS is not defined but is required"
-#endif
-
-
-/* Require that at least some queues are used by NFD. */
-#if ((NFD_MAX_VF_QUEUES * NFD_MAX_VFS) + (NFD_MAX_PF_QUEUES * NFD_MAX_PFS)) == 0
-#error "PF and VF options imply that no queues are in use"
-#endif
-
-
-/* NFD_MAX_VFS is used to determine PF vNIC number, so must
- * always be consistent with VFs in use.  The ambiguous case
- * where N VFs with 0 queues are requested is illegal. */
-#if (NFD_MAX_VF_QUEUES == 0) && (NFD_MAX_VFS != 0)
-#error "NFD_MAX_VFS must be zero if NFD_MAX_VF_QUEUES equals zero"
-#endif
-
-/* Just for completeness */
-#if (NFD_MAX_PF_QUEUES == 0) && (NFD_MAX_PFS != 0)
-#error "NFD_MAX_PFS must be zero if NFD_MAX_PF_QUEUES equals zero"
-#endif
-
-/* Ensure that the user provides NFD_CFG_VF_CAP if they
- * want to use VFs. */
-#if NFD_MAX_VF_QUEUES != 0
-#ifndef NFD_CFG_VF_CAP
-#error NFD_CFG_VF_CAP must be defined
-#endif
-#endif
-
-/* Ensure that the user provides NFD_CFG_PF_CAP if they
- * want to use PFs. */
-#if NFD_MAX_PF_QUEUES != 0
-#ifndef NFD_CFG_PF_CAP
-#error NFD_CFG_PF_CAP must be defined
-#endif
-#endif
-
-/* NFP_NET_CFG_CTRL_LSO2 and NFP_NET_CFG_CTRL_TXVLAN use the same bits in the
- * TX descriptor, so they can't be advertised for the same vNIC type. */
-#if (NFD_CFG_VF_CAP & NFP_NET_CFG_CTRL_LSO2) && \
-    (NFD_CFG_VF_CAP & NFP_NET_CFG_CTRL_TXVLAN)
-#error "NFP_NET_CFG_CTRL_LSO2 and NFP_NET_CFG_CTRL_TXVLAN are incompatible"
-#endif
-
-#if (NFD_CFG_PF_CAP & NFP_NET_CFG_CTRL_LSO2) && \
-    (NFD_CFG_PF_CAP & NFP_NET_CFG_CTRL_TXVLAN)
-#error "NFP_NET_CFG_CTRL_LSO2 and NFP_NET_CFG_CTRL_TXVLAN are incompatible"
-#endif
-
 
 /* Check that the user points NFD to usable EMUs for each EMU specified */
 #ifdef NFD_IN_WQ_SHARED
     #if !_nfp_has_island(NFD_EMEM_CHK(NFD_IN_WQ_SHARED))
@@ -214,32 +243,8 @@ enum pcie_cpp2pcie_bar {
     #endif
 #endif
 
 
-/* For NFP6000 chips < revision B0 a software workaround is used
- * to ensure that the final bytes of a packet that is not a 4B
- * multiple in size are byte swapped correctly.  This workaround
- * is incompatible with gather support.  If the capabilities
- * advertise gather, throw an error. */
-#if __REVISION_MIN < __REVISION_B0
-#if (NFD_CFG_VF_CAP & NFP_NET_CFG_CTRL_GATHER) || \
-    (NFD_CFG_PF_CAP & NFP_NET_CFG_CTRL_GATHER)
-#error "NFP_NET_CFG_CTRL_GATHER not supported for A0 chips"
-#endif
-#endif
-
-/* Debug defines */
-#ifdef NFD_VNIC_DBG_CHKS
-
-/* A mask used to test whether a value may be a legal MU buffer.
- * This provides very coarse checking for illegal MU buffers in NFD. */
-#ifndef NFD_MU_PTR_DBG_MSK
-#define NFD_MU_PTR_DBG_MSK 0x1f000000
-#endif
-
-#endif
-
-
 /* Shared structures */
 /**
  * Compact storage of NFD ring addresses and ring numbers
  */
@@ -253,6 +258,7 @@ struct nfd_ring_info {
         unsigned int __raw;
     };
 };
 
+#endif /* __NFP_LANG_MICROC */
 
 #endif /* !_BLOCKS__VNIC_SHARED_NFD_H_ */
diff --git a/me/blocks/vnic/shared/nfd_cfg.h b/me/blocks/vnic/shared/nfd_cfg.h
--- a/me/blocks/vnic/shared/nfd_cfg.h
+++ b/me/blocks/vnic/shared/nfd_cfg.h
@@ -20,19 +20,13 @@
 #define _BLOCKS__SHARED_NFD_CFG_H_
 
 #include <nfp_chipres.h>
 
-#include <nfp/mem_ring.h>
 #include <nfp_net_ctrl.h>
 
 #include <nfd_user_cfg.h>
 
-#include "nfd.h"
-
-
-#ifndef _link_sym
-#define _link_sym(x) __link_sym(#x)
-#endif
+#include <vnic/shared/nfd.h>
 
 
 /* /\* XXX Magic number currently */
 /*  * Set to official version number before release *\/ */
@@ -75,76 +69,37 @@
 #define NFD_CFG_TOTAL_RINGS     32
 #define NFD_CFG_NUM_RINGS       8
 
 
-#define NFD_CFG_RINGS_RES_IND(_emem)                                    \
-    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_nums _emem##_queues   \
-                     global NFD_CFG_TOTAL_RINGS NFD_CFG_TOTAL_RINGS)
-#define NFD_CFG_RINGS_RES(_emem) NFD_CFG_RINGS_RES_IND(_emem)
-
-NFD_CFG_RINGS_RES(NFD_CFG_RING_EMEM);
-
-
-#define NFD_CFG_RINGS_DECL_IND(_isl)                                    \
-    _NFP_CHIPRES_ASM(.declare_resource nfd_cfg_ring_nums##_isl          \
-                     global NFD_CFG_NUM_RINGS nfd_cfg_ring_nums)        \
-    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_num##_isl##0          \
-                     nfd_cfg_ring_nums##_isl global 1)                  \
-    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_num##_isl##1          \
-                     nfd_cfg_ring_nums##_isl global 1)                  \
-    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_num##_isl##2          \
-                     nfd_cfg_ring_nums##_isl global 1)                  \
-    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_num##_isl##3          \
-                     nfd_cfg_ring_nums##_isl global 1)                  \
-    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_num##_isl##4          \
-                     nfd_cfg_ring_nums##_isl global 1)                  \
-    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_num##_isl##5          \
-                     nfd_cfg_ring_nums##_isl global 1)
-
-#define NFD_CFG_RINGS_DECL(_isl) NFD_CFG_RINGS_DECL_IND(_isl)
-
-#if _nfp_has_island("pcie0")
-NFD_CFG_RINGS_DECL(0);
-#endif
-
-#if _nfp_has_island("pcie1")
-NFD_CFG_RINGS_DECL(1);
-#endif
-
-#if _nfp_has_island("pcie2")
-NFD_CFG_RINGS_DECL(2);
-#endif
-
-#if _nfp_has_island("pcie3")
-NFD_CFG_RINGS_DECL(3);
-#endif
-
-
-/*
- * The "nfd_flr_seen" atomic is used to track which FLRs have been noticed by
- * by PCI.IN ME0 but have not been completed by the service ME.  It prevents
- * us reissuing an FLR message if something else causes us to check the
- * hardware pending mask.
- *
- * "nfd_flr_seen" is structured as an "array" of 16B entries per PCIe island.
- * Each entry consists of two 32bit bitmasks "VF_LO" and "VF_HI", and an
- * extra 32bit mask with just one bit used for the PF (selected by
- * NFD_FLR_PF_shf).  There is one byte of padding per PCIe island too.
- *
- * Users outside of this file would generally call APIs from this file, so
- * they should not depend on this structure.
- */
-#define NFD_FLR_DECLARE                                                 \
-    _NFP_CHIPRES_ASM(.alloc_mem nfd_flr_atomic NFD_CFG_RING_EMEM        \
-                     global 64 64)                                      \
-    _NFP_CHIPRES_ASM(.declare_resource nfd_flr_atomic_mem               \
-                     global 64 nfd_flr_atomic)                          \
-    _NFP_CHIPRES_ASM(.alloc_resource nfd_flr_seen nfd_flr_atomic_mem    \
-                     global 64 64)
-
-#define NFD_FLR_LINK_IND(_isl)                                  \
-    ((__mem char *) _link_sym(nfd_flr_seen) + ((_isl) * 16))
-#define NFD_FLR_LINK(_isl) NFD_FLR_LINK_IND(_isl)
+/* Config message field declarations */
+#define NFD_CFG_MSG_VALID_bf            0, 31, 31
+#define NFD_CFG_MSG_VALID_wrd           0
+#define NFD_CFG_MSG_VALID_shf           31
+#define NFD_CFG_MSG_VALID_msk           0x1
+#define NFD_CFG_MSG_VALID_bit           31
+#define NFD_CFG_MSG_ERR_bf              0, 30, 30
+#define NFD_CFG_MSG_ERR_wrd             0
+#define NFD_CFG_MSG_ERR_shf             30
+#define NFD_CFG_MSG_ERR_msk             0x1
+#define NFD_CFG_MSG_ERR_bit             30
+#define NFD_CFG_MSG_INTERESTED_bf       0, 29, 29
+#define NFD_CFG_MSG_INTERESTED_wrd      0
+#define NFD_CFG_MSG_INTERESTED_shf      29
+#define NFD_CFG_MSG_INTERESTED_msk      0x1
+#define NFD_CFG_MSG_INTERESTED_bit      29
+#define NFD_CFG_MSG_UP_bf               0, 28, 28
+#define NFD_CFG_MSG_UP_wrd              0
+#define NFD_CFG_MSG_UP_shf              28
+#define NFD_CFG_MSG_UP_msk              0x1
+#define NFD_CFG_MSG_UP_bit              28
+#define NFD_CFG_MSG_QUEUE_bf            0, 15, 8
+#define NFD_CFG_MSG_QUEUE_wrd           0
+#define NFD_CFG_MSG_QUEUE_shf           8
+#define NFD_CFG_MSG_QUEUE_msk           0xFF
+#define NFD_CFG_MSG_VNIC_bf             0, 7, 0
+#define NFD_CFG_MSG_VNIC_wrd            0
+#define NFD_CFG_MSG_VNIC_shf            0
+#define NFD_CFG_MSG_VNIC_msk            0xFF
 
 
 /*
  * Defines that set the structure of "nfd_flr_seen".  These are also
@@ -184,8 +139,86 @@ NFD_CFG_RINGS_DECL(3);
 #define NFP_PCIEX_PCIE_INT_MGR_STATUS_FLR_msk                0x300
 #define NFP_PCIEX_COMPCFG_CFG0                               0x00100000
 #define NFP_PCIEX_COMPCFG_CFG0_MSG_VALID_shf                 11
 
+
+#if defined(__NFP_LANG_MICROC)
+
+#ifndef _link_sym
+#define _link_sym(x) __link_sym(#x)
+#endif
+
+/* Configuration mechanism memory and ring defines */
+#define NFD_CFG_RINGS_RES_IND(_emem)                                    \
+    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_nums _emem##_queues   \
+                     global NFD_CFG_TOTAL_RINGS NFD_CFG_TOTAL_RINGS)
+#define NFD_CFG_RINGS_RES(_emem) NFD_CFG_RINGS_RES_IND(_emem)
+
+NFD_CFG_RINGS_RES(NFD_CFG_RING_EMEM);
+
+
+#define NFD_CFG_RINGS_DECL_IND(_isl)                                    \
+    _NFP_CHIPRES_ASM(.declare_resource nfd_cfg_ring_nums##_isl          \
+                     global NFD_CFG_NUM_RINGS nfd_cfg_ring_nums)        \
+    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_num##_isl##0          \
+                     nfd_cfg_ring_nums##_isl global 1)                  \
+    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_num##_isl##1          \
+                     nfd_cfg_ring_nums##_isl global 1)                  \
+    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_num##_isl##2          \
+                     nfd_cfg_ring_nums##_isl global 1)                  \
+    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_num##_isl##3          \
+                     nfd_cfg_ring_nums##_isl global 1)                  \
+    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_num##_isl##4          \
+                     nfd_cfg_ring_nums##_isl global 1)                  \
+    _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_num##_isl##5          \
+                     nfd_cfg_ring_nums##_isl global 1)
+
+#define NFD_CFG_RINGS_DECL(_isl) NFD_CFG_RINGS_DECL_IND(_isl)
+
+#if _nfp_has_island("pcie0")
+NFD_CFG_RINGS_DECL(0);
+#endif
+
+#if _nfp_has_island("pcie1")
+NFD_CFG_RINGS_DECL(1);
+#endif
+
+#if _nfp_has_island("pcie2")
+NFD_CFG_RINGS_DECL(2);
+#endif
+
+#if _nfp_has_island("pcie3")
+NFD_CFG_RINGS_DECL(3);
+#endif
+
+
+/*
+ * The "nfd_flr_seen" atomic is used to track which FLRs have been noticed by
+ * by PCI.IN ME0 but have not been completed by the service ME.  It prevents
+ * us reissuing an FLR message if something else causes us to check the
+ * hardware pending mask.
+ *
+ * "nfd_flr_seen" is structured as an "array" of 16B entries per PCIe island.
+ * Each entry consists of two 32bit bitmasks "VF_LO" and "VF_HI", and an
+ * extra 32bit mask with just one bit used for the PF (selected by
+ * NFD_FLR_PF_shf).  There is one byte of padding per PCIe island too.
+ *
+ * Users outside of this file would generally call APIs from this file, so
+ * they should not depend on this structure.
+ */
+#define NFD_FLR_DECLARE                                                 \
+    _NFP_CHIPRES_ASM(.alloc_mem nfd_flr_atomic NFD_CFG_RING_EMEM        \
+                     global 64 64)                                      \
+    _NFP_CHIPRES_ASM(.declare_resource nfd_flr_atomic_mem               \
+                     global 64 nfd_flr_atomic)                          \
+    _NFP_CHIPRES_ASM(.alloc_resource nfd_flr_seen nfd_flr_atomic_mem    \
+                     global 64 64)
+
+#define NFD_FLR_LINK_IND(_isl)                                  \
+    ((__mem char *) _link_sym(nfd_flr_seen) + ((_isl) * 16))
+#define NFD_FLR_LINK(_isl) NFD_FLR_LINK_IND(_isl)
+
+
 #define NFD_CFG_EMEM_IND1(_emem) __LoadTimeConstant("__addr_" #_emem)
 #define NFD_CFG_EMEM_IND0(_emem) NFD_CFG_EMEM_IND1(_emem)
 #define NFD_CFG_EMEM NFD_CFG_EMEM_IND0(NFD_CFG_RING_EMEM)
 
@@ -319,5 +352,7 @@ struct nfd_cfg_msg {
                           __remote SIGNAL *cfg_sig_remote,
                           unsigned int next_me, unsigned int rnum_out,
                           unsigned int rnum_in);
 
+#endif /* __NFP_LANG_MICROC */
+
 #endif /* !_BLOCKS__SHARED_NFD_CFG_H_ */
diff --git a/me/blocks/vnic/shared/nfd_cfg_pf_bars.uc b/me/blocks/vnic/shared/nfd_cfg.uc
rename from me/blocks/vnic/shared/nfd_cfg_pf_bars.uc
rename to me/blocks/vnic/shared/nfd_cfg.uc
--- a/me/blocks/vnic/shared/nfd_cfg_pf_bars.uc
+++ b/me/blocks/vnic/shared/nfd_cfg.uc
@@ -12,17 +12,18 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
  *
- * @file          blocks/vnic/shared/nfd_cfg_pf_bars.uc
- * @brief         Microcode access to CFG BAR defines
+ * @file          blocks/vnic/shared/nfd_cfg.uc
+ * @brief         Microcode access to CFG BAR
  */
 
-#ifndef _BLOCKS__SHARED_NFD_CFG_PF_BARS_UC_
-#define _BLOCKS__SHARED_NFD_CFG_PF_BARS_UC_
+#ifndef _BLOCKS__SHARED_NFD_CFG_UC_
+#define _BLOCKS__SHARED_NFD_CFG_UC_
 
 #include "nfd_user_cfg.h"
 #include <nfp_net_ctrl.h>
+#include <vnic/shared/nfd_cfg.h>
 
 #ifndef NFD_MAX_PFS
 #error "NFD_MAX_PFS is not defined but is required"
 #endif
@@ -31,40 +32,50 @@
 #define_eval NFD_CFG_BAR_SZ (NFD_TOTAL_VNICS * NFP_NET_CFG_BAR_SZ)
 #define_eval NFD_CFG_BAR0_OFF (NFD_MAX_VFS * NFP_NET_CFG_BAR_SZ)
 
 
-#macro nfd_define_pf_bars(_isl)
+#macro nfd_cfg_define_bars(_isl)
 .alloc_mem nfd_cfg_base/**/_isl NFD_PCIE/**/_isl/**/_EMEM global \
     NFD_CFG_BAR_SZ 0x200000
-#if NFD_MAX_PFS != 0
-.declare_resource nfd_cfg_base/**/_isl/**/_res global NFD_CFG_BAR_SZ \
-    nfd_cfg_base/**/_isl
-.alloc_resource _pf/**/_isl/**/_net_bar0 \
-    nfd_cfg_base/**/_isl/**/_res+NFD_CFG_BAR0_OFF global \
-    (NFD_MAX_PFS * NFP_NET_CFG_BAR_SZ)
-.alloc_mem nfd_cfg_pf/**/_isl/**/_num_ports emem global 8 8
-.init nfd_cfg_pf/**/_isl/**/_num_ports NFD_MAX_PFS
-#endif
 #endm
 
 
 #ifdef NFD_PCIE0_EMEM
-nfd_define_pf_bars(0)
+nfd_cfg_define_bars(0)
 #endif
 
 #ifdef NFD_PCIE1_EMEM
-nfd_define_pf_bars(1)
+nfd_cfg_define_bars(1)
 #endif
 
 #ifdef NFD_PCIE2_EMEM
-nfd_define_pf_bars(2)
+nfd_cfg_define_bars(2)
 #endif
 
 #ifdef NFD_PCIE3_EMEM
-nfd_define_pf_bars(3)
+nfd_cfg_define_bars(3)
 #endif
 
 #undef NFD_TOTAL_VNICS
 #undef NFD_CFG_BAR_SZ
 #undef NFD_CFG_BAR0_OFF
 
-#endif /* !_BLOCKS__SHARED_NFD_CFG_PF_BARS_UC_ */
+
+#macro nfd_cfg_get_bar_addr(out_hi, out_lo, in_vnic, ISL)
+.begin
+    .reg tmp_lo
+    .reg off
+
+    #if (!is_ct_const(ISL))
+        #error "nfd_cfg_get_bar_addr: ISL must be CT const"
+    #endif
+
+    move(out_hi, ((nfd_cfg_base/**/ISL >> 8) & 0xFF000000))
+    move(tmp_lo, (nfd_cfg_base/**/ISL & 0xFFFFFFFF))
+    alu[off, --, B, in_vnic, <<(log2(NFP_NET_CFG_BAR_SZ))]
+    alu[out_lo, tmp_lo, +, off]
+
+.end
+#endm
+
+
+#endif /* !_BLOCKS__SHARED_NFD_CFG_UC_ */
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1492004241 -7200
# Node ID 48fd8d7206e2f1b37dd0f3f7d0eafd2412918219
# Parent  a611473bd9972034df79c7fa56ea5111f4a37ff5
[cfg] Add the concept of a CTRL vNIC type to NFD
* Defining NFD_USE_CTRL will create the CTRL vNIC
* An app ID must be specified if the CTRL vNIC is used (via NFD_NET_APP_ID)
* Introduce <type, vnic, queue> numbering into NFD and provide mappings
  to other numbering schemes (e.g. natq, qid).
* Introduce VID as the "linear" vNIC numbering across all types and provide
  mappings.
* See nfd_common.h and nfd_common.uc for mapping options.

diff --git a/me/apps/loopback/app_master.c b/me/apps/loopback/app_master.c
--- a/me/apps/loopback/app_master.c
+++ b/me/apps/loopback/app_master.c
@@ -132,13 +132,13 @@ main(void)
                                            PCIE_ISL);
 
                 if (cfg_msg.msg_valid) {
                     mem_read64(cfg_bar_data,
-                               NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg.vnic),
+                               NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg.vid),
                                sizeof cfg_bar_data);
 #ifdef APP_MASTER_MSIX_EN
                     mem_read64(rx_ring_vector_data,
-                               NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg.vnic)+0xa40,
+                               NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg.vid)+0xa40,
                                sizeof rx_ring_vector_data);
 #endif
                 }
             } else {
@@ -147,12 +147,12 @@ main(void)
 
                 __implicit_read(cfg_bar_data, 6);
 
 #ifdef APP_MASTER_MSIX_EN
-                msix_gen_update_config(cfg_msg.vnic, cfg_bar_data, rx_ring_vector_data);
+                msix_gen_update_config(cfg_msg.vid, cfg_bar_data, rx_ring_vector_data);
 #endif
 
-                local_csr_write(local_csr_mailbox_0, cfg_msg.vnic);
+                local_csr_write(local_csr_mailbox_0, cfg_msg.vid);
                 local_csr_write(local_csr_mailbox_1, cfg_bar_data[0]);
 
                 /* Set link state */
                 if (!cfg_msg.error && (cfg_bar_data[NFP_NET_CFG_CTRL] &
@@ -161,9 +161,9 @@ main(void)
                 } else {
                     link_state = 0;
                 }
                 mem_write32(&link_state,
-                            (NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg.vnic) +
+                            (NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg.vid) +
                              NFP_NET_CFG_STS),
                             sizeof link_state);
 
                 /* Complete the message */
diff --git a/me/apps/loopback/loopback_main.c b/me/apps/loopback/loopback_main.c
--- a/me/apps/loopback/loopback_main.c
+++ b/me/apps/loopback/loopback_main.c
@@ -187,21 +187,22 @@ drop_pkt(__gpr struct nbi_meta_pkt_info 
 
 
 /* Check CFG BAR for ring enables */
 __intrinsic int
-test_enable(unsigned int vnic, unsigned int queue) {
+test_enable(unsigned int type, unsigned int vnic, unsigned int queue) {
     __emem char *ptr;
     __xread unsigned int enables;
+    unsigned int vid = NFD_VNIC2VID(type, vnic);
 
     /* Check global enable */
-    ptr = NFD_CFG_BAR_ISL(PCIE_ISL, vnic) + NFP_NET_CFG_CTRL;
+    ptr = NFD_CFG_BAR_ISL(PCIE_ISL, vid) + NFP_NET_CFG_CTRL;
     mem_read32(&enables, ptr, sizeof(enables));
     if (!(enables & NFP_NET_CFG_CTRL_ENABLE)) {
         return 0;
     }
 
     /* Check per ring enable */
-    ptr = NFD_CFG_BAR_ISL(PCIE_ISL, vnic) + NFP_NET_CFG_RXRS_ENABLE;
+    ptr = NFD_CFG_BAR_ISL(PCIE_ISL, vid) + NFP_NET_CFG_RXRS_ENABLE;
     if (queue & 32) {
         ptr += sizeof(unsigned int);
     }
     queue &= 31;
@@ -217,10 +218,9 @@ void main(void)
     __xwrite struct nfd_out_input nfd_out_desc_xfer;
     __gpr struct nbi_meta_pkt_info pkt_info;
 
     unsigned int bmsk_queue;
-    unsigned int queue;
-    unsigned int vnic;
+    unsigned int type, vnic, queue;
     __xrw unsigned int credit;
 
     SIGNAL get_sig;
     SIGNAL_PAIR credit_sig;
@@ -290,28 +290,48 @@ void main(void)
         nfd_in_fill_meta(&pkt_info, &nfd_in_meta);
 
 
         /* Map the packet vnic and queue */
-        nfd_in_map_queue(&vnic, &queue, nfd_in_meta.q_num);
+        nfd_in_map_queue(&type, &vnic, &queue, nfd_in_meta.q_num);
 
-        /* Pick loopback queue and vNIC */
-#ifdef LOOPBACK_FLIP_QUEUE
-        queue = queue ^ 1;
-#endif
-#ifdef LOOPBACK_FLIP_VNIC
-
-        vnic = vnic ^ 1;
-
-        /* Mask queue into the range of queues supported */
-        if (NFD_VNIC_IS_PF(vnic)) {
-            queue = queue & (NFD_MAX_PF_QUEUES-1);
+        /* Pick loopback queue and vNIC
+         * Try to handle a number of possible vNIC configurations sensibly */
+        /* XXX Other loopback strategies can be used */
+        if (type == NFD_VNIC_TYPE_VF) {
+            type = NFD_VNIC_TYPE_VF;
+            vnic = vnic ^ 1;
+            queue = 0;
+        } else if (type == NFD_VNIC_TYPE_CTRL) {
+            #if (NFD_MAX_PF_QUEUES != 0)
+                type = NFD_VNIC_TYPE_PF;
+            #elif (NFD_MAX_VFS != 0)
+                type = NFD_VNIC_TYPE_VF;
+            #else
+                #error "At least some PFs or VFs need to be used"
+            #endif
+            vnic = 0;
+            queue = 0;
+        } else if (type == NFD_VNIC_TYPE_PF) {
+            #if ((NFD_MAX_PFS == 1) && defined(NFD_USE_CTRL))
+                type = NFD_VNIC_TYPE_CTRL;
+                vnic = 0;
+                queue = 0;
+            #elif ((NFD_MAX_PFS == 1) && (NFD_MAX_VFS != 0))
+                type = NFD_VNIC_TYPE_VF;
+                vnic = 0;
+                queue = 0;
+            #else
+                type = NFD_VNIC_TYPE_PF;
+                vnic = vnic ^ 1;
+                /* Leave queue untouched */
+            #endif
         } else {
-            queue = queue & (NFD_MAX_VF_QUEUES-1);
+            /* This is an error */
+            __asm {halt};
         }
-#endif
 
         /* PCI.OUT transmit */
-        bmsk_queue = nfd_out_map_queue(vnic, queue);
+        bmsk_queue = nfd_out_map_queue(type, vnic, queue);
 
 
         /* Get a credit, this does not need to be ordered provided that
          * the number of credits that PCI.OUT issues per queue is
@@ -319,9 +339,9 @@ void main(void)
         __nfd_out_get_credit(PCIE_ISL, bmsk_queue, 1, &credit,
                              ctx_swap, &credit_sig);
         while (credit == 0) {
             /* Check whether the queue is up */
-            if (!test_enable(vnic, queue)) {
+            if (!test_enable(type, vnic, queue)) {
                 /* Exit the loop leaving the CTX without a credit */
                 break;
             }
 
diff --git a/me/apps/loopback/loopback_main.uc b/me/apps/loopback/loopback_main.uc
--- a/me/apps/loopback/loopback_main.uc
+++ b/me/apps/loopback/loopback_main.uc
@@ -237,9 +237,9 @@ main#:
     .xfer_order $nfd_out_desc_wr
 
     .reg pkt_info[2]
     .reg qid
-    .reg is_pf vnic queue
+    .reg type vnic queue
     .reg $credit
     .reg ctm_isl ctm_pnum pkt_len meta_len
     .reg muptr bls
 
@@ -321,28 +321,57 @@ main#:
         nfd_in_pkt_meta(pkt_info, $nfd_in_meta)
 
         nfd_in_get_qid(qid, $nfd_in_meta)
 
-        nfd_q_extract(is_pf, vnic, queue, qid)
+        nfd_q_extract(type, vnic, queue, qid, route_vf#, route_ctrl#, route_pf#)
 
-        /* Pick loopback queue and vNIC */
-#ifdef LOOPBACK_FLIP_QUEUE
-        alu[queue, queue, xor, 1]
-#endif
-#ifdef LOOPBACK_FLIP_VNIC
+        /* Pick loopback queue and vNIC
+         * Try to handle a number of possible vNIC configurations sensibly */
+        /* XXX Other loopback strategies can be used */
+    route_vf#:
+        #if (NFD_MAX_VFS != 0)
+            move(type, NFD_VNIC_TYPE_VF)
+            alu[vnic, vnic, xor, 1]
+            immed[queue, 0]
+            br[route_done#]
+        #endif
 
-        alu[vnic, vnic, xor, 1]
+    route_ctrl#:
+        #ifdef NFD_USE_CTRL
+            #if (NFD_MAX_PF_QUEUES != 0)
+                move(type, NFD_VNIC_TYPE_PF)
+            #elif (NFD_MAX_VFS != 0)
+                move(type, NFD_VNIC_TYPE_VF)
+            #else
+                #error "At least some PFs or VFs need to be used"
+            #endif
+            move(vnic, 0)
+            move(queue, 0)
+            br[route_done#]
+        #endif
 
-        /* Mask queue into the range of queues supported */
-        .if (is_pf)
-            alu[queue, queue, and, (NFD_MAX_PF_QUEUES - 1)]
-        .else
-            alu[queue, queue, and, (NFD_MAX_VF_QUEUES - 1)]
-        .endif
-#endif
+    route_pf#:
+        #if (NFD_MAX_PFS != 0)
+            #if ((NFD_MAX_PFS == 1) && defined(NFD_USE_CTRL))
+                 move(type, NFD_VNIC_TYPE_CTRL)
+                 move(vnic, 0)
+                 move(queue, 0)
+            #elif ((NFD_MAX_PFS == 1) && (NFD_MAX_VFS != 0))
+                 move(type, NFD_VNIC_TYPE_VF)
+                 move(vnic, 0)
+                 move(queue, 0)
+             #else
+                 move(type, NFD_VNIC_TYPE_PF)
+                 alu[vnic, vnic, xor, 1]
+                 ; Leave queue untouched
+             #endif
+            br[route_done#]
+        #endif
+
+    route_done#:
 
         /* PCI.OUT transmit */
-        nfd_build_q(qid, is_pf, vnic, queue)
+        nfd_build_q(qid, type, vnic, queue)
 
         /* Get a credit, this does not need to be ordered provided that
          * the number of credits that PCI.OUT issues per queue is
          * much greater than the number of worker contexts */
diff --git a/me/apps/loopback/nfd_user_cfg.h b/me/apps/loopback/nfd_user_cfg.h
--- a/me/apps/loopback/nfd_user_cfg.h
+++ b/me/apps/loopback/nfd_user_cfg.h
@@ -11,10 +11,10 @@
 #ifdef LOOPBACK_FLIP_VNIC
 /* Select parameters suitable for testing netdev */
 #define NFD_MAX_VF_QUEUES_DEFAULT 1
 #define NFD_MAX_PF_QUEUES_DEFAULT 2
-#define NFD_MAX_VFS_DEFAULT       56
-#define NFD_MAX_PFS_DEFAULT       4
+#define NFD_MAX_VFS_DEFAULT       60
+#define NFD_MAX_PFS_DEFAULT       1
 #else
 /* Select parameters suitable for testing PMD */
 #define NFD_MAX_VF_QUEUES_DEFAULT 8
 #define NFD_MAX_PF_QUEUES_DEFAULT 4
@@ -38,8 +38,9 @@
 #ifndef NFD_MAX_PFS
 #define NFD_MAX_PFS       NFD_MAX_PFS_DEFAULT
 #endif
 
+#define NFD_USE_CTRL
 #define NFD_NET_APP_ID      10 * 5
 
 #define NFD_OUT_FL_BUFS_PER_QUEUE       1024
 
diff --git a/me/blocks/vnic/nfd_common.h b/me/blocks/vnic/nfd_common.h
--- a/me/blocks/vnic/nfd_common.h
+++ b/me/blocks/vnic/nfd_common.h
@@ -19,8 +19,9 @@
 #ifndef __NFD_COMMON_H
 #define __NFD_COMMON_H
 
 #include <nfd_user_cfg.h>
+#include <vnic/shared/nfd_ctrl.h>
 
 
 /* NFD version number define guards */
 #ifdef NFD_CFG_MAJOR
@@ -80,25 +81,8 @@
 #error "NFD_MAX_PFS is not defined but is required"
 #endif
 
 
-/*
- * VFs are assigned vNIC numbers first, followed by the PFs.
- * This makes the number of the first PF equal to NFD_MAX_VFS,
- * and NFD_MAX_VFS becomes the critical value in tests for
- * PF/VF.
- */
-#if (NFD_MAX_VFS == 0)
-    #define NFD_VNIC_IS_PF(_x) 1
-#else
-    #define NFD_VNIC_IS_PF(_x) ((_x) >= NFD_MAX_VFS)
-#endif
-#define NFD_VNIC_IS_VF(_x) ((_x) < NFD_MAX_VFS)
-
-#define NFD_FIRST_PF     NFD_MAX_VFS
-#define NFD_LAST_PF      (NFD_MAX_VFS + NFD_MAX_PFS - 1)
-
-
 /* vNICs must have queues, so if the "MAX_QUEUES" parameter is zero,
  * require the related MAX_VFS/PFS parameter to be zero as well. */
 #if ((NFD_MAX_VF_QUEUES == 0) && (NFD_MAX_VFS != 0))
 #error "NFD_MAX_VFS must be zero if NFD_MAX_VF_QUEUES equals zero"
@@ -107,8 +91,17 @@
 #if (NFD_MAX_PF_QUEUES == 0) && (NFD_MAX_PFS != 0)
 #error "NFD_MAX_PFS must be zero if NFD_MAX_PF_QUEUES equals zero"
 #endif
 
+/* The CTRL vNIC can only be used if PF vNICs are also in use */
+#if ((NFD_MAX_PFS == 0) && defined(NFD_USE_CTRL))
+#error "PF vNICs are required if the CTRL vNIC is used (NFD_USE_CTRL is set)"
+#endif
+
+/* The CTRL vNIC can only be used for FWs advertising an app_id */
+#if (defined(NFD_USE_CTRL) && !defined(NFD_NET_APP_ID))
+#error "An APP ID must be advertised if the CTRL vNIC is used"
+#endif
 
 #ifdef NFD_CFG_CLASS
 #ifndef NFD_CFG_CLASS_VERSION
 #error "NFD_CFG_CLASS_VERSION must be provided if NFD_CFG_CLASS is specified"
@@ -122,8 +115,79 @@
 #endif
 #endif
 
 
+#define NFD_VNIC_TYPE_VF    0
+#define NFD_VNIC_TYPE_PF    1
+#define NFD_VNIC_TYPE_CTRL  2
+
+#define NFD_TOTAL_VFQS      (NFD_MAX_VFS * NFD_MAX_VF_QUEUES)
+#define NFD_TOTAL_CTRLQS    (NFD_MAX_CTRL * NFD_MAX_CTRL_QUEUES)
+#define NFD_TOTAL_PFQS      (NFD_MAX_PFS * NFD_MAX_PF_QUEUES)
+
+#if (NFD_TOTAL_VFQS + NFD_TOTAL_CTRLQS + NFD_TOTAL_PFQS > 64)
+#error "Total number of NFD queues per island cannot exceed 64"
+#endif
+
+
+#ifdef NFD_USE_CTRL
+/* XXX The control vNIC is placed after the VF vNICs and before the PF vNICs */
+#define NFD_CTRL_VNIC       NFD_MAX_VFS
+#define NFD_CTRL_QUEUE      NFD_TOTAL_VFQS
+#endif
+
+#define NFD_FIRST_PF        (NFD_MAX_VFS + NFD_MAX_CTRL)
+#define NFD_LAST_PF         (NFD_FIRST_PF + NFD_MAX_PFS)
+#define NFD_FIRST_PF_QUEUE  (NFD_TOTAL_VFQS + NFD_TOTAL_CTRLQS)
+
+
+/*
+ * VFs are assigned VIDs and queues first, followed by the CTRL vNIC
+ * if used and finally the PF vNICs.
+ */
+#if (NFD_MAX_VFS > 0)
+    #if (NFD_MAX_CTRL + NFD_MAX_PFS)
+        #define NFD_VID_IS_VF(_x) ((_x) < NFD_MAX_VFS)
+        #define NFD_Q_IS_VF(_x) ((_x) < NFD_TOTAL_VFQS)
+    #else
+        #define NFD_VID_IS_VF(_x) 1
+        #define NFD_Q_IS_VF(_x) 1
+    #endif
+#else
+    #define NFD_VID_IS_VF(_x) 0
+    #define NFD_Q_IS_VF(_x) 0
+#endif
+
+#if (NFD_MAX_PFS > 0)
+    #if (NFD_MAX_VFS + NFD_MAX_CTRL)
+        #define NFD_VID_IS_PF(_x) ((_x) >= NFD_FIRST_PF)
+        #define NFD_Q_IS_PF(_x) ((_x) >= NFD_FIRST_PF_QUEUE)
+    #else
+        #define NFD_VID_IS_PF(_x) 1
+        #define NFD_Q_IS_PF(_x) 1
+    #endif
+#else
+    #define NFD_VID_IS_PF(_x) 0
+    #define NFD_Q_IS_PF(_x) 0
+#endif
+
+#if (NFD_MAX_CTRL > 0)
+    #if (NFD_MAX_CTRL_QUEUES != 1 || NFD_MAX_CTRL != 1)
+        #error "Unsupported CTRL vNIC values"
+    #endif
+
+    #if (NFD_MAX_VFS + NFD_MAX_PFS)
+        #define NFD_VID_IS_CTRL(_x) ((_x) == NFD_CTRL_VNIC)
+        #define NFD_Q_IS_CTRL(_x) ((_x) == NFD_CTRL_QUEUE)
+    #else
+        #define NFD_VID_IS_CTRL(_x) 1
+        #define NFD_Q_IS_CTRL(_x) 1
+    #endif
+#else
+    #define NFD_VID_IS_CTRL(_x) 0
+    #define NFD_Q_IS_CTRL(_x) 0
+#endif
+
 
 #define NFD_IN_DESC_SIZE        16
 
 #define NFD_OUT_DESC_SIZE       16
@@ -145,183 +209,219 @@
  * respectively).  Only PCI.IN and PCI.OUT access the QC queues
  * from the firmware, so this representation is never used outside
  * the PCIe island.
  *
- * == Bitmask queue number (BMQ) ==
+ * == Bitmask queue number (BMQ / QID) ==
  * NFD stores bitmasks of which queues need to be processed.  All data used
  * by PCI.IN and PCI.OUT is stored in the bitmask format.  A layer of
  * abstraction is used between the natural queue number and its internal
  * bitmask queue numbering, to allow NFD to convert from QC queue numbers
- * to an offset in a bitmask as efficiently as possible.
+ * to an offset in a bitmask as efficiently as possible.  The bitmask queue
+ * number is also referred to as the QID.
  *
- * == vNIC:queue pair numbering ==
- * Ultimately, NFD exposes up to N vNICs with up to Q queues to the user.
+ * == type:vNIC:queue pair numbering ==
+ * Ultimately, NFD exposes N of three different types of vNICs with up to Q
+ * queues to the user, where N and Q differ between types.
  * These vNIC queues need to be mapped into the NATQ space.  Currently,
- * the VF queues are enumerated first, from VF 0 to VF N-1, and the PF
- * afterwards.  Thus NATQ = vNIC * NFD_MAX_VF_QUEUES + queue.
- * We need to handle the case where there are no VFs or where there is no
- * PF as well.
+ * the VF queues are enumerated first, from VF 0 to VF N-1, then the CTRL,
+ * and finally the PFs.
+ *
+ * == VID:queue pair numbering ==
+ * All vNICs are given a unique ID independent of their type, the VID.  This
+ * VID is used for example to determine the vNIC's CFG BAR within the memory
+ * symbol.
  */
 
 
 /*
  * Conversions between NATQ and BMQ representations
  */
-#define NFD_NATQ2BMQ(_qid) _qid
+#define NFD_NATQ2BMQ(_qid) (_qid)
 
-#define NFD_BMQ2NATQ(_qid) _qid
+#define NFD_BMQ2NATQ(_qid) (_qid)
 
 
 /*
- * Conversions between vNIC:queue to NATQ
+ * Conversions between type:vNIC:queue to NATQ
  */
 
-/* Config queues are a special case where the vNIC
- * can be computed easily. The queue is known by definition. */
-
-#if NFD_MAX_PFS < 2
-#if NFD_MAX_VF_QUEUES != 0
-#define NFD_CFGQ2VNIC(_cfg)                     \
-    ((_cfg) / NFD_MAX_VF_QUEUES)
-#else
-/* We must have the PF */
-#define NFD_CFGQ2VNIC(_cfg) NFD_MAX_VFS
-#endif /* NFD_MAX_VF_QUEUES != 0 */
-#else
-#if NFD_MAX_VFS == 0
-#define NFD_CFGQ2VNIC(_cfg)                     \
-    ((_cfg) / NFD_MAX_PF_QUEUES)
-#else
-#define NFD_CFGQ2VNIC(_cfg)                                             \
-    (((_cfg) < (NFD_MAX_VFS * NFD_MAX_VF_QUEUES)) ?                     \
-     ((_cfg) / NFD_MAX_VF_QUEUES) :                                     \
-     ((((_cfg) - (NFD_MAX_VF_QUEUES * NFD_MAX_VFS)) / NFD_MAX_PF_QUEUES) \
-      + NFD_MAX_VFS))
-#endif /* NFD_MAX_VFS == 0 */
-#endif /* NFD_MAX_PFS < 2 */
-
-/* If a natural queue is known to be related to a VF,
- * the mapping can be computed cheaply. */
+#if (NFD_MAX_VF_QUEUES != 0)
 #define NFD_NATQ2VF(_nat)                       \
     ((_nat) / NFD_MAX_VF_QUEUES)
-
 #define NFD_NATQ2VFQ(_nat)                      \
     ((_nat) % NFD_MAX_VF_QUEUES)
-
-#if NFD_MAX_PFS < 2
-#define NFD_NATQ2PF(_nat)                       \
-    (NFD_MAX_VFS)
-#define NFD_NATQ2PFQ(_nat)                          \
-    ((_nat) - (NFD_MAX_VF_QUEUES * NFD_MAX_VFS))
+#define NFD_VF2NATQ(_vf, _q)                    \
+    ((_vf) * NFD_MAX_VF_QUEUES + (_q))
 #else
-#define NFD_NATQ2PF(_nat)                       \
-  ((((_nat) - (NFD_MAX_VF_QUEUES * NFD_MAX_VFS)) / NFD_MAX_PF_QUEUES)\
-   + NFD_MAX_VFS)
-#define NFD_NATQ2PFQ(_nat)                          \
-    (((_nat) - (NFD_MAX_VF_QUEUES * NFD_MAX_VFS)) % NFD_MAX_PF_QUEUES)
+#define NFD_NATQ2VF(_nat) 0
+#define NFD_NATQ2VFQ(_nat) 0
+#define NFD_VF2NATQ(_vf, _q) 0
 #endif
 
-/* If we know the vNIC, we can compute the queue cheaply. */
-#if NFD_MAX_PFS < 2
-#define NFD_NATQ2VQN(_nat, _vnic)                       \
-    ((_nat) - ((_vnic) * NFD_MAX_VF_QUEUES))
+#if (NFD_MAX_PF_QUEUES != 0)
+#define NFD_NATQ2PF(_nat)                               \
+    (((_nat) - NFD_FIRST_PF_QUEUE) / NFD_MAX_PF_QUEUES)
+#define NFD_NATQ2PFQ(_nat)                              \
+    (((_nat) - NFD_FIRST_PF_QUEUE) % NFD_MAX_PF_QUEUES)
+#define NFD_PF2NATQ(_pf, _q)                            \
+    ((_pf) * NFD_MAX_PF_QUEUES + (_q) + NFD_FIRST_PF_QUEUE)
 #else
-#define NFD_NATQ2VQN(_nat, _vnic)                               \
-    ((NFD_VNIC_IS_VF(_vnic)) ?                                  \
-    ((_nat) - ((_vnic) * NFD_MAX_VF_QUEUES)) :                  \
-      ((_nat) - ((NFD_MAX_VFS * NFD_MAX_VF_QUEUES) +            \
-                 (((_vnic) - NFD_MAX_VFS) *                     \
-                  NFD_MAX_PF_QUEUES))))
-#endif /* if NFD_MAX_PFS < 2 */
+#define NFD_NATQ2PF(_nat) 0
+#define NFD_NATQ2PFQ(_nat) 0
+#define NFD_PF2NATQ(_pf, _q) 0
+#endif
+
+#ifdef NFD_USE_CTRL
+    #if (NFD_MAX_CTRL_QUEUES != 1 || NFD_MAX_CTRL != 1)
+        #error "Unsupported CTRL vNIC values"
+    #endif
+
+    #define NFD_NATQ2CTRL(_nat) 0
+    #define NFD_NATQ2CTRLQ(_nat) 0
+    #define NFD_CTRL2NATQ(_ctrl, _q) NFD_CTRL_QUEUE
+#else
+    #define NFD_NATQ2CTRL(_nat) 0
+    #define NFD_NATQ2CTRLQ(_nat) 0
+    #define NFD_CTRL2NATQ(_ctrl, _q) 0
+#endif
+
 
 #ifndef __NFP_LANG_ASM
 
 /* Provide NFD_EXTRACT_NATQ and NFD_NATQ2VNIC that select from
  * the above PF and VF macros as appropriate, if the configuration
  * allows compile time selection. */
-#if (((NFD_MAX_VFS != 0) && (NFD_MAX_VF_QUEUES != 0)) &&     \
-     ((NFD_MAX_PFS != 0) && (NFD_MAX_PF_QUEUES != 0)))
-    /* With no special knowledge about the natural queue, */
-    /* we need to test whether it is a PF queue or a VF */
-    /* queue, and handle each case differently. */
-#define NFD_EXTRACT_NATQ(_vnic, _vqn, _nat)                  \
+#define NFD_EXTRACT_NATQ(_type, _vnic, _vqn, _nat)           \
 do {                                                         \
-    if ((_nat) < (NFD_MAX_VF_QUEUES * NFD_MAX_VFS)) {        \
-         (_vnic) = NFD_NATQ2VF(_nat);                        \
-         (_vqn) = NFD_NATQ2VFQ(_nat);                        \
+    if (NFD_Q_IS_PF(_nat)) {                                 \
+        (_type) = NFD_VNIC_TYPE_PF;                          \
+        (_vnic) = NFD_NATQ2PF(_nat);                         \
+        (_vqn) = NFD_NATQ2PFQ(_nat);                         \
+    } else if (NFD_Q_IS_VF(_nat)) {                          \
+        (_type) = NFD_VNIC_TYPE_VF;                          \
+        (_vnic) = NFD_NATQ2VF(_nat);                         \
+        (_vqn) = NFD_NATQ2VFQ(_nat);                         \
     } else {                                                 \
-         (_vnic) = NFD_NATQ2PF(_nat);                        \
-         (_vqn) = NFD_NATQ2PFQ(_nat);                        \
+        (_type) = NFD_VNIC_TYPE_CTRL;                        \
+        (_vnic) = NFD_NATQ2CTRL(_nat);                       \
+        (_vqn) = NFD_NATQ2CTRLQ(_nat);                       \
     }                                                        \
 } while(0)
 
-#define NFD_NATQ2VNIC(_vnic, _nat)                \
-do {                                              \
-    if (_nat < (NFD_MAX_VF_QUEUES * NFD_MAX_VFS)) \
-        _vnic = NFD_NATQ2VF(_nat);                \
-    else                                          \
-        _vnic = NFD_NATQ2PF(_nat);                \
-} while(0)
+#endif /* __NFP_LANG_ASM */
 
-#elif ((NFD_MAX_PFS != 0) && (NFD_MAX_PF_QUEUES != 0))
-    /* We have PF queues only */
-#define NFD_EXTRACT_NATQ(_vnic, _vqn, _nat)       \
-do {                                              \
-    (_vnic) = NFD_NATQ2PF(_nat);                  \
-    (_vqn) = NFD_NATQ2PFQ(_nat);                  \
-} while(0)
 
-#define NFD_NATQ2VNIC(_vnic, _nat)                \
-do {                                              \
-        _vnic = NFD_NATQ2PF(_nat);                \
-} while(0)
+#define NFD_BUILD_NATQ(_type, _vnic, _vqn)                      \
+    (((_type) == NFD_VNIC_TYPE_PF) ? NFD_PF2NATQ(_vnic, _vqn) : \
+     ((_type) == NFD_VNIC_TYPE_VF) ? NFD_VF2NATQ(_vnic, _vqn) : \
+     NFD_CTRL2NATQ(_vnic, _vqn))
 
-#elif ((NFD_MAX_VFS != 0) && (NFD_MAX_VF_QUEUES != 0))
-    /* We have VF queues only */
-#define NFD_EXTRACT_NATQ(_vnic, _vqn, _nat)       \
-do {                                              \
-    (_vnic) = NFD_NATQ2VF(_nat);                  \
-    (_vqn) = NFD_NATQ2VFQ(_nat);                  \
-} while(0)                                        \
 
-#define NFD_NATQ2VNIC(_vnic, _nat)                \
-do {                                              \
-        _vnic = NFD_NATQ2VF(_nat);                \
-} while(0)
+/*
+ * Conversions between type:vNIC and vid
+ */
 
+#define NFD_VID2PF(_vid) ((_vid) - NFD_FIRST_PF)
+#define NFD_PF2VID(_pf) ((_pf) + NFD_FIRST_PF)
+
+#define NFD_VID2VF(_vid) (_vid)
+#define NFD_VF2VID(_vf) (_vf)
+
+#ifdef NFD_USE_CTRL
+#define NFD_VID2CTRL(_vid) 0
+#define NFD_CTRL2VID(_ctrl) NFD_CTRL_VNIC
 #else
-#error "PF and VF options imply that no queues are in use!"
-#endif /* NFD_EXTRACT_NATQ defines */
+#define NFD_VID2CTRL(_vid) 0
+#define NFD_CTRL2VID(_ctrl) 0
+#endif
+
+
+#ifndef __NFP_LANG_ASM
+
+#define NFD_VID2VNIC(_type, _vnic, _vid)            \
+do {                                                \
+    if (NFD_VID_IS_PF(_vid)) {                      \
+        (_type) = NFD_VNIC_TYPE_PF;                 \
+        (_vnic) = NFD_VID2PF(_vid);                 \
+    } else if (NFD_VID_IS_VF(_vid)) {               \
+        (_type) = NFD_VNIC_TYPE_VF;                 \
+        (_vnic) = NFD_VID2VF(_vid);                 \
+    } else {                                        \
+        (_type) = NFD_VNIC_TYPE_CTRL;               \
+        (_vnic) = NFD_VID2CTRL(_vid);               \
+    }                                               \
+} while (0)
 
 #endif /* __NFP_LANG_ASM */
 
+#define NFD_VNIC2VID(_type, _vnic)                                  \
+    (((_type) == NFD_VNIC_TYPE_PF) ? NFD_PF2VID(_vnic) :            \
+     ((_type) == NFD_VNIC_TYPE_VF) ? NFD_VF2VID(_vnic) :            \
+     NFD_CTRL2VID(_vnic))
+
 
 /*
- * Convert between NATQ and vNIC:queue represenations,
+ * Conversions between vid:queue to NATQ
+ */
+
+/* Config queues are a special case where the VID
+ * can be computed easily. The queue is known by definition. */
+#define NFD_CFGQ2VID(_cfg)                                              \
+    (NFD_Q_IS_PF(_cfg) ? NFD_PF2VID(NFD_NATQ2PF(_cfg)) :                \
+     (NFD_Q_IS_VF(_cfg)) ? NFD_VF2VID(NFD_NATQ2VF(_cfg)) :              \
+     NFD_CTRL2VID(NFD_NATQ2CTRL(_cfg)))
+
+
+#ifndef __NFP_LANG_ASM
+
+#define NFD_NATQ2VID(_vid, _vqn, _nat)                   \
+do {                                                     \
+    if (NFD_Q_IS_PF(_nat)) {                             \
+        (_vid) = NFD_PF2VID(NFD_NATQ2PF(_nat));          \
+        (_vqn) = NFD_NATQ2PFQ(_nat);                     \
+    } else if (NFD_Q_IS_VF(_nat)) {                      \
+        (_vid) = NFD_VF2VID(NFD_NATQ2VF(_nat));          \
+        (_vqn) = NFD_NATQ2VFQ(_nat);                     \
+    } else {                                             \
+        (_vid) = NFD_CTRL2VID(NFD_NATQ2CTRL(_nat));      \
+        (_vqn) = NFD_NATQ2CTRLQ(_nat);                   \
+    }                                                    \
+} while(0)
+
+#endif /* __NFP_LANG_ASM */
+
+#define NFD_VID2NATQ(_vid, _vqn)                                        \
+   (NFD_VID_IS_PF(_vid) ? NFD_PF2NATQ(NFD_VID2PF(_vid), _vqn) :         \
+    NFD_VID_IS_VF(_vid) ? NFD_VF2NATQ(NFD_VID2VF(_vid), _vqn) :         \
+    NFD_CTRL2NATQ(NFD_VID2CTRL(_vid), _vqn))
+
+
+/*
+ * Convert between QID and type:vNIC:queue represenations,
+ * using the natural queue number as an intermediate stage.
+ */
+#ifndef __NFP_LANG_ASM
+#define NFD_EXTRACT_QID(_type, _vnic, _vqn, _qid)        \
+    NFD_EXTRACT_NATQ(_type, _vnic, _vqn, NFD_BMQ2NATQ(_qid))
+#endif /* __NFP_LANG_ASM */
+
+#define NFD_BUILD_QID(_type, _vnic, _vqn)        \
+    NFD_NATQ2BMQ(NFD_BUILD_NATQ(_type, _vnic, _vqn))
+
+
+/*
+ * Convert between QID and vid:queue represenations,
  * using the natural queue number as an intermediate stage.
  */
 
-#define NFD_EXTRACT_QID(_vnic, _vqn, _qid)              \
-    NFD_EXTRACT_NATQ(_vnic, _vqn, NFD_BMQ2NATQ(_qid))
+#ifndef __NFP_LANG_ASM
+#define NFD_QID2VID(_vid, _vqn, _qid)               \
+    NFD_NATQ2VID(_vid, _vqn, NFD_BMQ2NATQ(_qid))
+#endif /* __NFP_LANG_ASM */
 
-#if NFD_MAX_PFS < 2
-#define NFD_BUILD_NATQ(_vnic, _vqn)            \
-    ((_vnic) * NFD_MAX_VF_QUEUES + (_vqn))
-#else /* NFD_MAX_PFS < 2 */
-#if NFD_MAX_VFS > 0
-#define NFD_BUILD_NATQ(_vnic, _vqn)                             \
-    ((NFD_VNIC_IS_VF(_vnic)) ?                                  \
-     ((_vnic) * NFD_MAX_VF_QUEUES + (_vqn)) :                   \
-     ((NFD_MAX_VFS * NFD_MAX_VF_QUEUES) +                       \
-      (((_vnic) - NFD_MAX_VFS) * NFD_MAX_PF_QUEUES) + (_vqn)))
-#else /* NFD_MAX_VFS > 0 */
-#define NFD_BUILD_NATQ(_vnic, _vqn)             \
-    ((_vnic) * NFD_MAX_PF_QUEUES + (_vqn))
-#endif /* NFD_MAX_VFS > 0 */
-#endif /* NFD_MAX_PFS < 2 */
+#define NFD_VID2QID(_vid, _vqn)                 \
+    NFD_NATQ2BMQ(NFD_VID2NATQ(_vid, _vqn))
 
-#define NFD_BUILD_QID(_vnic, _vqn) \
-    NFD_NATQ2BMQ(NFD_BUILD_NATQ(_vnic, _vqn))
 
 /*
  * Convert between the queue controller queues and natural queues.
  * Each natural queue has a block of 4 QC queues allocated to it.  Different
@@ -330,12 +430,12 @@ do {                                    
  * to a natural queue does not, as a >> operator eliminates the low bits.
  * The defines to specify the types are as follows: NFD_OUT_FL_QUEUE,
  * NFD_IN_TX_QUEUE, and NFD_CFG_QUEUE.
  */
-#define NFD_NATQ2QC(_nat_q, _type)             \
-    ((_nat_q << 2) | _type)
+#define NFD_NATQ2QC(_nat_q, _qc_type)           \
+    (((_nat_q) << 2) | (_qc_type))
 
-#define NFD_QC2NATQ(_qc_q)                     \
-    (_qc_q >> 2)
+#define NFD_QC2NATQ(_qc_q)                      \
+    ((_qc_q) >> 2)
 
 
 #endif /* __NFD_COMMON_H */
diff --git a/me/blocks/vnic/nfd_common.uc b/me/blocks/vnic/nfd_common.uc
--- a/me/blocks/vnic/nfd_common.uc
+++ b/me/blocks/vnic/nfd_common.uc
@@ -35,137 +35,455 @@
 #define NFD_PCIE_ISL_BASE 4
 #endif /* NFD_PCIE_ISL_BASE */
 
 
-#define _NFD_TOTAL_VFQS (NFD_MAX_VFS * NFD_MAX_VF_QUEUES)
+#macro nfd_extract_vf_q(out_t, out_f, out_fq, in_q, VF_TGT)
+.begin
+    #if (NFD_MAX_VF_QUEUES != 0)
+        #if (!streq('out_t', '--'))
+            move(out_t, NFD_VNIC_TYPE_VF)
+        #endif
 
+        #if (!streq('out_f', '--'))
+            alu[out_f, --, B, in_q, >>(log2(NFD_MAX_VF_QUEUES))]
+        #endif
 
-#macro nfd_q_extract(out_ispf, out_f, out_fq, in_q)
+        #if (!streq('out_fq', '--'))
+            alu[out_fq, in_q, AND, (NFD_MAX_VF_QUEUES - 1)]
+        #endif
+
+        #if (!streq('VF_TGT', '--'))
+            br[VF_TGT]
+        #endif
+    #else
+        #error "Compile options don't support VF queues"
+    #endif
+.end
+#endm
+
+
+#macro nfd_extract_ctrl_q(out_t, out_f, out_fq, in_q, CTRL_TGT)
+.begin
+    #ifdef NFD_USE_CTRL
+        #if (NFD_MAX_CTRL_QUEUES != 1 || NFD_MAX_CTRL != 1)
+            #error "Unsupported CTRL vNIC values"
+        #endif
+
+        #if (!streq('out_t', '--'))
+            move(out_t, NFD_VNIC_TYPE_CTRL)
+        #endif
+
+        #if (!streq('out_f', '--'))
+            move(out_f, 0)
+        #endif
+
+        #if (!streq('out_fq', '--'))
+            move(out_f, 0)
+        #endif
+
+        #if (!streq('CTRL_TGT', '--'))
+            br[CTRL_TGT]
+        #endif
+    #else
+        #error "Compile options don't support CTRL queues"
+    #endif
+.end
+#endm
+
+
+#macro nfd_extract_pf_q(out_t, out_f, out_fq, in_q, PF_TGT)
+.begin
+    #if (NFD_MAX_PF_QUEUES != 0)
+        #if (!streq('out_t', '--'))
+            move(out_t, NFD_VNIC_TYPE_PF)
+        #endif
+
+
+        #if (isnum(in_q))
+            #if (!streq('out_f', '--'))
+                move(out_f, NFD_NATQ2PF(in_q))
+            #endif
+
+            #if (!streq('out_fq', '--'))
+                move(out_fq, NFD_NATQ2PF(in_q))
+            #endif
+        #else
+            #if (!streq('out_f', '--') || !streq('out_fq', '--'))
+                .reg pf_q
+
+                alu[pf_q, in_q, -, NFD_FIRST_PF_QUEUE]
+
+                #if (!streq('out_f', '--'))
+                    alu[out_f, --, b, pf_q, >>(log2(NFD_MAX_PF_QUEUES))]
+                #endif
+
+                #if (!streq('out_fq', '--'))
+                    alu[out_fq, pf_q, and, (NFD_MAX_PF_QUEUES - 1)]
+                #endif
+            #endif
+        #endif
+
+        #if (!streq('PF_TGT', '--'))
+            br[PF_TGT]
+        #endif
+    #else
+        #error "Compile options don't support PF queues"
+    #endif
+.end
+#endm
+
+
+#macro nfd_q_extract(out_t, out_f, out_fq, in_q, VF_TGT, CTRL_TGT, PF_TGT)
 .begin
 
-    #if (streq('out_ispf', '--') && streq('out_f', '--') && streq('out_fq', '--'))
-        #error "At least one of out_ispf, out_f or out_fq must be specified"
+    #if (streq('out_t', '--') && streq('out_f', '--') && streq('out_fq', '--'))
+        #error "At least one of out_type, out_f or out_fq must be specified"
     #endif
 
     #if (isnum(in_q))
 
-        #if (in_q < _NFD_TOTAL_VFQS)
-
-            #if (!streq('out_ispf', '--'))
-                move(out_ispf, 0)
-            #endif
-
-            #if (!streq('out_f', '--'))
-                move(out_f, (in_q / NFD_MAX_VF_QUEUES))
-            #endif
-
-            #if (!streq('out_fq', '--'))
-                move(out_fq, (in_q % NFD_MAX_VF_QUEUES))
-            #endif
-
+        #if (NFD_Q_IS_PF(in_q))
+            nfd_extract_pf_q(out_t, out_f, out_fq, in_q, PF_TGT)
+        #elif (NFD_Q_IS_VF(in_q))
+            nfd_extract_vf_q(out_t, out_f, out_fq, in_q, VF_TGT)
+        #elif (NFD_Q_IS_CTRL(in_q))
+            nfd_extract_ctrl_q(out_t, out_f, out_fq, in_q, CTRL_TGT)
         #else
-
-            #if (!streq('out_ispf', '--'))
-                move(out_ispf, 1)
-            #endif
-
-            #if (!streq('out_f', '--'))
-                move(out_f, 0)
-            #endif
-
-            #if (!streq('out_fq', '--'))
-                move(out_fq, ((in_q - _NFD_TOTAL_VFQS) % NFD_MAX_PF_QUEUES))
-            #endif
-
+            #error "Invalid queue number"
         #endif
 
     #else
 
-        .if (in_q < _NFD_TOTAL_VFQS)
-
-            #if (!streq('out_ispf', '--'))
-                move(out_ispf, 0)
-            #endif
-
-            #if (!streq('out_f', '--'))
-                alu[out_f, --, B, in_q, >>(log2(NFD_MAX_VF_QUEUES))]
-            #endif
-
-            #if (!streq('out_fq', '--'))
-                alu[out_fq, in_q, AND, (NFD_MAX_VF_QUEUES - 1)]
-            #endif
-
-        .else
-
-            #if (!streq('out_ispf', '--'))
-                move(out_ispf, 1)
-            #endif
-
-            #if (!streq('out_f', '--') || !streq('out_fq', '--'))
-
-                #if (!streq('out_f', '--'))
-                    move(out_f, 0)
-                #endif
-
-                #if (!streq('out_fq', '--'))
-                    alu[out_fq, in_q, -, _NFD_TOTAL_VFQS]
-                #endif
-
-            #endif
-
-        .endif
+        #if ((NFD_MAX_VFS != 0) && (NFD_MAX_PFS != 0) && defined(NFD_USE_CTRL))
+            .if (NFD_Q_IS_PF(in_q))
+                nfd_extract_pf_q(out_t, out_f, out_fq, in_q, PF_TGT)
+            .elif (NFD_Q_IS_VF(in_q))
+                nfd_extract_vf_q(out_t, out_f, out_fq, in_q, VF_TGT)
+            .else
+                nfd_extract_ctrl_q(out_t, out_f, out_fq, in_q, CTRL_TGT)
+            .endif
+        #elif ((NFD_MAX_PFS != 0) && defined(NFD_USE_CTRL))
+            .if (NFD_Q_IS_PF(in_q))
+                nfd_extract_pf_q(out_t, out_f, out_fq, in_q, PF_TGT)
+            .else
+                nfd_extract_ctrl_q(out_t, out_f, out_fq, in_q, CTRL_TGT)
+            .endif
+        #elif ((NFD_MAX_VFS != 0) && (NFD_MAX_PFS != 0))
+            .if (NFD_Q_IS_PF(in_q))
+                nfd_extract_pf_q(out_t, out_f, out_fq, in_q, PF_TGT)
+            .else
+                nfd_extract_vf_q(out_t, out_f, out_fq, in_q, VF_TGT)
+            .endif
+        #elif (NFD_MAX_PFS != 0)
+            nfd_extract_pf_q(out_t, out_f, out_fq, in_q, PF_TGT)
+        #elif (NFD_MAX_VFS != 0)
+            nfd_extract_vf_q(out_t, out_f, out_fq, in_q, VF_TGT)
+        #else
+            #error "Unsupported vNIC parameters"
+        #endif
 
     #endif
 .end
 #endm
 
 
+#macro nfd_q_extract(out_t, out_f, out_fq, in_q)
+    nfd_q_extract(out_t, out_f, out_fq, in_q, --, --, --)
+#endm
+
+
 #macro nfd_build_vf_q(out_q, in_vf, in_vfq)
 .begin
-    #if (isnum(in_vf) && isnum(in_vfq))
-        move(out_q, NFD_BUILD_QID(in_vf, in_vfq))
+    #if (NFD_MAX_VF_QUEUES != 0)
+        #if (isnum(in_vf) && isnum(in_vfq))
+            move(out_q, NFD_BUILD_QID(NFD_VNIC_TYPE_VF, in_vf, in_vfq))
+        #else
+            alu[out_q, in_vfq, OR, in_vf, <<(log2(NFD_MAX_VF_QUEUES))]
+        #endif
     #else
-        alu[out_q, in_vfq, OR, in_vf, <<(log2(NFD_MAX_VF_QUEUES))]
+        #error "Compile options don't support VF queues"
     #endif
 .end
 #endm
 
 
-#macro nfd_build_pf_q(out_q, in_pfq)
+#macro nfd_build_ctrl_q(out_q, in_ctrlf, in_ctrlq)
 .begin
-    #if (isnum(in_pf) && isnum(in_pfq))
-        move(out_q, (_NFD_TOTAL_VFQS + in_pfq))
+    #ifdef NFD_USE_CTRL
+        #if (isnum(in_ctrlf) && isnum(in_ctrlq))
+            move(out_q, NFD_BUILD_QID(NFD_VNIC_TYPE_CTRL, in_ctrlf, in_ctrlq))
+        #else
+            #if (NFD_MAX_CTRL_QUEUES != 1 || NFD_MAX_CTRL != 1)
+                #error "Unsupported CTRL vNIC values"
+            #endif
+            move(out_q, NFD_CTRL_QUEUE)
+        #endif
     #else
-        alu[out_q, _NFD_TOTAL_VFQS, +, in_pfq]
+        #error "Compile options don't support CTRL queues"
     #endif
 .end
 #endm
 
 
-#macro nfd_build_q(out_q, in_ispf, in_f, in_fq)
+#macro nfd_build_pf_q(out_q, in_pf, in_pfq)
 .begin
-    #if (isnum(in_ispf))
+    #if (NFD_MAX_PF_QUEUES != 0)
+        #if (isnum(in_pf) && isnum(in_pfq))
+            move(out_q, NFD_BUILD_QID(NFD_VNIC_TYPE_PF, in_pf, in_pfq))
+        #else
+            alu[out_q, in_pfq, or, in_pf, <<(log2(NFD_MAX_PF_QUEUES))]
+            alu[out_q, NFD_FIRST_PF_QUEUE, +, out_q]
+        #endif
+    #else
+        #error "Compile options don't support PF queues"
+    #endif
+.end
+#endm
 
-        #if (in_ispf)
-            nfd_build_pf_q(out_q, in_fq)
+
+#macro nfd_build_q(out_q, in_t, in_f, in_fq)
+.begin
+    #if (isnum(in_t))
+        #if (in_t == NFD_VNIC_TYPE_PF)
+            nfd_build_pf_q(out_q, in_f, in_fq)
+        #elif (in_t == NFD_VNIC_TYPE_VF)
+            nfd_build_vf_q(out_q, in_f, in_fq)
+        #elif (in_t == NFD_VNIC_TYPE_CTRL)
+            nfd_build_ctrl_q(out_q, in_f, in_fq)
         #else
+            #error "Illegal vNIC type"
+        #endif
+    #else
+        #if ((NFD_MAX_VFS != 0) && (NFD_MAX_PFS != 0) && defined(NFD_USE_CTRL))
+            .if (in_t == NFD_VNIC_TYPE_PF)
+                nfd_build_pf_q(out_q, in_f, in_fq)
+            .elif (in_t == NFD_VNIC_TYPE_VF)
+                nfd_build_vf_q(out_q, in_f, in_fq)
+            .else
+                nfd_build_ctrl_q(out_q, in_f, in_fq)
+            .endif
+        #elif ((NFD_MAX_PFS != 0) && defined(NFD_USE_CTRL))
+            .if (in_t == NFD_VNIC_TYPE_PF)
+                nfd_build_pf_q(out_q, in_f, in_fq)
+            .else
+                nfd_build_ctrl_q(out_q, in_f, in_fq)
+            .endif
+        #elif ((NFD_MAX_VFS != 0) && (NFD_MAX_PFS != 0))
+            .if (in_t == NFD_VNIC_TYPE_PF)
+                nfd_build_pf_q(out_q, in_f, in_fq)
+            .else
+                nfd_build_vf_q(out_q, in_f, in_fq)
+            .endif
+        #elif (NFD_MAX_PFS != 0)
+            nfd_build_pf_q(out_q, in_f, in_fq)
+        #elif (NFD_MAX_VFS != 0)
             nfd_build_vf_q(out_q, in_f, in_fq)
+        #else
+            #error "Unsupported vNIC parameters"
         #endif
+    #endif
+.end
+#endm
 
+
+#macro nfd_vid2natq(out_natq, in_vid, in_q)
+.begin
+    #if (isnum(in_vid) && isnum(in_q))
+        move(out_natq, NFD_VID2NATQ(in_vid, in_q))
     #else
+        .reg vnic
 
-        .if (BIT(in_ispf, 0) == 0)
-
-            nfd_build_vf_q(out_q, in_f, in_fq)
-
-        .else
-
-            nfd_build_pf_q(out_q, in_fq)
-
-        .endif
+        #if ((NFD_MAX_VFS != 0) && (NFD_MAX_PFS != 0) && defined(NFD_USE_CTRL))
+            .if (NFD_VID_IS_PF(in_vid))
+                alu[vnic, in_vid, -, NFD_FIRST_PF]
+                nfd_build_pf_q(out_natq, vnic, in_q)
+            .elif (NFD_VID_IS_VF(in_vid))
+                nfd_build_vf_q(out_natq, in_vid, in_q)
+            .else
+                nfd_build_ctrl_q(out_natq, 0, 0)
+            .endif
+        #elif ((NFD_MAX_PFS != 0) && defined(NFD_USE_CTRL))
+            .if (NFD_VID_IS_PF(in_vid))
+                alu[vnic, in_vid, -, NFD_FIRST_PF]
+                nfd_build_pf_q(out_natq, vnic, in_q)
+            .else
+                nfd_build_ctrl_q(out_natq, 0, 0)
+            .endif
+        #elif ((NFD_MAX_VFS != 0) && (NFD_MAX_PFS != 0))
+            .if (NFD_VID_IS_PF(in_vid))
+                alu[vnic, in_vid, -, NFD_FIRST_PF]
+                nfd_build_pf_q(out_natq, vnic, in_q)
+            .else
+                nfd_build_vf_q(out_natq, in_vid, in_q)
+            .endif
+        #elif (NFD_MAX_PFS != 0)
+            alu[vnic, in_vid, -, NFD_FIRST_PF]
+            nfd_build_pf_q(out_natq, vnic, in_q)
+        #elif (NFD_MAX_VFS != 0)
+                nfd_build_vf_q(out_natq, in_vid, in_q)
+        #else
+            #error "Unsupported vNIC parameters"
+        #endif
 
     #endif
 .end
 #endm
 
 
+#macro nfd_vid2qid(out_qid, in_vid, in_q)
+    nfd_vid2natq(out_qid, in_vid, in_q)
+#endm
+
+
+#macro nfd_vnic2vid(out_vid, in_t, in_f)
+.begin
+    #ifdef NFD_USE_CTRL
+        #if (NFD_MAX_CTRL_QUEUES != 1 || NFD_MAX_CTRL != 1)
+            #error "Unsupported CTRL vNIC values"
+        #endif
+    #endif
+
+    #if (isnum(in_t) && isnum(in_f))
+        move(out_vid, NFD_VNIC2VID(in_t, in_f))
+    #elif (isnum(in_t))
+        #if (in_t == NFD_VNIC_TYPE_PF)
+            alu[out_vid, in_f, +, NFD_FIRST_PF]
+        #elif (in_t == NFD_VNIC_TYPE_VF)
+            alu[out_vid, --, b, in_f]
+        #elif (in_t == NFD_VNIC_TYPE_CTRL)
+            #if (NFD_MAX_CTRL_QUEUES != 1 || NFD_MAX_CTRL != 1)
+                #error "Unsupported CTRL vNIC values"
+            #endif
+            move(out_vid, NFD_CTRL_VNIC)
+        #else
+            #error "Illegal vNIC type"
+        #endif
+    #else
+        #if ((NFD_MAX_VFS != 0) && (NFD_MAX_PFS != 0) && defined(NFD_USE_CTRL))
+            .if (in_t == NFD_VNIC_TYPE_PF)
+                alu[out_vid, in_f, +, NFD_FIRST_PF]
+            .elif (in_t == NFD_VNIC_TYPE_VF)
+                alu[out_vid, --, b, in_f]
+            .else
+                move(out_vid, NFD_CTRL_VNIC)
+            .endif
+        #elif ((NFD_MAX_PFS != 0) && defined(NFD_USE_CTRL))
+            .if (in_t == NFD_VNIC_TYPE_PF)
+                alu[out_vid, in_f, +, NFD_FIRST_PF]
+            .else
+                move(out_vid, NFD_CTRL_VNIC)
+            .endif
+        #elif ((NFD_MAX_VFS != 0) && (NFD_MAX_PFS != 0))
+            .if (in_t == NFD_VNIC_TYPE_PF)
+                alu[out_vid, in_f, +, NFD_FIRST_PF]
+            .else (in_t == NFD_VNIC_TYPE_VF)
+                alu[out_vid, --, b, in_f]
+            .endif
+        #elif (NFD_MAX_PFS != 0)
+                alu[out_vid, in_f, +, NFD_FIRST_PF]
+        #elif (NFD_MAX_VFS != 0)
+                alu[out_vid, --, b, in_f]
+        #else
+            #error "Unsupported vNIC parameters"
+        #endif
+    #endif
+.end
+#endm
+
+
+#macro nfd_vid2vf(out_t, out_f, in_vid, VF_TGT)
+.begin
+    move(out_t, NFD_VNIC_TYPE_VF)
+    move(out_f, in_vid)
+
+    #if (!streq('VF_TGT', '--'))
+        br[VF_TGT]
+    #endif
+.end
+#endm
+
+
+#macro nfd_vid2ctrl(out_t, out_f, in_vid, CTRL_TGT)
+.begin
+    #if (NFD_MAX_CTRL_QUEUES != 1 || NFD_MAX_CTRL != 1)
+        #error "Unsupported CTRL vNIC values"
+    #endif
+
+    move(out_t, NFD_VNIC_TYPE_CTRL)
+    move(out_f, 0)
+
+    #if (!streq('CTRL_TGT', '--'))
+        br[CTRL_TGT]
+    #endif
+.end
+#endm
+
+
+#macro nfd_vid2pf(out_t, out_f, in_vid, PF_TGT)
+.begin
+    move(out_t, NFD_VNIC_TYPE_PF)
+
+    #if (isnum(in_vid))
+        move(out_f, (in_vid - NFD_FIRST_PF))
+    #else
+        alu[out_f, in_vid, -, NFD_FIRST_PF]
+    #endif
+
+    #if (!streq('PF_TGT', '--'))
+        br[PF_TGT]
+    #endif
+.end
+#endm
+
+
+#macro nfd_vid2vnic(out_t, out_f, in_vid, VF_TGT, CTRL_TGT, PF_TGT)
+.begin
+    #if (isnum(in_vid))
+
+        #if (NFD_VID_IS_PF(in_vid))
+            nfd_vid2pf(out_t, out_f, in_vid, PF_TGT)
+        #elif (NFD_VID_IS_VF(in_vid))
+            nfd_vid2vf(out_t, out_f, in_vid, VF_TGT)
+        #elif (NFD_VID_IS_CTRL(in_vid))
+            nfd_vid2ctrl(out_t, out_f, in_vid, CTRL_TGT)
+        #else
+            #error "Invalid vid number"
+        #endif
+    #else
+        #if ((NFD_MAX_VFS != 0) && (NFD_MAX_PFS != 0) && defined(NFD_USE_CTRL))
+            .if (NFD_VID_IS_PF(in_vid))
+                nfd_vid2pf(out_t, out_f, in_vid, PF_TGT)
+            .elif (NFD_VID_IS_VF(in_vid))
+                nfd_vid2vf(out_t, out_f, in_vid, VF_TGT)
+            .else
+                nfd_vid2ctrl(out_t, out_f, in_vid, CTRL_TGT)
+            .endif
+        #elif ((NFD_MAX_PFS != 0) && defined(NFD_USE_CTRL))
+            .if (NFD_VID_IS_PF(in_vid))
+                nfd_vid2pf(out_t, out_f, in_vid, PF_TGT)
+            .else
+                nfd_vid2ctrl(out_t, out_f, in_vid, CTRL_TGT)
+            .endif
+        #elif ((NFD_MAX_VFS != 0) && (NFD_MAX_PFS != 0))
+            .if (NFD_VID_IS_PF(in_vid))
+                nfd_vid2pf(out_t, out_f, in_vid, PF_TGT)
+            .else
+                nfd_vid2vf(out_t, out_f, in_vid, VF_TGT)
+            .endif
+        #elif (NFD_MAX_PFS != 0)
+            nfd_vid2pf(out_t, out_f, in_vid, PF_TGT)
+        #elif (NFD_MAX_VFS != 0)
+            nfd_vid2vf(out_t, out_f, in_vid, VF_TGT)
+        #else
+            #error "Unsupported vNIC parameters"
+        #endif
+
+    #endif
+.end
+#endm
+
+
+#macro nfd_vid2vnic(out_t, out_f, in_vid)
+    nfd_vid2vnic(out_t, out_f, in_vid, --, --, --)
+#endm
+
 #endif /* __NFD_COMMON_UC */
diff --git a/me/blocks/vnic/nfd_stats.uc b/me/blocks/vnic/nfd_stats.uc
--- a/me/blocks/vnic/nfd_stats.uc
+++ b/me/blocks/vnic/nfd_stats.uc
@@ -21,21 +21,24 @@
 #define __NFD_STATS_UC
 
 #include <nfd_user_cfg.h>
 
+#include <vnic/nfd_common.h>
+
 #ifndef NFD_MAX_PFS
 #error "NFD_MAX_PFS is not defined but is required"
 #endif
 
+
 /* Each statistic is a 64-bit count + a 64-bit byte-count */
 #define NFD_STAT_SIZE   16
 
 
 #define NFD_STAT_MAX_QUEUES     64
 
 #macro _nfd_stat_declare_help(NAME)
 
-    #if ((NFD_MAX_VFS * NFD_MAX_VF_QUEUES + NFD_MAX_PFS * NFD_MAX_PF_QUEUES) > NFD_STAT_MAX_QUEUES)
+    #if ((NFD_TOTAL_VFQS + NFD_TOTAL_CTRLQS + NFD_TOTAL_PFQS) > NFD_STAT_MAX_QUEUES)
         #error "Total number of NFD queues per island cannot exceed NFD_STAT_MAX_QUEUES"
     #endif
 
     #define_eval __STATSZ (NFD_MAX_ISL * NFD_STAT_MAX_QUEUES * NFD_STAT_SIZE)
diff --git a/me/blocks/vnic/pci_in.c b/me/blocks/vnic/pci_in.c
--- a/me/blocks/vnic/pci_in.c
+++ b/me/blocks/vnic/pci_in.c
@@ -153,9 +153,9 @@ nfd_in_recv(unsigned int pcie_isl, unsig
 {
     unsigned int pkt_count;
     unsigned long long byte_count;
     __xwrite unsigned long long xfer_update[2];
-    int vnic;
+    int vid;
     int vqn;
 
     ctassert(__is_ct_const(sync));
     ctassert(sync == sig_done || sync == ctx_swap);
@@ -166,10 +166,10 @@ nfd_in_recv(unsigned int pcie_isl, unsig
     if (pkt_count != 0) {
         xfer_update[0] = swapw64(pkt_count);
         xfer_update[1] = swapw64(byte_count);
         /* Support a single PCIE island */
-        NFD_EXTRACT_NATQ(vnic, vqn, bmsk_queue);
-        __mem_add64(xfer_update, (NFD_CFG_BAR_ISL(0/*PCIE_ISL*/, vnic) +
+        NFD_QID2VID(vid, vqn, bmsk_queue);
+        __mem_add64(xfer_update, (NFD_CFG_BAR_ISL(0/*PCIE_ISL*/, vid) +
                     NFP_NET_CFG_TXR_STATS(vqn)),
                     sizeof xfer_update, sizeof xfer_update, sync, sig);
     }
 }
@@ -214,12 +214,12 @@ nfd_in_fill_meta(void *pkt_info,
 }
 
 
 __intrinsic void
-nfd_in_map_queue(unsigned int *vnic, unsigned int *queue,
+nfd_in_map_queue(unsigned int *type, unsigned int *vnic, unsigned int *queue,
                  unsigned int nfd_queue)
 {
-    NFD_EXTRACT_QID(*vnic, *queue, nfd_queue);
+    NFD_EXTRACT_QID(*type, *vnic, *queue, nfd_queue);
 }
 
 
 __intrinsic unsigned int
diff --git a/me/blocks/vnic/pci_in.h b/me/blocks/vnic/pci_in.h
--- a/me/blocks/vnic/pci_in.h
+++ b/me/blocks/vnic/pci_in.h
@@ -23,8 +23,9 @@
 #include <pkt/pkt.h>
 
 #include <nfd_user_cfg.h>
 
+#include <nfd_common.h>
 #include "shared/nfd_net.h"
 #include "shared/nfd_api_common.h"
 
 
@@ -371,14 +372,15 @@ struct nfd_in_pkt_desc {
 
 
 /**
  * Map an NFD bitmask queue to a vnic, queue number pair.
- * @param vnic      vNIC as seen by the host
+ * @param type      vNIC type as seen by the host
+ * @param vnic      vNIC within type as seen by the host
  * @param queue     Queue number within the vNIC
  * @param nfd_queue Queue number within NFD numbering system
  */
-__intrinsic void nfd_in_map_queue(unsigned int *vnic, unsigned int *queue,
-                                  unsigned int nfd_queue);
+__intrinsic void nfd_in_map_queue(unsigned int *type, unsigned int *vnic,
+                                  unsigned int *queue, unsigned int nfd_queue);
 
 /**
  * Get the length of the packet excluding metadata.
  * @param nfd_in_meta   PCI.IN descriptor for the packet
diff --git a/me/blocks/vnic/pci_in/issue_dma.c b/me/blocks/vnic/pci_in/issue_dma.c
--- a/me/blocks/vnic/pci_in/issue_dma.c
+++ b/me/blocks/vnic/pci_in/issue_dma.c
@@ -392,19 +392,9 @@ issue_dma_vnic_setup(struct nfd_cfg_msg 
     if (cfg_msg->error || !cfg_msg->interested) {
         return;
     }
 
-    #if NFD_MAX_PFS < 2
-        queue += cfg_msg->vnic * NFD_MAX_VF_QUEUES;
-    #else
-    if (NFD_VNIC_IS_PF(cfg_msg->vnic))
-        queue += ((NFD_MAX_VFS * NFD_MAX_VF_QUEUES) +
-                   ((cfg_msg->vnic - NFD_MAX_VFS) * NFD_MAX_PF_QUEUES));
-    else
-        queue += cfg_msg->vnic * NFD_MAX_VF_QUEUES;
-    #endif
-
-    bmsk_queue = NFD_NATQ2BMQ(queue);
+    bmsk_queue = NFD_VID2QID(cfg_msg->vid, queue);
 
     if (queue_data[bmsk_queue].locked) {
         /* The queue is locked by the worker contexts so
          * we can't change it's configuration.  Revert the
@@ -417,10 +407,10 @@ issue_dma_vnic_setup(struct nfd_cfg_msg 
         queue_data[bmsk_queue].sp0 = 0;
         queue_data[bmsk_queue].lso_offhdr = 0;
         queue_data[bmsk_queue].lso_seq_cnt = 0;
         queue_data[bmsk_queue].rid = 0;
-        if (NFD_VNIC_IS_VF(cfg_msg->vnic)) {
-            queue_data[bmsk_queue].rid = cfg_msg->vnic + NFD_CFG_VF_OFFSET;
+        if (NFD_VID_IS_VF(cfg_msg->vid)) {
+            queue_data[bmsk_queue].rid = cfg_msg->vid + NFD_CFG_VF_OFFSET;
         }
         queue_data[bmsk_queue].cont = 0;
         queue_data[bmsk_queue].up = 1;
         queue_data[bmsk_queue].jumbo = 0;
diff --git a/me/blocks/vnic/pci_in/service_qc.c b/me/blocks/vnic/pci_in/service_qc.c
--- a/me/blocks/vnic/pci_in/service_qc.c
+++ b/me/blocks/vnic/pci_in/service_qc.c
@@ -121,9 +121,9 @@ service_qc_vnic_setup(struct nfd_cfg_msg
     if (cfg_msg->error || !cfg_msg->interested) {
         return;
     }
 
-    queue = NFD_BUILD_NATQ(cfg_msg->vnic, queue);
+    queue = NFD_VID2NATQ(cfg_msg->vid, queue);
     bmsk_queue = NFD_NATQ2BMQ(queue);
 
     txq.watermark    = NFP_QC_STS_HI_WATERMARK_4;
     txq.event_data   = NFD_EVENT_DATA;
@@ -137,10 +137,10 @@ service_qc_vnic_setup(struct nfd_cfg_msg
         queue_data[bmsk_queue].tx_w = 0;
         queue_data[bmsk_queue].tx_s = 0;
         queue_data[bmsk_queue].ring_sz_msk = ((1 << ring_sz) - 1);
         queue_data[bmsk_queue].requester_id = 0;
-        if (NFD_VNIC_IS_VF(cfg_msg->vnic)) {
-            queue_data[bmsk_queue].requester_id = (cfg_msg->vnic +
+        if (NFD_VID_IS_VF(cfg_msg->vid)) {
+            queue_data[bmsk_queue].requester_id = (cfg_msg->vid +
                                                    NFD_CFG_VF_OFFSET);
         }
         queue_data[bmsk_queue].spare0 = 0;
         queue_data[bmsk_queue].up = 1;
diff --git a/me/blocks/vnic/pci_in_me0.c b/me/blocks/vnic/pci_in_me0.c
--- a/me/blocks/vnic/pci_in_me0.c
+++ b/me/blocks/vnic/pci_in_me0.c
@@ -44,8 +44,9 @@
 
 NFD_CFG_DECLARE(nfd_cfg_sig_pci_in, nfd_cfg_sig_pci_in0);
 NFD_INIT_DONE_DECLARE;
 
+NFD_CFG_CTRL_DECLARE(PCIE_ISL);
 NFD_CFG_PF_DECLARE(PCIE_ISL);
 
 struct nfd_cfg_msg cfg_msg;
 
@@ -131,19 +132,19 @@ main(void)
 
             /* Either check for a message, or perform one tick of processing
              * on the message each loop iteration */
             if (!cfg_msg.msg_valid) {
-                int curr_vnic;
+                int curr_vid;
 
-                curr_vnic = nfd_cfg_next_flr((void *) &cfg_msg);
+                curr_vid = nfd_cfg_next_flr((void *) &cfg_msg);
 
-                if (curr_vnic < 0) {
+                if (curr_vid < 0) {
                     /* No FLRs to process, look for a host message. */
-                    curr_vnic = nfd_cfg_next_vnic();
+                    curr_vid = nfd_cfg_next_vnic();
 
-                    if (curr_vnic >= 0) {
+                    if (curr_vid >= 0) {
                         cfg_msg.__raw = 0;
-                        cfg_msg.vnic = curr_vnic;
+                        cfg_msg.vid = curr_vid;
                         cfg_msg.msg_valid = 1;
 
                         nfd_cfg_parse_msg((void *) &cfg_msg, NFD_CFG_PCI_IN0);
                     }
diff --git a/me/blocks/vnic/pci_out.c b/me/blocks/vnic/pci_out.c
--- a/me/blocks/vnic/pci_out.c
+++ b/me/blocks/vnic/pci_out.c
@@ -90,11 +90,11 @@ nfd_out_send_init()
 }
 
 
 __intrinsic unsigned int
-nfd_out_map_queue(unsigned int vnic, unsigned int queue)
+nfd_out_map_queue(unsigned int type, unsigned int vnic, unsigned int queue)
 {
-    return NFD_BUILD_QID(vnic, queue);
+    return NFD_BUILD_QID(type, vnic, queue);
 }
 
 
 /*
@@ -160,9 +160,9 @@ nfd_out_get_credit(unsigned int pcie_isl
 {
     unsigned int pkt_count;
     unsigned long long byte_count;
     __xwrite unsigned long long xfer_update[2];
-    int vnic;
+    int vid;
     int vqn;
 
     ctassert(__is_ct_const(sync));
     ctassert(sync == sig_done || sync == ctx_swap);
@@ -173,10 +173,10 @@ nfd_out_get_credit(unsigned int pcie_isl
     if (pkt_count != 0) {
         xfer_update[0] = swapw64(pkt_count);
         xfer_update[1] = swapw64(byte_count);
         /* Support a single PCIE island */
-        NFD_EXTRACT_NATQ(vnic, vqn, bmsk_queue);
-        __mem_add64(xfer_update, (NFD_CFG_BAR_ISL(0/*PCIE_ISL*/, vnic) +
+        NFD_QID2VID(vid, vqn, bmsk_queue);
+        __mem_add64(xfer_update, (NFD_CFG_BAR_ISL(0/*PCIE_ISL*/, vid) +
                     NFP_NET_CFG_RXR_STATS(vqn)),
                     sizeof xfer_update, sizeof xfer_update, sync, sig);
     }
 }
diff --git a/me/blocks/vnic/pci_out.h b/me/blocks/vnic/pci_out.h
--- a/me/blocks/vnic/pci_out.h
+++ b/me/blocks/vnic/pci_out.h
@@ -111,8 +111,9 @@ struct nfd_out_input {
 #include <nfd_user_cfg.h>
 
 #include <nfp_chipres.h>
 #include "shared/nfd_api_common.h"
+#include <nfd_common.h>
 
 /** \cond DOXYGEN_SHOULD_SKIP_THIS */
 
 #define NFD_OUT_RINGS_DECL_IND2(_isl, _emem)                            \
@@ -155,16 +156,18 @@ struct nfd_out_input {
 
 
 /**
  * Map a vNIC, queue number pair to an NFD queue number.
- * @param vnic      vNIC as seen by the host
+ * @param type      vNIC type as seen by the host
+ * @param vnic      vNIC within type as seen by the host
  * @param queue     Queue number within the vNIC
  * @return          The corresponding NFD queue number
  *
  * This method returns an NFD queue number (the numbering system used
  * internally in PCI.OUT and PCI.IN) from a vNIC, queue number pair.
  */
-__intrinsic unsigned int nfd_out_map_queue(unsigned int vnic,
+__intrinsic unsigned int nfd_out_map_queue(unsigned int type,
+                                           unsigned int vnic,
                                            unsigned int queue);
 
 
 /**
diff --git a/me/blocks/vnic/pci_out/cache_desc.c b/me/blocks/vnic/pci_out/cache_desc.c
--- a/me/blocks/vnic/pci_out/cache_desc.c
+++ b/me/blocks/vnic/pci_out/cache_desc.c
@@ -332,9 +332,9 @@ cache_desc_vnic_setup(struct nfd_cfg_msg
     if (cfg_msg->error || !cfg_msg->interested) {
         return;
     }
 
-    queue_s = NFD_BUILD_NATQ(cfg_msg->vnic, queue_s);
+    queue_s = NFD_VID2NATQ(cfg_msg->vid, queue_s);
     bmsk_queue = NFD_NATQ2BMQ(queue_s);
 
     rxq.watermark    = NFP_QC_STS_HI_WATERMARK_32; /* XXX Tune */
     rxq.event_data   = NFD_EVENT_DATA;
@@ -348,10 +348,10 @@ cache_desc_vnic_setup(struct nfd_cfg_msg
         queue_data[bmsk_queue].fl_w = 0;
         queue_data[bmsk_queue].fl_s = 0;
         queue_data[bmsk_queue].ring_sz_msk = ((1 << ring_sz) - 1);
         queue_data[bmsk_queue].requester_id = 0;
-        if (NFD_VNIC_IS_VF(cfg_msg->vnic)) {
-            queue_data[bmsk_queue].requester_id = (cfg_msg->vnic +
+        if (NFD_VID_IS_VF(cfg_msg->vid)) {
+            queue_data[bmsk_queue].requester_id = (cfg_msg->vid +
                                                    NFD_CFG_VF_OFFSET);
         }
         queue_data[bmsk_queue].spare0 = 0;
         queue_data[bmsk_queue].up = 1;
diff --git a/me/blocks/vnic/pci_out_me0.c b/me/blocks/vnic/pci_out_me0.c
--- a/me/blocks/vnic/pci_out_me0.c
+++ b/me/blocks/vnic/pci_out_me0.c
@@ -38,11 +38,8 @@ int
 main(void)
 {
     /* Perform per ME initialisation  */
     if (ctx() == 0) {
-        ctassert((NFD_MAX_VFS * NFD_MAX_VF_QUEUES +
-                  NFD_MAX_PFS * NFD_MAX_PF_QUEUES) <= 64);
-
         nfd_cfg_check_pcie_link(); /* Will halt ME on failure */
 
         nfd_cfg_init_cfg_msg(&nfd_cfg_sig_pci_out, &cfg_msg);
 
diff --git a/me/blocks/vnic/pci_out_sb.uc b/me/blocks/vnic/pci_out_sb.uc
--- a/me/blocks/vnic/pci_out_sb.uc
+++ b/me/blocks/vnic/pci_out_sb.uc
@@ -222,9 +222,9 @@
 .end
 #endm
 
 
-#macro _set_queue_state(in_vnic, in_q, in_up, in_rid)
+#macro _set_queue_state(in_vid, in_q, in_up, in_rid)
 .begin
 
     .reg qid
     .reg lma
@@ -232,30 +232,9 @@
     .reg currently_up
     .reg base_addr
     .reg tmp
 
-#if NFD_MAX_PFS < 2
-    #if (NFD_MAX_VF_QUEUES > 0)
-        alu[qid, in_q, OR, in_vnic, <<(log2(NFD_MAX_VF_QUEUES))]
-    #else
-        move(qid, in_q)
-    #endif
-#else
-    #if NFD_MAX_VFS == 0
-        alu[qid, in_q, OR, in_vnic, <<(log2(NFD_MAX_PF_QUEUES))]
-    #else
-    .if (NFD_VNIC_IS_PF(in_vnic))
-        alu[qid, --, b, NFD_MAX_VFS, <<(log2(NFD_MAX_VF_QUEUES))]
-        alu[tmp, in_vnic, -, NFD_MAX_VFS]
-        alu[tmp, --, B, tmp, <<(log2(NFD_MAX_PF_QUEUES))]
-        alu[qid, qid, +, tmp]
-        alu[qid, in_q, +, qid]
-    .else
-        alu[qid, in_q, OR, in_vnic, <<(log2(NFD_MAX_VF_QUEUES))]
-    .endif
-    #endif // NFD_MAX_VFS == 0
-#endif // NFD_MAX_PFS < 1
-
+    nfd_vid2qid(qid, in_vid, in_q)
 
     // Load the queue state for that queue
     alu[lma, --, B, qid, <<LM_QSTATE_SIZE_lg2]
     local_csr_wr[LM_QSTATE_CSR, lma]
@@ -290,9 +269,9 @@
 .end
 #endm
 
 
-#macro _check_vnic_state(in_vnic)
+#macro _check_vnic_state(in_vid)
 .begin
 
     .reg bar_addr_hi
     .reg bar_addr_lo
@@ -305,27 +284,55 @@
     .xfer_order $bar
 
     .sig read_sig
 
-    nfd_cfg_get_bar_addr(bar_addr_hi, bar_addr_lo, in_vnic, PCIE_ISL)
+    nfd_cfg_get_bar_addr(bar_addr_hi, bar_addr_lo, in_vid, PCIE_ISL)
     mem[read32, $bar[0], bar_addr_hi, <<8, bar_addr_lo, 6], ctx_swap[read_sig]
 
-    .if (NFD_VNIC_IS_VF(in_vnic))
-        move(maxqs, NFD_MAX_VF_QUEUES)
-        alu[rid, in_vnic, +, NFD_CFG_VF_OFFSET]
-    .else
+    #if ((NFD_MAX_VFS != 0) && (NFD_MAX_PFS != 0) && defined(NFD_USE_CTRL))
+        .if (NFD_VID_IS_PF(in_vid))
+            move(maxqs, NFD_MAX_PF_QUEUES)
+            immed[rid, 0]
+        .elif (NFD_VID_IS_VF(in_vid))
+            move(maxqs, NFD_MAX_VF_QUEUES)
+            alu[rid, in_vid, +, NFD_CFG_VF_OFFSET]
+        .else
+            move(maxqs, NFD_MAX_CTRL_QUEUES)
+            immed[rid, 0]
+        .endif
+    #elif ((NFD_MAX_PFS != 0) && defined(NFD_USE_CTRL))
+        .if (NFD_VID_IS_PF(in_vid))
+            move(maxqs, NFD_MAX_PF_QUEUES)
+            immed[rid, 0]
+        .else
+            move(maxqs, NFD_MAX_CTRL_QUEUES)
+            immed[rid, 0]
+        .endif
+    #elif ((NFD_MAX_VFS != 0) && (NFD_MAX_PFS != 0))
+        .if (NFD_VID_IS_PF(in_vid))
+            move(maxqs, NFD_MAX_PF_QUEUES)
+            immed[rid, 0]
+        .else
+            move(maxqs, NFD_MAX_VF_QUEUES)
+            alu[rid, in_vid, +, NFD_CFG_VF_OFFSET]
+        .endif
+    #elif (NFD_MAX_PFS != 0)
         move(maxqs, NFD_MAX_PF_QUEUES)
         immed[rid, 0]
-    .endif
-
+    #elif (NFD_MAX_VFS != 0)
+        move(maxqs, NFD_MAX_VF_QUEUES)
+        alu[rid, in_vid, +, NFD_CFG_VF_OFFSET]
+    #else
+        #error "Unsupported vNIC parameters"
+    #endif
 
     .if ($bar[NFP_NET_CFG_CTRL] & NFP_NET_CFG_CTRL_ENABLE == 0)
 
         move(up, 0)
         move(q, 0)
         .while (q < maxqs)
 
-            _set_queue_state(in_vnic, q, up, rid)
+            _set_queue_state(in_vid, q, up, rid)
             alu[q, q, +, 1]
 
         .endw
 
@@ -345,9 +352,9 @@
                 alu[up, 1, AND, $bar[(NFP_NET_CFG_RXRS_ENABLE/4 + 1)], >>indirect]
 
             .endif
 
-            _set_queue_state(in_vnic, q, up, rid)
+            _set_queue_state(in_vid, q, up, rid)
             alu[q, q, +, 1]
 
         .endw
 
@@ -407,9 +414,9 @@
 
     .reg ring_addr_hi
     .reg ring_in_addr_lo
     .reg ring_out_addr_lo
-    .reg vnic
+    .reg vid
 
     .reg $cmsg[1]
     .xfer_order $cmsg
 
@@ -433,11 +440,11 @@
             .break
         .endif
 
         // Extract the queue ID that is going up or down
-        wsm_extract(vnic, $cmsg, NFD_CFG_MSG_VNIC)
+        wsm_extract(vid, $cmsg, NFD_CFG_MSG_VID)
 
-        _check_vnic_state(vnic)
+        _check_vnic_state(vid)
 
         // Propagate the message down the line
         move($cmsg[0], $cmsg[0])
         mem[journal, $cmsg[0], ring_addr_hi, <<8, ring_out_addr_lo, 1], ctx_swap[put_sig]
diff --git a/me/blocks/vnic/shared/nfd_cfg.c b/me/blocks/vnic/shared/nfd_cfg.c
--- a/me/blocks/vnic/shared/nfd_cfg.c
+++ b/me/blocks/vnic/shared/nfd_cfg.c
@@ -58,9 +58,9 @@ send_interthread_sig(unsigned int dst_me
 __intrinsic void
 nfd_cfg_check_cfg_msg(struct nfd_cfg_msg *cfg_msg, SIGNAL *cfg_sig,
                       unsigned int rnum)
 {
-    /* XXX should this method read the vnic config BAR? */
+    /* XXX should this method read the vid config BAR? */
     if (signal_test(cfg_sig)) {
         int ret;
         __xread struct nfd_cfg_msg cfg_msg_rd;
         mem_ring_addr_t ring_addr;
@@ -168,9 +168,9 @@ nfd_cfg_app_complete_cfg_msg(unsigned in
     SIGNAL read_sig, write_sig;
     unsigned int nfd_isl_master;
 
     /* Compute the address of the update field */
-    addr += cfg_msg->vnic * NFP_NET_CFG_BAR_SZ;
+    addr += cfg_msg->vid * NFP_NET_CFG_BAR_SZ;
     addr += NFP_NET_CFG_UPDATE;
 
     if (cfg_msg->error) {
         result = NFP_NET_CFG_UPDATE_ERR;
@@ -189,14 +189,14 @@ nfd_cfg_app_complete_cfg_msg(unsigned in
     wait_for_all(&read_sig, &write_sig);
 
     /* Check for and handle FLRs */
     if (update_request & NFP_NET_CFG_UPDATE_RESET) {
-        if ((NFD_MAX_VFS != 0) && NFD_VNIC_IS_VF(cfg_msg->vnic)) {
+        if ((NFD_MAX_VFS != 0) && NFD_VID_IS_VF(cfg_msg->vid)) {
             /* We have a VF FLR */
-            _nfd_flr_ack_vf(pcie_isl, cfg_msg->vnic);
+            _nfd_flr_ack_vf(pcie_isl, cfg_msg->vid);
         } else {
             /* We have a PF FLR, but is it the last PF vNIC? */
-            if (cfg_msg->vnic == NFD_LAST_PF) {
+            if (cfg_msg->vid == NFD_LAST_PF) {
                 /* Only ack the FLR on the message for the last PF vNIC */
                 _nfd_flr_ack_pf(pcie_isl);
             }
         }
@@ -231,9 +231,9 @@ nfd_cfg_svc_complete_cfg_msg(struct nfd_
     /* Clear the internal state fields and set msg_valid before sending  */
     cfg_msg_tmp.__raw = 0;
     cfg_msg_tmp.msg_valid = 1;
     cfg_msg_tmp.error = cfg_msg->error;
-    cfg_msg_tmp.vnic = cfg_msg->vnic;
+    cfg_msg_tmp.vid = cfg_msg->vid;
     cfg_msg_wr.__raw = cfg_msg_tmp.__raw;
 
     /* Journal is guaranteed to not overflow by design (it is larger than
      * the number of possible vNICs). */
diff --git a/me/blocks/vnic/shared/nfd_cfg.h b/me/blocks/vnic/shared/nfd_cfg.h
--- a/me/blocks/vnic/shared/nfd_cfg.h
+++ b/me/blocks/vnic/shared/nfd_cfg.h
@@ -25,8 +25,9 @@
 
 #include <nfd_user_cfg.h>
 
 #include <vnic/shared/nfd.h>
+#include <vnic/shared/nfd_ctrl.h>
 
 
 /* /\* XXX Magic number currently */
 /*  * Set to official version number before release *\/ */
@@ -94,12 +95,12 @@
 #define NFD_CFG_MSG_QUEUE_bf            0, 15, 8
 #define NFD_CFG_MSG_QUEUE_wrd           0
 #define NFD_CFG_MSG_QUEUE_shf           8
 #define NFD_CFG_MSG_QUEUE_msk           0xFF
-#define NFD_CFG_MSG_VNIC_bf             0, 7, 0
-#define NFD_CFG_MSG_VNIC_wrd            0
-#define NFD_CFG_MSG_VNIC_shf            0
-#define NFD_CFG_MSG_VNIC_msk            0xFF
+#define NFD_CFG_MSG_VID_bf              0, 7, 0
+#define NFD_CFG_MSG_VID_wrd             0
+#define NFD_CFG_MSG_VID_shf             0
+#define NFD_CFG_MSG_VID_msk             0xFF
 
 
 /*
  * Defines that set the structure of "nfd_flr_seen".  These are also
@@ -235,10 +236,12 @@ NFD_CFG_RINGS_DECL(3);
 /* Due to THB-350, BARs must be 2M aligned on A0 */
 #if 1
 #define NFD_CFG_BASE_DECLARE(_isl)                                      \
     _NFP_CHIPRES_ASM(.alloc_mem NFD_CFG_BASE(_isl) NFD_EMEM(_isl) global \
-                     ((NFD_MAX_VFS + NFD_MAX_PFS) * NFP_NET_CFG_BAR_SZ) SZ_2M)
+                     ((NFD_MAX_VFS + NFD_MAX_PFS + NFD_MAX_CTRL) * \
+                      NFP_NET_CFG_BAR_SZ) SZ_2M)
 #else
+/* TODO This logic seems broken, remove it entirely */
 #define NFD_CFG_BASE_DECLARE(_isl)                                      \
     _NFP_CHIPRES_ASM(.alloc_mem NFD_CFG_BASE(_isl) NFD_EMEM(_isl) global \
                      ((NFD_MAX_VFS + NFD_MAX_PFS) * NFP_NET_CFG_BAR_SZ) \
                      (NFD_MAX_VFS * NFP_NET_CFG_BAR_SZ * (1 +  NFD_MAX_PFS)))
@@ -252,13 +255,13 @@ NFD_CFG_RINGS_DECL(3);
 #define NFD_CFG_BASE_LINK(_isl) NFD_CFG_BASE_LINK_IND0(_isl)
 
 
 /* XXX we can't use "|" here due to NFCC error, check and possibly JIRA. */
-#define NFD_CFG_BAR(_base, _vnic)               \
-    ((_base) + ((_vnic) * NFP_NET_CFG_BAR_SZ))
+#define NFD_CFG_BAR(_base, _vid)                \
+    ((_base) + ((_vid) * NFP_NET_CFG_BAR_SZ))
 
-#define NFD_CFG_BAR_ISL(_isl, _vnic)            \
-    NFD_CFG_BAR(NFD_CFG_BASE_LINK(_isl), (_vnic))
+#define NFD_CFG_BAR_ISL(_isl, _vid )            \
+    NFD_CFG_BAR(NFD_CFG_BASE_LINK(_isl), (_vid))
 
 
 /**
  * @param msg_valid     message contains valid information
@@ -266,12 +269,12 @@ NFD_CFG_RINGS_DECL(3);
  * @param interested    this component must process this message
  * @param up_bit        the current queue is up
  * @param spare         spare bits
  * @param queue         queue number to process
- * @param vnic          vnic to process
+ * @param vid           vNIC ID to process
  *
  * This structure is passed between NFD components and used internally
- * to carry configuration messages.  'vnic', 'msg_valid', and 'error' are
+ * to carry configuration messages.  'vid', 'msg_valid', and 'error' are
  * passed between components (other fields must be zeroed).  'msg_valid' is
  * used to determine whether to process a configuration message, and must be
  * set when passing the structure to the next stage.  Unsetting this bit signals
  * that processing in this stage is complete.  'up_bit' and 'queue' are only
@@ -285,9 +288,9 @@ struct nfd_cfg_msg {
             unsigned int interested:1;
             unsigned int up_bit:1;
             unsigned int spare:12;
             unsigned int queue:8;
-            unsigned int vnic:8;
+            unsigned int vid:8;
         };
         unsigned int __raw;
     };
 };
diff --git a/me/blocks/vnic/shared/nfd_cfg.uc b/me/blocks/vnic/shared/nfd_cfg.uc
--- a/me/blocks/vnic/shared/nfd_cfg.uc
+++ b/me/blocks/vnic/shared/nfd_cfg.uc
@@ -27,9 +27,9 @@
 #ifndef NFD_MAX_PFS
 #error "NFD_MAX_PFS is not defined but is required"
 #endif
 
-#define_eval NFD_TOTAL_VNICS (NFD_MAX_VFS + NFD_MAX_PFS)
+#define_eval NFD_TOTAL_VNICS (NFD_MAX_VFS + NFD_MAX_PFS + NFD_MAX_CTRL)
 #define_eval NFD_CFG_BAR_SZ (NFD_TOTAL_VNICS * NFP_NET_CFG_BAR_SZ)
 #define_eval NFD_CFG_BAR0_OFF (NFD_MAX_VFS * NFP_NET_CFG_BAR_SZ)
 
 
@@ -59,9 +59,9 @@ nfd_cfg_define_bars(3)
 #undef NFD_CFG_BAR_SZ
 #undef NFD_CFG_BAR0_OFF
 
 
-#macro nfd_cfg_get_bar_addr(out_hi, out_lo, in_vnic, ISL)
+#macro nfd_cfg_get_bar_addr(out_hi, out_lo, in_vid, ISL)
 .begin
     .reg tmp_lo
     .reg off
 
@@ -70,9 +70,9 @@ nfd_cfg_define_bars(3)
     #endif
 
     move(out_hi, ((nfd_cfg_base/**/ISL >> 8) & 0xFF000000))
     move(tmp_lo, (nfd_cfg_base/**/ISL & 0xFFFFFFFF))
-    alu[off, --, B, in_vnic, <<(log2(NFP_NET_CFG_BAR_SZ))]
+    alu[off, --, B, in_vid, <<(log2(NFP_NET_CFG_BAR_SZ))]
     alu[out_lo, tmp_lo, +, off]
 
 .end
 #endm
diff --git a/me/blocks/vnic/shared/nfd_cfg_internal.c b/me/blocks/vnic/shared/nfd_cfg_internal.c
--- a/me/blocks/vnic/shared/nfd_cfg_internal.c
+++ b/me/blocks/vnic/shared/nfd_cfg_internal.c
@@ -35,8 +35,9 @@
 
 #include <vnic/nfd_common.h>
 #include <vnic/shared/nfd.h>
 #include <vnic/shared/nfd_cfg.h>
+#include <vnic/shared/nfd_ctrl.h>
 #include <vnic/shared/nfd_internal.h>
 #include <vnic/utils/qc.h>
 #include <vnic/utils/qcntl.h>
 
@@ -124,16 +125,37 @@ NFD_CFG_RINGS_INIT(2);
 #if _nfp_has_island("pcie3")
 NFD_CFG_RINGS_INIT(3);
 #endif
 
+
+#if (defined(NFD_USE_CTRL) && (PCIE_ISL == 0))
+#define NFD_CFG_CTRL_DECLARE_IND(_isl)                                      \
+    NFD_CFG_BASE_DECLARE(_isl)                                              \
+    _NFP_CHIPRES_ASM(.declare_resource nfd_cfg_base##_isl##_res global      \
+                     ((NFD_MAX_VFS + NFD_MAX_PFS + NFD_MAX_CTRL) *          \
+                       NFP_NET_CFG_BAR_SZ)                                  \
+                     nfd_cfg_base##_isl)                                    \
+    _NFP_CHIPRES_ASM(.alloc_resource _pf##_isl##_net_ctrl_bar               \
+                     nfd_cfg_base##_isl##_res+(NFD_MAX_VFS *                \
+                                               NFP_NET_CFG_BAR_SZ)          \
+                     global (NFD_MAX_CTRL * NFP_NET_CFG_BAR_SZ))
+#else
+#define NFD_CFG_CTRL_DECLARE_IND(_isl)
+#endif
+
+#define NFD_CFG_CTRL_DECLARE(_isl) NFD_CFG_CTRL_DECLARE_IND(_isl)
+
+
 #if NFD_MAX_PFS != 0
 #define NFD_CFG_PF_DECLARE_IND(_isl)                                    \
     NFD_CFG_BASE_DECLARE(_isl)                                          \
     _NFP_CHIPRES_ASM(.declare_resource nfd_cfg_base##_isl##_res global  \
-                     ((NFD_MAX_VFS + NFD_MAX_PFS) * NFP_NET_CFG_BAR_SZ) \
+                     ((NFD_MAX_VFS + NFD_MAX_PFS + NFD_MAX_CTRL) *      \
+                       NFP_NET_CFG_BAR_SZ)                              \
                      nfd_cfg_base##_isl)                                \
     _NFP_CHIPRES_ASM(.alloc_resource _pf##_isl##_net_bar0               \
-                     nfd_cfg_base##_isl##_res+(NFD_MAX_VFS * NFP_NET_CFG_BAR_SZ) \
+                     nfd_cfg_base##_isl##_res+((NFD_MAX_VFS + NFD_MAX_CTRL) * \
+                                               NFP_NET_CFG_BAR_SZ)      \
                      global (NFD_MAX_PFS * NFP_NET_CFG_BAR_SZ))         \
     _NFP_CHIPRES_ASM(.alloc_mem nfd_cfg_pf##_isl##_num_ports emem global 8 8)  \
     _NFP_CHIPRES_ASM(.init nfd_cfg_pf##_isl##_num_ports NFD_MAX_PFS)
 
@@ -419,38 +441,35 @@ void
     nfd_cfg_queue.event_data = NFD_EVENT_DATA;
     nfd_cfg_queue.event_type = PCIE_QC_EVENT_NOT_EMPTY;
     nfd_cfg_queue.ptr        = 0;
 
-
-#if NFD_MAX_VFS == 0
-    init_qc_queues(PCIE_ISL, &nfd_cfg_queue, NFD_CFG_QUEUE,
-                   4 * NFD_MAX_PF_QUEUES, NFD_MAX_PFS);
-
-#elif (NFD_MAX_PFS < 2)
-    /* Init the VF config queues and possibly end with PF queue.
-     * Each NFD queue uses a block of 4 QC queues. */
-    init_qc_queues(PCIE_ISL, &nfd_cfg_queue, NFD_CFG_QUEUE,
-                   4 * NFD_MAX_VF_QUEUES, NFD_MAX_VFS + NFD_MAX_PFS);
-
-#else
+#if (NFD_MAX_VFS != 0)
     init_qc_queues(PCIE_ISL, &nfd_cfg_queue, NFD_CFG_QUEUE,
                    4 * NFD_MAX_VF_QUEUES, NFD_MAX_VFS);
+#endif
+
+#ifdef NFD_USE_CTRL
     init_qc_queues(PCIE_ISL, &nfd_cfg_queue,
-                   NFD_CFG_QUEUE + (4 * NFD_MAX_VF_QUEUES * NFD_MAX_VFS),
+                   NFD_CFG_QUEUE + (4 * NFD_CTRL_QUEUE),
+                   4 * NFD_MAX_CTRL_QUEUES, NFD_MAX_CTRL);
+#endif
+
+#if (NFD_MAX_PFS != 0)
+    init_qc_queues(PCIE_ISL, &nfd_cfg_queue,
+                   NFD_CFG_QUEUE + (4 * NFD_FIRST_PF_QUEUE),
                    4 * NFD_MAX_PF_QUEUES, NFD_MAX_PFS);
 #endif
-
 }
 
 /*
  * Initialise the VF and PF control BAR
  */
 static void
-_nfd_cfg_init_vf_ctrl_bar(unsigned int vnic)
+_nfd_cfg_init_vf_cfg_bar(unsigned int vid)
 {
 #if ((NFD_MAX_VFS != 0) && (NFD_MAX_VF_QUEUES != 0))
 #ifdef NFD_NO_ISOLATION
-    unsigned int q_base = NFD_MAX_VF_QUEUES * vnic;
+    unsigned int q_base = NFD_VID2NATQ(vid, 0);
 #else
     unsigned int q_base = 0;
 #endif
     __xwrite unsigned int cfg[] = {NFD_CFG_VERSION,
@@ -464,27 +483,53 @@ static void
     __xwrite unsigned int exn_lsc = 0xffffffff;
     __xwrite unsigned int cfg2[] = {NFD_OUT_RX_OFFSET,
                                     NFD_RSS_HASH_FUNC};
 
-    mem_write64(&cfg, NFD_CFG_BAR_ISL(PCIE_ISL, vnic) + NFP_NET_CFG_VERSION,
+    mem_write64(&cfg, NFD_CFG_BAR_ISL(PCIE_ISL, vid) + NFP_NET_CFG_VERSION,
                 sizeof cfg);
 
-    mem_write8(&exn_lsc, NFD_CFG_BAR_ISL(PCIE_ISL, vnic) + NFP_NET_CFG_LSC,
+    mem_write8(&exn_lsc, NFD_CFG_BAR_ISL(PCIE_ISL, vid) + NFP_NET_CFG_LSC,
                sizeof exn_lsc);
 
     mem_write8(&cfg2,
-               NFD_CFG_BAR_ISL(PCIE_ISL, vnic) + NFP_NET_CFG_RX_OFFSET,
+               NFD_CFG_BAR_ISL(PCIE_ISL, vid) + NFP_NET_CFG_RX_OFFSET,
                sizeof cfg2);
 #endif
 }
 
 
 static void
-_nfd_cfg_init_pf_ctrl_bar(unsigned int vnic)
+_nfd_cfg_init_ctrl_cfg_bar(unsigned int vid)
 {
-#if (NFD_MAX_PFS != 0)
-    unsigned int q_base = (NFD_MAX_VF_QUEUES * NFD_MAX_VFS) +
-        (vnic - NFD_MAX_VFS) * NFD_MAX_PF_QUEUES;
+    unsigned int q_base =  NFD_VID2NATQ(vid, 0);
+    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION,
+                                   (NFP_NET_CFG_STS_LINK_RATE_UNSUPPORTED
+                                    << NFP_NET_CFG_STS_LINK_RATE_SHIFT) | 0,
+                                   NFD_CFG_CTRL_CAP,
+                                   NFD_MAX_CTRL_QUEUES, NFD_MAX_CTRL_QUEUES,
+                                   NFD_CFG_MAX_MTU,
+                                   NFD_NATQ2QC(q_base, NFD_IN_TX_QUEUE),
+                                   NFD_NATQ2QC(q_base, NFD_OUT_FL_QUEUE)};
+    __xwrite unsigned int exn_lsc = 0xffffffff;
+    __xwrite unsigned int cfg2[] = {NFD_OUT_RX_OFFSET,
+                                    NFD_RSS_HASH_FUNC};
+
+    mem_write64(&cfg, NFD_CFG_BAR_ISL(PCIE_ISL, vid) + NFP_NET_CFG_VERSION,
+                sizeof cfg);
+
+    mem_write8(&exn_lsc, NFD_CFG_BAR_ISL(PCIE_ISL, vid) + NFP_NET_CFG_LSC,
+               sizeof exn_lsc);
+
+    mem_write8(&cfg2, NFD_CFG_BAR_ISL(PCIE_ISL, vid) + NFP_NET_CFG_RX_OFFSET,
+               sizeof cfg2);
+
+}
+
+
+static void
+_nfd_cfg_init_pf_cfg_bar(unsigned int vid)
+{
+    unsigned int q_base =  NFD_VID2NATQ(vid, 0);
     __xwrite unsigned int cfg[] = {NFD_CFG_VERSION,
                                    (NFP_NET_CFG_STS_LINK_RATE_UNSUPPORTED
                                     << NFP_NET_CFG_STS_LINK_RATE_SHIFT) | 0,
                                    NFD_CFG_PF_CAP,
@@ -501,23 +546,22 @@ static void
           NFD_BPF_START_OFF | NFD_BPF_DONE_OFF << 16,
           30 << 8 /* CTM buf size / 64 */ };
 #endif
 
-    mem_write64(&cfg, NFD_CFG_BAR_ISL(PCIE_ISL, vnic) + NFP_NET_CFG_VERSION,
+    mem_write64(&cfg, NFD_CFG_BAR_ISL(PCIE_ISL, vid) + NFP_NET_CFG_VERSION,
                 sizeof cfg);
 
-    mem_write8(&exn_lsc, NFD_CFG_BAR_ISL(PCIE_ISL, vnic) + NFP_NET_CFG_LSC,
+    mem_write8(&exn_lsc, NFD_CFG_BAR_ISL(PCIE_ISL, vid) + NFP_NET_CFG_LSC,
                sizeof exn_lsc);
 
-    mem_write8(&cfg2, NFD_CFG_BAR_ISL(PCIE_ISL, vnic) + NFP_NET_CFG_RX_OFFSET,
+    mem_write8(&cfg2, NFD_CFG_BAR_ISL(PCIE_ISL, vid) + NFP_NET_CFG_RX_OFFSET,
                sizeof cfg2);
 
 #ifdef NFD_BPF_CAPABLE
     mem_write8(&bpf_cfg,
-               NFD_CFG_BAR_ISL(PCIE_ISL, vnic) + NFP_NET_CFG_BPF_ABI,
+               NFD_CFG_BAR_ISL(PCIE_ISL, vid) + NFP_NET_CFG_BPF_ABI,
                sizeof bpf_cfg);
 #endif
-#endif
 }
 
 
 /**
@@ -525,9 +569,9 @@ static void
  */
 void
 nfd_cfg_setup()
 {
-    unsigned int vnic;
+    unsigned int vid;
     unsigned int ring;
 
     /* XXX remove once .declare_resource and .alloc_resource support
      * bracketed expressions. */
@@ -542,16 +586,22 @@ nfd_cfg_setup()
      * NFD_MAX_PF_QUEUES to mem.
      * XXX Could be .init'ed?
      */
 #if NFD_MAX_VFS != 0
-    for (vnic = 0; vnic < NFD_MAX_VFS; vnic++) {
-        _nfd_cfg_init_vf_ctrl_bar(vnic);
+    for (vid = 0; vid < NFD_MAX_VFS; vid++) {
+        _nfd_cfg_init_vf_cfg_bar(vid);
     }
 #endif
 
-    for (vnic = NFD_FIRST_PF; vnic <= NFD_LAST_PF; vnic++) {
-        _nfd_cfg_init_pf_ctrl_bar(vnic);
+#if (defined(NFD_USE_CTRL) && (PCIE_ISL == 0))
+    _nfd_cfg_init_ctrl_cfg_bar(NFD_CTRL_VNIC);
+#endif
+
+#if (NFD_MAX_PFS != 0)
+    for (vid = NFD_FIRST_PF; vid <= NFD_LAST_PF; vid++) {
+        _nfd_cfg_init_pf_cfg_bar(vid);
     }
+#endif
 }
 
 
 /**
@@ -717,25 +767,25 @@ int
 nfd_cfg_next_vnic()
 {
     /* XXX throttle how often this function runs? */
     __gpr unsigned int queue;
-    int vnic;
+    int vid;
     int ret;
 
     /* Get a bmsk queue number from the configuration queue bmsk */
     ret = select_queue(&queue, &cfg_queue_bmsk);
     if (ret) {
         /* We haven't found a configuration queue to service */
-        vnic = -1;
+        vid = -1;
     } else {
         __xread unsigned int wptr_raw;
         struct nfp_qc_sts_hi wptr;
         unsigned int qc_queue;
 
         /* We have a configuration queue to service */
 
-        /* Compute the vNIC and QC queue associated with that CFG queue */
-        vnic = NFD_CFGQ2VNIC(queue);
+        /* Compute the vNIC vid and QC queue associated with that CFG queue */
+        vid = NFD_CFGQ2VID(queue);
         qc_queue = NFD_NATQ2QC(queue, NFD_CFG_QUEUE);
 
         /* Confirm that the queue is not empty */
         wptr.__raw = qc_read(PCIE_ISL, qc_queue, QC_WPTR);
@@ -745,17 +795,17 @@ nfd_cfg_next_vnic()
         } else {
             /* The qc queue was already empty, which might indicate
              * an FLR has occurred after the CFG message was started.
              * There is nothing to do on this CFG queue. */
-            vnic = -1;
+            vid = -1;
         }
 
         /* Clear the bit in the bitmask so the queue isn't picked again,
          * and increment the QC queue read pointer */
         clear_queue(&queue, &cfg_queue_bmsk);
    }
 
-    return vnic;
+    return vid;
 }
 
 
 /**
@@ -778,9 +828,9 @@ nfd_cfg_start_cfg_msg(struct nfd_cfg_msg
     /* Clear the internal state fields and set msg_valid before sending  */
     cfg_msg_tmp.__raw = 0;
     cfg_msg_tmp.msg_valid = 1;
     cfg_msg_tmp.error = cfg_msg->error;
-    cfg_msg_tmp.vnic = cfg_msg->vnic;
+    cfg_msg_tmp.vid = cfg_msg->vid;
     cfg_msg_wr.__raw = cfg_msg_tmp.__raw;
 
     mem_ring_journal(rnum, ring_addr, &cfg_msg_wr, sizeof cfg_msg_wr);
 
@@ -815,9 +865,9 @@ nfd_cfg_complete_cfg_msg(struct nfd_cfg_
     /* Clear the internal state fields and set msg_valid before sending  */
     cfg_msg_tmp.__raw = 0;
     cfg_msg_tmp.msg_valid = 1;
     cfg_msg_tmp.error = cfg_msg->error;
-    cfg_msg_tmp.vnic = cfg_msg->vnic;
+    cfg_msg_tmp.vid = cfg_msg->vid;
     cfg_msg_wr.__raw = cfg_msg_tmp.__raw;
 
     /* Journal is guaranteed to not overflow by design (it is larger than
      * the number of possible vNICs). */
@@ -854,53 +904,58 @@ nfd_cfg_next_flr(struct nfd_cfg_msg *cfg
 {
     if (bit_test(flr_pend_status, NFD_FLR_PEND_BUSY_shf)) {
         if (bit_test(flr_pend_status, NFD_FLR_PF_ind)) {
             /* The PF gets priority */
-            unsigned int vnic;
+            unsigned int vid;
 
-#if NFD_MAX_PFS != 0
+#if ((NFD_MAX_PFS != 0) || defined(NFD_USE_CTRL))
 
-#if NFD_MAX_PFS == 1
-            vnic = NFD_FIRST_PF;
+            vid = ((flr_pend_status >> NFD_CFG_FLR_NEXT_PF_shf) &
+                   NFD_CFG_FLR_NEXT_PF_msk);
+
+            /* Set cfg_msg->queue to most likely value, and
+             * only correct it to the CTRL vNIC value if necessary */
+            cfg_msg->queue = NFD_MAX_PF_QUEUES - 1;
+
+            /* vid == 0 means nothing in progress, so pick the starting
+             * new starting vid. */
+            if (vid == 0) {
+#if (defined(NFD_USE_CTRL) && (PCIE_ISL == 0))
+                vid = NFD_CTRL_VNIC;
+                cfg_msg->queue = NFD_MAX_CTRL_QUEUES - 1;
 #else
-            vnic = ((flr_pend_status >> NFD_CFG_FLR_NEXT_PF_shf) &
-                    NFD_CFG_FLR_NEXT_PF_msk);
-            if (vnic == 0) {
-                vnic = NFD_FIRST_PF;
+                vid = NFD_FIRST_PF;
+#endif
             }
-#endif
-            /* Setup the parse_msg info */
-            cfg_msg->queue = NFD_MAX_PF_QUEUES - 1;
-            cfg_msg->vnic = vnic;
+
+            /* Setup the remaining parse_msg info */
+            cfg_msg->vid = vid;
             cfg_msg->interested = 1;
             cfg_msg->msg_valid = 1;
 
             cfg_ring_enables[0] = 0;
             cfg_ring_enables[1] = 0;
 
             /* Rewrite the CFG BAR for other components */
-            nfd_flr_write_cfg_msg(NFD_CFG_BASE_LINK(PCIE_ISL), vnic);
-            nfd_flr_init_cfg_queue(PCIE_ISL, vnic,
+            nfd_flr_write_cfg_msg(NFD_CFG_BASE_LINK(PCIE_ISL), vid);
+            nfd_flr_init_cfg_queue(PCIE_ISL, vid,
                                    NFP_QC_STS_LO_EVENT_TYPE_NEVER);
-#if NFD_MAX_PFS == 1
-            /* Just one PF vNIC, so we're done */
-            flr_pend_status &= ~(1 << NFD_FLR_PF_ind);
-#else
-            if (vnic == NFD_LAST_PF) {
+
+            /* Check whether we have finished with the PF FLR */
+            if (vid == NFD_LAST_PF) {
                 /* This was the last PF vNIC, so clear the state */
                 flr_pend_status &= ~(NFD_CFG_FLR_NEXT_PF_msk <<
                                      NFD_CFG_FLR_NEXT_PF_shf);
                 flr_pend_status &= ~(1 << NFD_FLR_PF_ind);
 
             } else {
-                /* We have more vNICs to service, so increment vnic and
+                /* We have more vNICs to service, so increment vid and
                  * leave NFD_FLR_PF_ind set. */
                 flr_pend_status &= ~(NFD_CFG_FLR_NEXT_PF_msk <<
                                      NFD_CFG_FLR_NEXT_PF_shf);
-                vnic++;
-                flr_pend_status |= (vnic << NFD_CFG_FLR_NEXT_PF_shf);
+                vid++;
+                flr_pend_status |= (vid << NFD_CFG_FLR_NEXT_PF_shf);
             }
-#endif
 
 #else
             /* We're not using the PF, just ACK. */
             nfd_flr_ack_pf(PCIE_ISL);
@@ -922,18 +977,20 @@ nfd_cfg_next_flr(struct nfd_cfg_msg *cfg
 
             if (vf < NFD_MAX_VFS) {
                 /* Setup the parse_msg info */
                 cfg_msg->queue = NFD_MAX_VF_QUEUES - 1;
-                cfg_msg->vnic = vf;
+                cfg_msg->vid = vf;
                 cfg_msg->interested = 1;
                 cfg_msg->msg_valid = 1;
 
                 cfg_ring_enables[0] = 0;
                 cfg_ring_enables[1] = 0;
 
                 /* Rewrite the CFG BAR for other components */
-                nfd_flr_write_cfg_msg(NFD_CFG_BASE_LINK(PCIE_ISL), vf);
-                nfd_flr_init_cfg_queue(PCIE_ISL, vf,
+                nfd_flr_write_cfg_msg(NFD_CFG_BASE_LINK(PCIE_ISL),
+                                      NFD_VNIC2VID(NFD_VNIC_TYPE_VF, vf));
+                nfd_flr_init_cfg_queue(PCIE_ISL,
+                                       NFD_VNIC2VID(NFD_VNIC_TYPE_VF, vf),
                                        NFP_QC_STS_LO_EVENT_TYPE_NEVER);
 
             } else {
 
@@ -958,18 +1015,20 @@ nfd_cfg_next_flr(struct nfd_cfg_msg *cfg
 
             if (vf < NFD_MAX_VFS) {
                 /* Setup the parse_msg info */
                 cfg_msg->queue = NFD_MAX_VF_QUEUES - 1;
-                cfg_msg->vnic = vf;
+                cfg_msg->vid = vf;
                 cfg_msg->interested = 1;
                 cfg_msg->msg_valid = 1;
 
                 cfg_ring_enables[0] = 0;
                 cfg_ring_enables[1] = 0;
 
                 /* Rewrite the CFG BAR for other components */
-                nfd_flr_write_cfg_msg(NFD_CFG_BASE_LINK(PCIE_ISL), vf);
-                nfd_flr_init_cfg_queue(PCIE_ISL, vf,
+                nfd_flr_write_cfg_msg(NFD_CFG_BASE_LINK(PCIE_ISL),
+                                      NFD_VNIC2VID(NFD_VNIC_TYPE_VF, vf));
+                nfd_flr_init_cfg_queue(PCIE_ISL,
+                                       NFD_VNIC2VID(NFD_VNIC_TYPE_VF, vf),
                                        NFP_QC_STS_LO_EVENT_TYPE_NEVER);
 
 
             } else {
@@ -1015,14 +1074,14 @@ nfd_cfg_parse_msg(struct nfd_cfg_msg *cf
 
     if (comp == NFD_CFG_PCI_OUT) {
         /* Need RXRS_ENABLES, at 0x10 */
         mem_read64(cfg_bar_data,
-                   NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg->vnic) + NFP_NET_CFG_CTRL,
+                   NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg->vid) + NFP_NET_CFG_CTRL,
                    6 * sizeof(unsigned int));
     } else {
         /* Only need TXRS_ENABLES, at 0x08 */
         mem_read64(cfg_bar_data,
-                   NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg->vnic) + NFP_NET_CFG_CTRL,
+                   NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg->vid) + NFP_NET_CFG_CTRL,
                    4 * sizeof(unsigned int));
     }
 
     /* Check if change affects this component */
@@ -1032,10 +1091,12 @@ nfd_cfg_parse_msg(struct nfd_cfg_msg *cf
         cfg_msg->interested = 1;
     }
 
     /* Set the queue to process to the final queue */
-    if (NFD_VNIC_IS_PF(cfg_msg->vnic)) {
+    if (NFD_VID_IS_PF(cfg_msg->vid)) {
         cfg_msg->queue = NFD_MAX_PF_QUEUES - 1;
+    } else if (NFD_VID_IS_CTRL(cfg_msg->vid)) {
+        cfg_msg->queue = NFD_MAX_CTRL_QUEUES - 1;
     } else {
         cfg_msg->queue = NFD_MAX_VF_QUEUES - 1;
     }
 
@@ -1067,12 +1128,12 @@ nfd_cfg_parse_msg(struct nfd_cfg_msg *cf
              * For size, we want the 4B aligned entry that holds
              * the end ring. */
             sz_off &= ~3;
             mem_read64(&cfg_ring_addr,
-                       NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg->vnic) + addr_off,
+                       NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg->vid) + addr_off,
                        sizeof(cfg_ring_addr));
             mem_read32(&cfg_ring_sizes,
-                       NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg->vnic) + sz_off,
+                       NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg->vid) + sz_off,
                        sizeof(cfg_ring_sizes));
         }
     } else {
         /* All rings are set disabled, we won't need any addresses or sizes */
@@ -1144,9 +1205,9 @@ nfd_cfg_proc_msg(struct nfd_cfg_msg *cfg
     /* We only use the address if the ring is enabled.
      * Otherwise suppress read to save CPP bandwidth. */
     if (_ring_enables_test(cfg_msg)) {
         mem_read64(&cfg_ring_addr,
-                   NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg->vnic) + next_addr_off,
+                   NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg->vid) + next_addr_off,
                    sizeof(cfg_ring_addr));
     }
 
     /* Reread the queue sizes if necessary.
@@ -1154,9 +1215,9 @@ nfd_cfg_proc_msg(struct nfd_cfg_msg *cfg
      * so need to reread when the low bits are "3". */
     if ((cfg_msg->queue & 3) == 3) {
         next_sz_off &= ~3;
         mem_read32(&cfg_ring_sizes,
-                   NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg->vnic) + next_sz_off,
+                   NFD_CFG_BAR_ISL(PCIE_ISL, cfg_msg->vid) + next_sz_off,
                    sizeof(cfg_ring_sizes));
     }
 }
 
diff --git a/me/blocks/vnic/shared/nfd_ctrl.h b/me/blocks/vnic/shared/nfd_ctrl.h
new file mode 100644
--- /dev/null
+++ b/me/blocks/vnic/shared/nfd_ctrl.h
@@ -0,0 +1,37 @@
+/*
+ * Copyright (C) 2017,  Netronome Systems, Inc.  All rights reserved.
+ *
+ * @file          blocks/vnic/shared/nfd_ctrl.h
+ * @brief         NFD control message definitions
+ */
+#ifndef _BLOCKS__VNIC_SHARED_NFD_CTRL_H_
+#define _BLOCKS__VNIC_SHARED_NFD_CTRL_H_
+
+#define NFD_MAX_CTRL_QUEUES 1
+
+#define NFD_CFG_CTRL_CAP                                        \
+    (NFP_NET_CFG_CTRL_ENABLE | NFP_NET_CFG_CTRL_PROMISC |       \
+     NFP_NET_CFG_CTRL_MSIXAUTO | NFP_NET_CFG_CTRL_GATHER |      \
+     NFP_NET_CFG_CTRL_IRQMOD)
+
+
+#ifdef NFD_USE_CTRL
+#define NFD_MAX_CTRL 1
+#else
+#define NFD_MAX_CTRL 0
+#endif
+
+
+#endif /* !_BLOCKS__VNIC_SHARED_NFD_CTRL_H_ */
diff --git a/me/blocks/vnic/shared/nfd_flr.c b/me/blocks/vnic/shared/nfd_flr.c
--- a/me/blocks/vnic/shared/nfd_flr.c
+++ b/me/blocks/vnic/shared/nfd_flr.c
@@ -82,10 +82,10 @@
 /** Clear the bulk of the CFG BAR
  * @param addr      start address of the vNIC CFG BAR
  *
  * This function performs the bulk write of data that won't be reset
- * by other functions (e.g. nfd_flr_init__pf_ctrl_bar() and
- * nfd_flr_init_vf_ctrl_bar()).  "addr" should be obtained via the
+ * by other functions (e.g. nfd_flr_init_pf_cfg_bar() and
+ * nfd_flr_init_vf_cfg_bar()).  "addr" should be obtained via the
  * appropriate API, e.g. NFD_CFG_BAR_ISL.
  */
 __intrinsic void
 nfd_flr_clr_bar(__emem char *addr)
@@ -120,9 +120,9 @@ nfd_flr_clr_bar(__emem char *addr)
 
 
 /** Reset the vNIC CFG QC queue to its initial state
  * @param pcie_isl      PCIe island to reset
- * @param vnic          vNIC to reset
+ * @param vid           vid of vNIC to reset
  * @param event_type    event type to configure
  *
  * Reset the CFG QC to a clean state, in case the previous
  * user left it broken.  This is done twice, once when the
@@ -131,9 +131,9 @@ nfd_flr_clr_bar(__emem char *addr)
  * again after the CFG BAR has been zeroed out to renable
  * configuration message events.
  */
 __intrinsic void
-nfd_flr_init_cfg_queue(unsigned int pcie_isl, unsigned int vnic,
+nfd_flr_init_cfg_queue(unsigned int pcie_isl, unsigned int vid,
                        unsigned int event_type)
 {
     struct qc_queue_config nfd_cfg_queue;
 
@@ -147,25 +147,25 @@ nfd_flr_init_cfg_queue(unsigned int pcie
     nfd_cfg_queue.event_data = NFD_EVENT_DATA;
     nfd_cfg_queue.event_type = event_type;
     nfd_cfg_queue.ptr        = 0;
 
-    qc_init_queue(pcie_isl, NFD_NATQ2QC(NFD_BUILD_NATQ(vnic, 0), NFD_CFG_QUEUE),
+    qc_init_queue(pcie_isl, NFD_NATQ2QC(NFD_VID2NATQ(vid, 0), NFD_CFG_QUEUE),
                   &nfd_cfg_queue);
 }
 
 
 /** Init the non-zero parts of the PF control BAR
  * @param isl_base      start address of the CFG BARs for the PCIe island
+ * @param vid           vid number on the PCIe island
  *
  * "isl_base" should be obtained via the appropriate API,
  * e.g. NFD_CFG_BASE_LINK.
  */
 void
-nfd_flr_init_pf_ctrl_bar(__emem char *isl_base, unsigned int vnic)
+nfd_flr_init_pf_cfg_bar(__emem char *isl_base, unsigned int vid)
 {
 #if (NFD_MAX_PFS != 0)
-    unsigned int q_base = (NFD_MAX_VF_QUEUES * NFD_MAX_VFS) +
-        (vnic - NFD_MAX_VFS) * NFD_MAX_PF_QUEUES;
+    unsigned int q_base = NFD_VID2NATQ(vid, 0);
     __xwrite unsigned int cfg[] = {NFD_CFG_VERSION,
                                    (NFP_NET_CFG_STS_LINK_RATE_UNSUPPORTED
                                     << NFP_NET_CFG_STS_LINK_RATE_SHIFT) | 0,
                                    NFD_CFG_PF_CAP,
@@ -182,39 +182,78 @@ nfd_flr_init_pf_ctrl_bar(__emem char *is
                                         30 << 8 /* CTM buf size / 64 */ };
 #endif
 
     mem_write64(&cfg,
-                NFD_CFG_BAR(isl_base, vnic) + NFP_NET_CFG_VERSION,
+                NFD_CFG_BAR(isl_base, vid) + NFP_NET_CFG_VERSION,
                 sizeof cfg);
 
-    mem_write8(&exn_lsc, NFD_CFG_BAR(isl_base, vnic) +
+    mem_write8(&exn_lsc, NFD_CFG_BAR(isl_base, vid) +
                NFP_NET_CFG_LSC, sizeof exn_lsc);
 
     mem_write8(&cfg2,
-               NFD_CFG_BAR(isl_base, vnic) + NFP_NET_CFG_RX_OFFSET,
+               NFD_CFG_BAR(isl_base, vid) + NFP_NET_CFG_RX_OFFSET,
                sizeof cfg2);
 #ifdef NFD_BPF_CAPABLE
     mem_write8(&bpf_cfg,
-               NFD_CFG_BAR(isl_base, vnic) + NFP_NET_CFG_BPF_ABI,
+               NFD_CFG_BAR(isl_base, vid) + NFP_NET_CFG_BPF_ABI,
                sizeof bpf_cfg);
 #endif
 #endif
 }
 
 
-/** Init the non-zero parts of the VF control BAR
+/** Init the non-zero parts of the CTRL control BAR
  * @param isl_base      start address of the CFG BARs for the PCIe island
- * @param vf            VF number on the PCIe island
+ * @param vid           vid number on the PCIe island
  *
  * "isl_base" should be obtained via the appropriate API,
  * e.g. NFD_CFG_BASE_LINK.
  */
 void
-nfd_flr_init_vf_ctrl_bar(__emem char *isl_base, __emem char *vf_cfg_base, unsigned int vf)
+nfd_flr_init_ctrl_cfg_bar(__emem char *isl_base, unsigned int vid)
+{
+#ifdef NFD_USE_CTRL
+    unsigned int q_base = NFD_VID2NATQ(vid, 0);
+    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION,
+                                   (NFP_NET_CFG_STS_LINK_RATE_UNSUPPORTED
+                                    << NFP_NET_CFG_STS_LINK_RATE_SHIFT) | 0,
+                                   NFD_CFG_CTRL_CAP,
+                                   NFD_MAX_CTRL_QUEUES, NFD_MAX_CTRL_QUEUES,
+                                   NFD_CFG_MAX_MTU,
+                                   NFD_NATQ2QC(q_base, NFD_IN_TX_QUEUE),
+                                   NFD_NATQ2QC(q_base, NFD_OUT_FL_QUEUE)};
+    __xwrite unsigned int exn_lsc = 0xffffffff;
+    __xwrite unsigned int cfg2[] = {NFD_OUT_RX_OFFSET,
+                                    NFD_RSS_HASH_FUNC};
+
+    mem_write64(&cfg,
+                NFD_CFG_BAR(isl_base, vid) + NFP_NET_CFG_VERSION,
+                sizeof cfg);
+
+    mem_write8(&exn_lsc, NFD_CFG_BAR(isl_base, vid) +
+               NFP_NET_CFG_LSC, sizeof exn_lsc);
+
+    mem_write8(&cfg2,
+               NFD_CFG_BAR(isl_base, vid) + NFP_NET_CFG_RX_OFFSET,
+               sizeof cfg2);
+#endif
+}
+
+
+
+/** Init the non-zero parts of the VF control BAR
+ * @param isl_base      start address of the CFG BARs for the PCIe island
+ * @param vid           vid number on the PCIe island
+ *
+ * "isl_base" should be obtained via the appropriate API,
+ * e.g. NFD_CFG_BASE_LINK.
+ */
+void
+nfd_flr_init_vf_cfg_bar(__emem char *isl_base, __emem char *vf_cfg_base, unsigned int vid)
 {
 #if ((NFD_MAX_VFS != 0) && (NFD_MAX_VF_QUEUES != 0))
 #ifdef NFD_NO_ISOLATION
-    unsigned int q_base = NFD_MAX_VF_QUEUES * vnic;
+    unsigned int q_base = NFD_VID2NATQ(vid, 0);
 #else
     unsigned int q_base = 0;
 #endif
     __xwrite unsigned int cfg[] = {NFD_CFG_VERSION,
@@ -230,21 +269,22 @@ nfd_flr_init_vf_ctrl_bar(__emem char *is
                                     NFD_RSS_HASH_FUNC};
     __xread unsigned int vf_cfg_rd[2];
     __xwrite unsigned int vf_cfg_wr[2];
 
-    mem_write64(&cfg, NFD_CFG_BAR(isl_base, vf) + NFP_NET_CFG_VERSION,
+    mem_write64(&cfg, NFD_CFG_BAR(isl_base, vid) + NFP_NET_CFG_VERSION,
                 sizeof cfg);
 
-    mem_write8(&exn_lsc, NFD_CFG_BAR(isl_base, vf) + NFP_NET_CFG_LSC,
+    mem_write8(&exn_lsc, NFD_CFG_BAR(isl_base, vid) + NFP_NET_CFG_LSC,
                sizeof exn_lsc);
 
-    mem_write8(&cfg2, NFD_CFG_BAR(isl_base, vf) + NFP_NET_CFG_RX_OFFSET,
+    mem_write8(&cfg2, NFD_CFG_BAR(isl_base, vid) + NFP_NET_CFG_RX_OFFSET,
                sizeof cfg2);
 
-    mem_read8(&vf_cfg_rd, NFD_VF_CFG_ADDR(vf_cfg_base, vf),
+    /* XXX should vid technically be vf below? */
+    mem_read8(&vf_cfg_rd, NFD_VF_CFG_ADDR(vf_cfg_base, vid),
               NFD_VF_CFG_MAC_SZ);
     reg_cp(vf_cfg_wr, vf_cfg_rd, sizeof vf_cfg_rd);
-    mem_write8(&vf_cfg_wr, NFD_CFG_BAR(isl_base, vf) + NFP_NET_CFG_MACADDR,
+    mem_write8(&vf_cfg_wr, NFD_CFG_BAR(isl_base, vid) + NFP_NET_CFG_MACADDR,
               NFD_VF_CFG_MAC_SZ);
 
 #endif
 }
diff --git a/me/blocks/vnic/svc/msix.c b/me/blocks/vnic/svc/msix.c
--- a/me/blocks/vnic/svc/msix.c
+++ b/me/blocks/vnic/svc/msix.c
@@ -171,9 +171,9 @@ out:
 /**
  * Send MSI-X interrupt for specified virtual function and optionally mask
  * @param pcie_nr     PCIe island number (0 to 3)
  * @param bar_nr      CPP2PCIe bar to use
- * @param vf_nr       Virtual function number (0 to 63)
+ * @param vid         Virtual function number (0 to 63)
  * @param entry_nr    MSI-X table entry number
  * @param mask_en     Boolean, should interrupt be masked after sending.
  * @return            0 on success, else the interrupt was masked.
  *
@@ -197,9 +197,9 @@ out:
  *
  * The same potential race as for the PF exists in this code too.
  */
 __intrinsic int
-msix_vf_send(unsigned int pcie_nr, unsigned int bar_nr, unsigned int vf_nr,
+msix_vf_send(unsigned int pcie_nr, unsigned int bar_nr, unsigned int vid,
              unsigned int entry_nr, unsigned int mask_en)
 {
     unsigned int addr_hi;
     unsigned int addr_lo;
@@ -217,9 +217,9 @@ msix_vf_send(unsigned int pcie_nr, unsig
 
     int ret = 1;
 
     msix_table_addr =
-        (__emem char *)NFD_CFG_BAR(msix_cfg_bars[pcie_nr], vf_nr);
+        (__emem char *)NFD_CFG_BAR(msix_cfg_bars[pcie_nr], vid);
     msix_table_addr += NFD_VF_MSIX_TABLE_OFF;
 
     /* Read the full table entry */
     mem_read8(tmp,
@@ -233,9 +233,10 @@ msix_vf_send(unsigned int pcie_nr, unsig
     if (flags & PCIE_MSIX_FLAGS_MASKED)
         goto out;
 
     /* Check if we need to re-configure the CPP2PCI BAR */
-    bar_addr = pcie_c2p_barcfg_val(addr_hi, addr_lo, (vf_nr + 64));
+    /* XXX vid is equal to VF num currently */
+    bar_addr = pcie_c2p_barcfg_val(addr_hi, addr_lo, (vid + 64));
     if (bar_addr != msix_cur_cpp2pci_addr) {
         pcie_c2p_barcfg_set_expl(pcie_nr, bar_nr, bar_addr);
         msix_cur_cpp2pci_addr = bar_addr;
     }
diff --git a/me/blocks/vnic/svc/msix_qmon.c b/me/blocks/vnic/svc/msix_qmon.c
--- a/me/blocks/vnic/svc/msix_qmon.c
+++ b/me/blocks/vnic/svc/msix_qmon.c
@@ -84,8 +84,9 @@
 #define MSIX_RINGS_MASK(num_rings)  ((num_rings) == 64 ? 0xffffffffffffffff : \
                                      (1ull << (num_rings)) - 1)
 #define MSIX_PF_RINGS_MASK          MSIX_RINGS_MASK(NFD_MAX_PF_QUEUES)
 #define MSIX_VF_RINGS_MASK          MSIX_RINGS_MASK(NFD_MAX_VF_QUEUES)
+#define MSIX_CTRL_RINGS_MASK        MSIX_RINGS_MASK(NFD_MAX_CTRL_QUEUES)
 
 
 /*
  * Interrupt Moderation support;
@@ -205,9 +206,9 @@ msix_qmon_init(unsigned int pcie_isl)
 /*
  * Reconfigure RX and TX rings (executed by context 0)
  *
  * @pcie_isl        PCIe Island this function is handling
- * @vnic            vNIC inside the island this function is handling
+ * @vid             vNIC inside the island this function is handling
  * @cfg_bar         Points to the control bar for the vnic
  * @rx_rings        Boolean, if set, handle RX rings, else RX rings
  * @vf_rings        Bitmask of enabled tings for the VF/vNIC.
  *
@@ -219,9 +220,9 @@ msix_qmon_init(unsigned int pcie_isl)
  *
  * Note: Some of the code generates contains CLS reads/writes.
  */
 __intrinsic static void
-msix_reconfig_rings(unsigned int pcie_isl, unsigned int vnic,
+msix_reconfig_rings(unsigned int pcie_isl, unsigned int vid,
                     __mem char *cfg_bar, int rx_rings, uint64_t vf_rings)
 {
     unsigned int qnum;
     uint64_t rings;
@@ -243,17 +244,9 @@ msix_reconfig_rings(unsigned int pcie_is
         ring = ffs64(rings);
         rings &= rings - 1;
 
        /* Convert ring number to a queue number */
-        #if NFD_MAX_PFS < 2
-            qnum = ring + vnic * NFD_MAX_VF_QUEUES;
-        #else
-        if (NFD_VNIC_IS_PF(vnic))
-            qnum = ring + ((NFD_MAX_VFS * NFD_MAX_VF_QUEUES) +
-                           ((vnic - NFD_MAX_VFS) * NFD_MAX_PF_QUEUES));
-        else
-            qnum = ring + vnic * NFD_MAX_VF_QUEUES;
-        #endif /* NFD_MAX_PFS < 2 */
+        qnum = NFD_VID2NATQ(vid, ring);
 
         /* Get MSI-X entry number and stash it into local memory */
         if (rx_rings) {
             entry_addr = cfg_bar + NFP_NET_CFG_RXR_VEC(ring);
@@ -275,17 +268,9 @@ msix_reconfig_rings(unsigned int pcie_is
         mem_write8_le(&tmp_w, cfg_bar + NFP_NET_CFG_ICR(entry), 1);
     }
 
     /* Convert VF ring bitmask into Queue mask */
-    #if NFD_MAX_PFS < 2
-        queues = vf_rings << (vnic * NFD_MAX_VF_QUEUES);
-    #else
-    if (NFD_VNIC_IS_PF(vnic))
-        queues = vf_rings << ((NFD_MAX_VFS * NFD_MAX_VF_QUEUES) +
-                              ((vnic - NFD_MAX_VFS) * NFD_MAX_PF_QUEUES));
-    else
-        queues = vf_rings << (vnic * NFD_MAX_VF_QUEUES);
-    #endif
+    queues = vf_rings << NFD_VID2NATQ(vid, 0);
 
     /* Work out which queues have been newly enabled and make sure
      * they don't have pending bits set. */
     if (rx_rings) {
@@ -298,19 +283,14 @@ msix_reconfig_rings(unsigned int pcie_is
         msix_cls_tx_new_enabled[pcie_isl] = new_queues_en;
     }
 
     /* Update the enabled bit mask with queues for this VF. */
-    #if NFD_MAX_PFS < 2
-    if (NFD_VNIC_IS_PF(vnic))
-        vf_queue_mask = MSIX_PF_RINGS_MASK << (vnic * NFD_MAX_VF_QUEUES);
-    #else
-    if (NFD_VNIC_IS_PF(vnic))
-        vf_queue_mask = MSIX_PF_RINGS_MASK <<
-            ((NFD_MAX_VFS * NFD_MAX_VF_QUEUES) +
-             ((vnic - NFD_MAX_VFS) * NFD_MAX_PF_QUEUES));
-    #endif
+    if (NFD_VID_IS_PF(vid))
+        vf_queue_mask = MSIX_PF_RINGS_MASK << NFD_VID2NATQ(vid, 0);
+    else if (NFD_VID_IS_CTRL(vid))
+        vf_queue_mask = MSIX_CTRL_RINGS_MASK << NFD_VID2NATQ(vid, 0);
     else
-        vf_queue_mask = MSIX_VF_RINGS_MASK << (vnic * NFD_MAX_VF_QUEUES);
+        vf_queue_mask = MSIX_VF_RINGS_MASK << NFD_VID2NATQ(vid, 0);
 
     if (rx_rings) {
         msix_cls_rx_enabled[pcie_isl] &= ~vf_queue_mask;
         msix_cls_rx_enabled[pcie_isl] |= queues;
@@ -323,9 +303,9 @@ msix_reconfig_rings(unsigned int pcie_is
 /*
  * Reconfigure RX and TX rings (executed by context 0)
  *
  * @pcie_isl        PCIe Island this function is handling
- * @vnic            vNIC inside the island this function is handling
+ * @vid             vNIC inside the island this function is handling
  * @cfg_bar         Points to the control bar for the vnic
  * @rx_rings        Boolean, if set, handle RX rings, else RX rings
  * @vf_rings        Bitmask of enabled tings for the VF/vNIC.
  *
@@ -337,9 +317,9 @@ msix_reconfig_rings(unsigned int pcie_is
  *
  * Note: Some of the code generates contains CLS reads/writes.
  */
 __intrinsic static void
-msix_reconfig_irq_mod(unsigned int pcie_isl, unsigned int vnic,
+msix_reconfig_irq_mod(unsigned int pcie_isl, unsigned int vid,
                       __mem char *cfg_bar, int rx_rings, uint64_t vf_rings)
 {
     unsigned int qnum;
     uint64_t rings;
@@ -354,17 +334,9 @@ msix_reconfig_irq_mod(unsigned int pcie_
         ring = ffs64(rings);
         rings &= rings - 1;
 
         /* Convert ring number to a queue number */
-        #if NFD_MAX_PFS < 2
-            qnum = ring + vnic * NFD_MAX_VF_QUEUES;
-        #else
-        if (NFD_VNIC_IS_PF(vnic))
-            qnum = ring + ((NFD_MAX_VFS * NFD_MAX_VF_QUEUES) +
-                           ((vnic - NFD_MAX_VFS) * NFD_MAX_PF_QUEUES));
-        else
-            qnum = ring + vnic * NFD_MAX_VF_QUEUES;
-        #endif
+        qnum = NFD_VID2NATQ(vid, ring);
 
         /* Get interrupt moderation packet count and timeout and and stash
          * them into local memory */
         if (rx_rings)
@@ -384,9 +356,9 @@ msix_reconfig_irq_mod(unsigned int pcie_
 /*
  * Handle reconfiguration changes of RX queues (executed by context 0)
  *
  * @pcie_isl        PCIe Island this function is handling
- * @vnic            vNIC inside the island this function is handling
+ * @vid             vid of vNIC inside the island this function is handling
  * @cfg_bar         points to the control bar for the vnic
  * @cfg_bar_data[]  contains the first 6 words of the control bar.
  *
  * This function is called from context 0 of the service ME on
@@ -396,9 +368,9 @@ msix_reconfig_irq_mod(unsigned int pcie_
  *
  * Note: Some of the code contains implicit CLS reads/writes.
  */
 __intrinsic void
-msix_qmon_reconfig(unsigned int pcie_isl, unsigned int vnic,
+msix_qmon_reconfig(unsigned int pcie_isl, unsigned int vid,
                    __mem char *cfg_bar, __xread unsigned int cfg_bar_data[6])
 {
     unsigned int control, update;
 
@@ -434,11 +406,14 @@ msix_qmon_reconfig(unsigned int pcie_isl
             vf_rx_rings_new = 0;
         }
 
         /* Make sure the vnic is not configuring rings it has no control over */
-        if (NFD_VNIC_IS_PF(vnic)) {
+        if (NFD_VID_IS_PF(vid)) {
             vf_tx_rings_new &= MSIX_PF_RINGS_MASK;
             vf_rx_rings_new &= MSIX_PF_RINGS_MASK;
+        } else if (NFD_VID_IS_CTRL(vid)) {
+            vf_tx_rings_new &= MSIX_CTRL_RINGS_MASK;
+            vf_rx_rings_new &= MSIX_CTRL_RINGS_MASK;
         } else {
             vf_tx_rings_new &= MSIX_VF_RINGS_MASK;
             vf_rx_rings_new &= MSIX_VF_RINGS_MASK;
         }
@@ -451,27 +426,18 @@ msix_qmon_reconfig(unsigned int pcie_isl
         /* Set MSI-X automask bits.  We assume that a VF/PF has the same
          * number of RX and TX rings and simple set the auto-mask bits for
          * all queues of the VF/PF depending on the auto-mask bit in the
          * control word. */
-        #if NFD_MAX_PFS < 2
-            queues = vf_rx_rings_new << (vnic * NFD_MAX_VF_QUEUES);
-        #else
-        if (NFD_VNIC_IS_PF(vnic))
-            queues = vf_rx_rings_new << ((NFD_MAX_VFS * NFD_MAX_VF_QUEUES) +
-                                         ((vnic - NFD_MAX_VFS) *
-                                          NFD_MAX_PF_QUEUES));
-        else
-            queues = vf_rx_rings_new << (vnic * NFD_MAX_VF_QUEUES);
-        #endif
+        queues = vf_rx_rings_new << NFD_VID2NATQ(vid, 0);
 
         if (control & NFP_NET_CFG_CTRL_MSIXAUTO)
             msix_cls_automask[pcie_isl] |= queues;
         else
             msix_cls_automask[pcie_isl] &= ~queues;
 
         /* Reconfigure the RX/TX ring state */
-        msix_reconfig_rings(pcie_isl, vnic, cfg_bar, 1, vf_rx_rings_new);
-        msix_reconfig_rings(pcie_isl, vnic, cfg_bar, 0, vf_tx_rings_new);
+        msix_reconfig_rings(pcie_isl, vid, cfg_bar, 1, vf_rx_rings_new);
+        msix_reconfig_rings(pcie_isl, vid, cfg_bar, 0, vf_tx_rings_new);
     }
 
     if (update & NFP_NET_CFG_UPDATE_IRQMOD) {
 
@@ -483,10 +449,10 @@ msix_qmon_reconfig(unsigned int pcie_isl
             cfg_bar_data[(NFP_NET_CFG_RXRS_ENABLE >> 2) + 1];
         vf_rx_rings_new = ((vf_rx_rings_new << 32) |
                            cfg_bar_data[NFP_NET_CFG_RXRS_ENABLE >> 2]);
 
-        msix_reconfig_irq_mod(pcie_isl, vnic, cfg_bar, 1, vf_rx_rings_new);
-        msix_reconfig_irq_mod(pcie_isl, vnic, cfg_bar, 0, vf_tx_rings_new);
+        msix_reconfig_irq_mod(pcie_isl, vid, cfg_bar, 1, vf_rx_rings_new);
+        msix_reconfig_irq_mod(pcie_isl, vid, cfg_bar, 0, vf_tx_rings_new);
 
         /* if update did not include MSIX, ensure local reconfig does
          * use see any stale newly enabled RX/TX ring state */
         if (!(update & NFP_NET_CFG_UPDATE_MSIX)) {
@@ -824,9 +790,9 @@ msix_send_q_irq(const unsigned int pcie_
                 unsigned int count)
 {
     unsigned int automask;
     unsigned int entry;
-    int fn;
+    int vid, vqn;
     uint64_t cfg_bar;
     __xread uint32_t mask_r;
     __xwrite uint32_t mask_w;
 
@@ -846,14 +812,14 @@ msix_send_q_irq(const unsigned int pcie_
 
     /* Should we automask this queue? */
     automask = msix_automask & (1ull << qnum);
 
-    /* Get the function (aka vnic) */
-    NFD_NATQ2VNIC(fn, qnum);
+    /* Get the vNIC vid and queue number */
+    NFD_NATQ2VID(vid, vqn, qnum);
 
     /* If we don't use auto-masking, check (and update) the ICR */
     if (!automask) {
-        cfg_bar = NFD_CFG_BAR(msix_cfg_bars[pcie_isl], fn);
+        cfg_bar = NFD_CFG_BAR(msix_cfg_bars[pcie_isl], vid);
         cfg_bar += NFP_NET_CFG_ICR(entry);
         mem_read32_le(&mask_r, (__mem void *)cfg_bar, sizeof(mask_r));
         if (mask_r & 0x000000ff) {
             ret = 1;
@@ -862,13 +828,13 @@ msix_send_q_irq(const unsigned int pcie_
         mask_w = NFP_NET_CFG_ICR_RXTX;
         mem_write8_le(&mask_w, (__mem void *)cfg_bar, 1);
     }
 
-    if (NFD_VNIC_IS_PF(fn))
+    if (NFD_VID_IS_VF(vid))
+        ret = msix_vf_send(pcie_isl, PCIE_CPP2PCIE_QMON, vid,
+                           entry, automask);
+    else
         ret = msix_pf_send(pcie_isl, PCIE_CPP2PCIE_QMON, entry, automask);
-    else
-        ret = msix_vf_send(pcie_isl, PCIE_CPP2PCIE_QMON, fn,
-                           entry, automask);
 
     /* IRQ issued, cleanup interrupt moderation state */
     if (!ret)
         msix_imod_irq_issued(pcie_isl, qnum, rx_queue);
diff --git a/me/blocks/vnic/svc_me.c b/me/blocks/vnic/svc_me.c
--- a/me/blocks/vnic/svc_me.c
+++ b/me/blocks/vnic/svc_me.c
@@ -92,33 +92,38 @@ do {                                    
                           NFD_CFG_RING_NUM(_isl, 4));                   \
     if (cfg_msg##_isl.msg_valid) {                                      \
         ncfg++;                                                         \
         mem_read64(cfg_bar_data##_isl,                                  \
-                   NFD_CFG_BAR_ISL(_isl, cfg_msg##_isl.vnic),           \
+                   NFD_CFG_BAR_ISL(_isl, cfg_msg##_isl.vid),            \
                    sizeof cfg_bar_data##_isl);                          \
                                                                         \
-        msix_qmon_reconfig(_isl, cfg_msg##_isl.vnic,                    \
-                           NFD_CFG_BAR_ISL(_isl, cfg_msg##_isl.vnic),   \
+        msix_qmon_reconfig(_isl, cfg_msg##_isl.vid,                     \
+                           NFD_CFG_BAR_ISL(_isl, cfg_msg##_isl.vid),    \
                            cfg_bar_data##_isl);                         \
                                                                         \
         /* Handle FLRs */                                               \
         if (cfg_bar_data##_isl[1] & NFP_NET_CFG_UPDATE_RESET) {         \
                                                                         \
             /* NB: This function writes ~8K of data */                  \
-            nfd_flr_clr_bar(NFD_CFG_BAR_ISL(_isl, cfg_msg##_isl.vnic)); \
-            nfd_flr_init_cfg_queue(_isl, cfg_msg##_isl.vnic,            \
+            nfd_flr_clr_bar(NFD_CFG_BAR_ISL(_isl, cfg_msg##_isl.vid));  \
+            nfd_flr_init_cfg_queue(_isl, cfg_msg##_isl.vid,             \
                                    PCIE_QC_EVENT_NOT_EMPTY);            \
                                                                         \
-            if (NFD_VNIC_IS_PF(cfg_msg##_isl.vnic)) {                   \
+            if (NFD_VID_IS_PF(cfg_msg##_isl.vid)) {                     \
                 /* We have a PF FLR */                                  \
-                nfd_flr_init_pf_ctrl_bar(NFD_CFG_BASE_LINK(_isl),       \
-                                         cfg_msg##_isl.vnic);           \
+                nfd_flr_init_pf_cfg_bar(NFD_CFG_BASE_LINK(_isl),        \
+                                        cfg_msg##_isl.vid);             \
+                                                                        \
+            } else if (NFD_VID_IS_VF(cfg_msg##_isl.vid)) {              \
+                /* We have a VF FLR */                                  \
+                nfd_flr_init_vf_cfg_bar(NFD_CFG_BASE_LINK(_isl),        \
+                                        NFD_VF_CFG_BASE_LINK(_isl),     \
+                                        cfg_msg##_isl.vid);             \
                                                                         \
             } else {                                                    \
-                /* We have a VF FLR */                                  \
-                nfd_flr_init_vf_ctrl_bar(NFD_CFG_BASE_LINK(_isl),       \
-                                         NFD_VF_CFG_BASE_LINK(_isl),    \
-                                         cfg_msg##_isl.vnic);           \
+                /* We have a PF/CTRL FLR */                             \
+                nfd_flr_init_ctrl_cfg_bar(NFD_CFG_BASE_LINK(_isl),      \
+                                          cfg_msg##_isl.vid);           \
                                                                         \
             }                                                           \
         }                                                               \
                                                                         \
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498210357 -7200
# Node ID 4ab28ba77d57b40462af86f8b2ead3e94585f0ee
# Parent  48fd8d7206e2f1b37dd0f3f7d0eafd2412918219
[cfg] Add rtsym pointing to VF CFG BARs
* _pfX_net_vf_bar holds all the VFs BARs
* The same data is accessible via nfd_cfg_base0, but this symbol holds the
  VFs only and can safely be indexed by VF number

diff --git a/me/blocks/vnic/pci_in_me0.c b/me/blocks/vnic/pci_in_me0.c
--- a/me/blocks/vnic/pci_in_me0.c
+++ b/me/blocks/vnic/pci_in_me0.c
@@ -44,8 +44,9 @@
 
 NFD_CFG_DECLARE(nfd_cfg_sig_pci_in, nfd_cfg_sig_pci_in0);
 NFD_INIT_DONE_DECLARE;
 
+NFD_CFG_VF_DECLARE(PCIE_ISL);
 NFD_CFG_CTRL_DECLARE(PCIE_ISL);
 NFD_CFG_PF_DECLARE(PCIE_ISL);
 
 struct nfd_cfg_msg cfg_msg;
diff --git a/me/blocks/vnic/shared/nfd_cfg_internal.c b/me/blocks/vnic/shared/nfd_cfg_internal.c
--- a/me/blocks/vnic/shared/nfd_cfg_internal.c
+++ b/me/blocks/vnic/shared/nfd_cfg_internal.c
@@ -126,8 +126,26 @@ NFD_CFG_RINGS_INIT(2);
 NFD_CFG_RINGS_INIT(3);
 #endif
 
 
+#if (NFD_MAX_VFS != 0)
+#define NFD_CFG_VF_DECLARE_IND(_isl)                                    \
+    NFD_CFG_BASE_DECLARE(_isl)                                          \
+    _NFP_CHIPRES_ASM(.declare_resource nfd_cfg_base##_isl##_res global  \
+                     ((NFD_MAX_VFS + NFD_MAX_PFS + NFD_MAX_CTRL) *      \
+                       NFP_NET_CFG_BAR_SZ)                              \
+                     nfd_cfg_base##_isl)                                \
+    _NFP_CHIPRES_ASM(.alloc_resource _pf##_isl##_net_vf_bar             \
+                     nfd_cfg_base##_isl##_res+0                         \
+                     global (NFD_MAX_VFS * NFP_NET_CFG_BAR_SZ))         \
+
+#else
+#define NFD_CFG_VF_DECLARE_IND(_isl)
+#endif
+
+#define NFD_CFG_VF_DECLARE(_isl) NFD_CFG_VF_DECLARE_IND(_isl)
+
+
 #if (defined(NFD_USE_CTRL) && (PCIE_ISL == 0))
 #define NFD_CFG_CTRL_DECLARE_IND(_isl)                                      \
     NFD_CFG_BASE_DECLARE(_isl)                                              \
     _NFP_CHIPRES_ASM(.declare_resource nfd_cfg_base##_isl##_res global      \
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498210358 -7200
# Node ID 536079a216467506cd10b527435cfb0c57aa52ac
# Parent  4ab28ba77d57b40462af86f8b2ead3e94585f0ee
[cfg] Allow developers to overwrite NFP_NET_BPF_ABI with their preferred value
* This means that the eBFP team can develop ABIs that don't use the CFG BAR
  without touching nfp_net_ctrl.h

diff --git a/me/blocks/vnic/shared/nfd_cfg_internal.c b/me/blocks/vnic/shared/nfd_cfg_internal.c
--- a/me/blocks/vnic/shared/nfd_cfg_internal.c
+++ b/me/blocks/vnic/shared/nfd_cfg_internal.c
@@ -558,10 +558,14 @@ static void
     __xwrite unsigned int exn_lsc = 0xffffffff;
     __xwrite unsigned int cfg2[] = {NFD_OUT_RX_OFFSET,
                                     NFD_RSS_HASH_FUNC};
 #ifdef NFD_BPF_CAPABLE
+#ifndef NFD_BPF_ABI
+#define NFD_BPF_ABI (NFP_NET_BPF_ABI)
+#endif
+
     __xwrite unsigned int bpf_cfg[] =
-        { NFP_NET_BPF_ABI | (8 * 1024 - NFD_BPF_START_OFF) << 16,
+        { NFD_BPF_ABI | (8 * 1024 - NFD_BPF_START_OFF) << 16,
           NFD_BPF_START_OFF | NFD_BPF_DONE_OFF << 16,
           30 << 8 /* CTM buf size / 64 */ };
 #endif
 
diff --git a/me/blocks/vnic/shared/nfd_flr.c b/me/blocks/vnic/shared/nfd_flr.c
--- a/me/blocks/vnic/shared/nfd_flr.c
+++ b/me/blocks/vnic/shared/nfd_flr.c
@@ -176,9 +176,13 @@ nfd_flr_init_pf_cfg_bar(__emem char *isl
     __xwrite unsigned int exn_lsc = 0xffffffff;
     __xwrite unsigned int cfg2[] = {NFD_OUT_RX_OFFSET,
                                     NFD_RSS_HASH_FUNC};
 #ifdef NFD_BPF_CAPABLE
-    __xwrite unsigned int bpf_cfg[] = { NFP_NET_BPF_ABI | (8 * 1024 - NFD_BPF_START_OFF) << 16,
+#ifndef NFD_BPF_ABI
+#define NFD_BPF_ABI (NFP_NET_BPF_ABI)
+#endif
+
+    __xwrite unsigned int bpf_cfg[] = { NFD_BPF_ABI | (8 * 1024 - NFD_BPF_START_OFF) << 16,
                                         NFD_BPF_START_OFF | NFD_BPF_DONE_OFF << 16,
                                         30 << 8 /* CTM buf size / 64 */ };
 #endif
 
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498210358 -7200
# Node ID 80aa7f17675ba882553e57db1b992c11ccc3b127
# Parent  536079a216467506cd10b527435cfb0c57aa52ac
[cfg] Provide standard mac_stats symbol for the host drivers to access
* If NFD_MAX_PHYS_PORTS is defined, the symbol will be created, as an
  array of macstats_port_accum structs of the specified size.
* The default memory type is __emem, but this can be changed by specifying
  NFD_MAC_STATS_MEM_TYPE.

diff --git a/me/blocks/vnic/shared/nfd.h b/me/blocks/vnic/shared/nfd.h
--- a/me/blocks/vnic/shared/nfd.h
+++ b/me/blocks/vnic/shared/nfd.h
@@ -119,8 +119,19 @@
 #if defined(__NFP_LANG_MICROC)
 
 #include <nfp/mem_atomic.h>     /* TEMP */
 
+/* Provide a standard symbol for host drivers to access MAC stats */
+#ifdef NFD_MAX_PHYS_PORTS
+#include <nfp/macstats.h>
+
+#ifndef NFD_MAC_STATS_MEM_TYPE
+#define NFD_MAC_STATS_MEM_TYPE __emem
+#endif
+__export __shared __align256 NFD_MAC_STATS_MEM_TYPE
+    struct macstats_port_accum mac_stats[NFD_MAX_PHYS_PORTS];
+#endif
+
 /*
  * CPP2PCIe BAR allocation
  * XXX This should go into chip_res
  */
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498210359 -7200
# Node ID 5f19a613115021db5a132469fe87d1b816a77415
# Parent  80aa7f17675ba882553e57db1b992c11ccc3b127
[cfg] Support separate version numbers per vNIC type
* NFD_CFG_MAJOR_VF and NFD_CFG_MINOR_VF may be set by the user
* NFD places constrains upon the version numbers advertised to ensure
  that they are compatible with each other and the currrent NFD source
  code

diff --git a/me/blocks/vnic/nfd_common.h b/me/blocks/vnic/nfd_common.h
--- a/me/blocks/vnic/nfd_common.h
+++ b/me/blocks/vnic/nfd_common.h
@@ -23,27 +23,45 @@
 #include <vnic/shared/nfd_ctrl.h>
 
 
 /* NFD version number define guards */
-#ifdef NFD_CFG_MAJOR
-#error "NFD application code may not set NFD_CFG_MAJOR version number"
+#ifdef NFD_CFG_MAJOR_PF
+#error "NFD application code may not set NFD_CFG_MAJOR_PF version number"
 #endif
 
-#ifdef NFD_CFG_MINOR
-#error "NFD application code may not set NFD_CFG_MINOR version number"
+#ifdef NFD_CFG_MINOR_PF
+#error "NFD application code may not set NFD_CFG_MINOR_PF version number"
+#endif
+
+#ifdef NFD_CFG_MAJOR_CTRL
+#error "NFD application code may not set NFD_CFG_MAJOR_CTRL version number"
+#endif
+
+#ifdef NFD_CFG_MINOR_CTRL
+#error "NFD application code may not set NFD_CFG_MINOR_CTRL version number"
 #endif
 
 /* NFD version numbers.  Increment major version number for each incompatible
  * ABI change.  Increment minor version number for each compatible ABI change
  * (e.g. a new feature flag).  Reset minor version number to zero for each
  * major version number change. */
 #ifdef NFD_NET_APP_ID
-/* Firmwares that advertise an app_id must advertise ABI 5 */
-#define NFD_CFG_MAJOR               5
+    /* Firmwares that advertise an app_id must advertise ABI 5 */
+    #define NFD_CFG_MAJOR_PF            5
+    #define NFD_CFG_MAJOR_CTRL          5
+    #define NFD_CFG_MAJOR_VF_MAX        5
 #else
-#define NFD_CFG_MAJOR               4
+    #define NFD_CFG_MAJOR_PF            4
+    #define NFD_CFG_MAJOR_CTRL          4
+    #define NFD_CFG_MAJOR_VF_MAX        4
 #endif
-#define NFD_CFG_MINOR               4
+#define NFD_CFG_MAJOR_VF_MIN        3
+
+#define NFD_CFG_MINOR_PF            4
+#define NFD_CFG_MINOR_CTRL          4
+#define NFD_CFG_MINOR_VF_MAX        4
+#define NFD_CFG_MINOR_VF_MIN        0
+
 #define NFD_CFG_CLASS_DEFAULT       0
 
 /* Version number helper defines */
 #define NFD_CFG_CLASS_VER_msk       0xff
@@ -80,8 +98,32 @@
 #ifndef NFD_MAX_PFS
 #error "NFD_MAX_PFS is not defined but is required"
 #endif
 
+#ifdef NFD_CFG_MAJOR_VF
+#if (NFD_CFG_MAJOR_VF > NFD_CFG_MAJOR_VF_MAX)
+#error "NFD_CFG_MAJOR_VF out of supported range"
+#endif
+
+#if (NFD_CFG_MAJOR_VF < NFD_CFG_MAJOR_VF_MIN)
+#error "NFD_CFG_MAJOR_VF out of supported range"
+#endif
+#else
+#define NFD_CFG_MAJOR_VF NFD_CFG_MAJOR_VF_MAX
+#endif
+
+#ifdef NFD_CFG_MINOR_VF
+#if (NFD_CFG_MINOR_VF > NFD_CFG_MINOR_VF_MAX)
+#error "NFD_CFG_MINOR_VF out of supported range"
+#endif
+
+#if (NFD_CFG_MINOR_VF < NFD_CFG_MINOR_VF_MIN)
+#error "NFD_CFG_MINOR_VF out of supported range"
+#endif
+#else
+#define NFD_CFG_MINOR_VF NFD_CFG_MINOR_VF_MAX
+#endif
+
 
 /* vNICs must have queues, so if the "MAX_QUEUES" parameter is zero,
  * require the related MAX_VFS/PFS parameter to be zero as well. */
 #if ((NFD_MAX_VF_QUEUES == 0) && (NFD_MAX_VFS != 0))
diff --git a/me/blocks/vnic/shared/nfd_cfg.h b/me/blocks/vnic/shared/nfd_cfg.h
--- a/me/blocks/vnic/shared/nfd_cfg.h
+++ b/me/blocks/vnic/shared/nfd_cfg.h
@@ -28,12 +28,8 @@
 #include <vnic/shared/nfd.h>
 #include <vnic/shared/nfd_ctrl.h>
 
 
-/* /\* XXX Magic number currently */
-/*  * Set to official version number before release *\/ */
-/* #define NFD_CFG_VERSION 0x1248 */
-
 #ifndef NFD_CFG_CLASS
 /* The user hasn't specified a firmware class, so we set default class */
 #define NFD_CFG_CLASS NFD_CFG_CLASS_DEFAULT
 #endif
@@ -49,15 +45,8 @@
 #endif
 #endif
 
 
-#define NFD_CFG_VERSION                         \
-    (NFD_CFG_CLASS_VER(NFD_CFG_CLASS_VERSION) | \
-     NFD_CFG_CLASS_TYPE(NFD_CFG_CLASS) |        \
-     NFD_CFG_MAJOR_VERSION(NFD_CFG_MAJOR) |     \
-     NFD_CFG_MINOR_VERSION(NFD_CFG_MINOR))
-
-
 #ifndef NFD_CFG_MAX_MTU
 #define NFD_CFG_MAX_MTU         1500
 #endif
 
@@ -147,8 +136,16 @@
 #ifndef _link_sym
 #define _link_sym(x) __link_sym(#x)
 #endif
 
+
+#define NFD_CFG_VERSION(_type)                      \
+    (NFD_CFG_CLASS_VER(NFD_CFG_CLASS_VERSION) |     \
+     NFD_CFG_CLASS_TYPE(NFD_CFG_CLASS) |            \
+     NFD_CFG_MAJOR_VERSION(NFD_CFG_MAJOR_##_type) |  \
+     NFD_CFG_MINOR_VERSION(NFD_CFG_MINOR_##_type))
+
+
 /* Configuration mechanism memory and ring defines */
 #define NFD_CFG_RINGS_RES_IND(_emem)                                    \
     _NFP_CHIPRES_ASM(.alloc_resource nfd_cfg_ring_nums _emem##_queues   \
                      global NFD_CFG_TOTAL_RINGS NFD_CFG_TOTAL_RINGS)
diff --git a/me/blocks/vnic/shared/nfd_cfg_internal.c b/me/blocks/vnic/shared/nfd_cfg_internal.c
--- a/me/blocks/vnic/shared/nfd_cfg_internal.c
+++ b/me/blocks/vnic/shared/nfd_cfg_internal.c
@@ -489,9 +489,9 @@ static void
     unsigned int q_base = NFD_VID2NATQ(vid, 0);
 #else
     unsigned int q_base = 0;
 #endif
-    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION,
+    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION(VF),
                                    (NFP_NET_CFG_STS_LINK_RATE_UNSUPPORTED
                                     << NFP_NET_CFG_STS_LINK_RATE_SHIFT) | 0,
                                    NFD_CFG_VF_CAP,
                                    NFD_MAX_VF_QUEUES, NFD_MAX_VF_QUEUES,
@@ -518,9 +518,9 @@ static void
 static void
 _nfd_cfg_init_ctrl_cfg_bar(unsigned int vid)
 {
     unsigned int q_base =  NFD_VID2NATQ(vid, 0);
-    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION,
+    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION(CTRL),
                                    (NFP_NET_CFG_STS_LINK_RATE_UNSUPPORTED
                                     << NFP_NET_CFG_STS_LINK_RATE_SHIFT) | 0,
                                    NFD_CFG_CTRL_CAP,
                                    NFD_MAX_CTRL_QUEUES, NFD_MAX_CTRL_QUEUES,
@@ -546,9 +546,9 @@ static void
 static void
 _nfd_cfg_init_pf_cfg_bar(unsigned int vid)
 {
     unsigned int q_base =  NFD_VID2NATQ(vid, 0);
-    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION,
+    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION(PF),
                                    (NFP_NET_CFG_STS_LINK_RATE_UNSUPPORTED
                                     << NFP_NET_CFG_STS_LINK_RATE_SHIFT) | 0,
                                    NFD_CFG_PF_CAP,
                                    NFD_MAX_PF_QUEUES, NFD_MAX_PF_QUEUES,
diff --git a/me/blocks/vnic/shared/nfd_flr.c b/me/blocks/vnic/shared/nfd_flr.c
--- a/me/blocks/vnic/shared/nfd_flr.c
+++ b/me/blocks/vnic/shared/nfd_flr.c
@@ -164,9 +164,9 @@ void
 nfd_flr_init_pf_cfg_bar(__emem char *isl_base, unsigned int vid)
 {
 #if (NFD_MAX_PFS != 0)
     unsigned int q_base = NFD_VID2NATQ(vid, 0);
-    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION,
+    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION(PF),
                                    (NFP_NET_CFG_STS_LINK_RATE_UNSUPPORTED
                                     << NFP_NET_CFG_STS_LINK_RATE_SHIFT) | 0,
                                    NFD_CFG_PF_CAP,
                                    NFD_MAX_PF_QUEUES, NFD_MAX_PF_QUEUES,
@@ -216,9 +216,9 @@ void
 nfd_flr_init_ctrl_cfg_bar(__emem char *isl_base, unsigned int vid)
 {
 #ifdef NFD_USE_CTRL
     unsigned int q_base = NFD_VID2NATQ(vid, 0);
-    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION,
+    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION(CTRL),
                                    (NFP_NET_CFG_STS_LINK_RATE_UNSUPPORTED
                                     << NFP_NET_CFG_STS_LINK_RATE_SHIFT) | 0,
                                    NFD_CFG_CTRL_CAP,
                                    NFD_MAX_CTRL_QUEUES, NFD_MAX_CTRL_QUEUES,
@@ -259,9 +259,9 @@ nfd_flr_init_vf_cfg_bar(__emem char *isl
     unsigned int q_base = NFD_VID2NATQ(vid, 0);
 #else
     unsigned int q_base = 0;
 #endif
-    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION,
+    __xwrite unsigned int cfg[] = {NFD_CFG_VERSION(VF),
                                    (NFP_NET_CFG_STS_LINK_RATE_UNSUPPORTED
                                     << NFP_NET_CFG_STS_LINK_RATE_SHIFT) | 0,
                                    NFD_CFG_VF_CAP,
                                    NFD_MAX_VF_QUEUES, NFD_MAX_VF_QUEUES,
# HG changeset patch
# User Michael Rapson <michael.rapson@netronome.com>
# Date 1498210360 -7200
# Node ID c1a04d58f6e7d788c45b388e15358bdfa8bbf8ae
# Parent  5f19a613115021db5a132469fe87d1b816a77415
[cfg] Add mailbox and VLAN ctag filter support

diff --git a/docs/ABI b/docs/ABI
--- a/docs/ABI
+++ b/docs/ABI
@@ -95,8 +95,14 @@ NFP_NET_CFG_UPDATE_GEN updates.
 
 NFP_NET_CFG_UPDATE_MACADDR indicates an update to the
 MAC address while up.
 
+4.5:
+
+Add general use mailbox area and NFP_NET_CFG_CTRL_CTAG_FILTER, a
+capabilities and control flag to indicate that the firmware is able to
+filter CTAG or 802.1q frames based on the vid.
+
 5.0:
 
 Advertise _pf##_isl##_net_app_id rtsym to notify host of advanced firmware
 capabilities.  Minor ABI versions are as for 4.x ABIs.
\ No newline at end of file
diff --git a/kernel/nfp_net_ctrl.h b/kernel/nfp_net_ctrl.h
--- a/kernel/nfp_net_ctrl.h
+++ b/kernel/nfp_net_ctrl.h
@@ -97,8 +97,9 @@
 #define   NFP_NET_CFG_CTRL_TXVLAN         (0x1 <<  7) /* Enable VLAN insert */
 #define   NFP_NET_CFG_CTRL_SCATTER        (0x1 <<  8) /* Scatter DMA */
 #define   NFP_NET_CFG_CTRL_GATHER         (0x1 <<  9) /* Gather DMA */
 #define   NFP_NET_CFG_CTRL_LSO		  (0x1 << 10) /* LSO/TSO (version 1) */
+#define   NFP_NET_CFG_CTRL_CTAG_FILTER    (0x1 << 11) /* VLAN CTAG filtering */
 #define   NFP_NET_CFG_CTRL_RINGCFG        (0x1 << 16) /* Ring runtime changes */
 #define   NFP_NET_CFG_CTRL_RSS		  (0x1 << 17) /* RSS (version 1) */
 #define   NFP_NET_CFG_CTRL_IRQMOD         (0x1 << 18) /* Interrupt moderation */
 #define   NFP_NET_CFG_CTRL_RINGPRIO       (0x1 << 19) /* Ring priorities */
@@ -134,8 +135,9 @@
 #define   NFP_NET_CFG_UPDATE_IRQMOD       (0x1 <<  8) /* IRQ mod change */
 #define   NFP_NET_CFG_UPDATE_VXLAN        (0x1 <<  9) /* VXLAN port change */
 #define   NFP_NET_CFG_UPDATE_BPF	  (0x1 << 10) /* BPF program load */
 #define   NFP_NET_CFG_UPDATE_MACADDR	  (0x1 << 11) /* MAC address change */
+#define   NFP_NET_CFG_UPDATE_MBOX         (0x1 << 12) /* Mailbox update */
 #define   NFP_NET_CFG_UPDATE_ERR          (0x1 << 31) /* A error occurred */
 #define NFP_NET_CFG_TXRS_ENABLE         0x0008
 #define NFP_NET_CFG_RXRS_ENABLE         0x0010
 #define NFP_NET_CFG_MTU                 0x0018
@@ -391,8 +393,33 @@
 #define NFP_NET_CFG_RXR_STATS_BASE      0x1400
 #define NFP_NET_CFG_RXR_STATS(_x)       (NFP_NET_CFG_RXR_STATS_BASE + \
 					 ((_x) * 0x10))
 
+/**
+ * General use mailbox area (0x1800 - 0x19ff)
+ * 4B used for update command and 4B return code
+ * followed by a max of 504B of variable length value
+ */
+#define NFP_NET_CFG_MBOX_CMD           0x1800
+#define NFP_NET_CFG_MBOX_RET           0x1804
+#define NFP_NET_CFG_MBOX_VAL           0x1808
+#define NFP_NET_CFG_MBOX_VAL_MAX_SZ    0x1F8
+
+#define NFP_NET_CFG_MBOX_CMD_CTAG_FILTER_ADD 1
+#define NFP_NET_CFG_MBOX_CMD_CTAG_FILTER_KILL 2
+
+/**
+ * VLAN filtering using general use mailbox
+ * @NFP_NET_CFG_VLAN_FILTER:           Base address of VLAN filter mailbox
+ * @NFP_NET_CFG_VLAN_FILTER_VID:       VLAN ID to filter
+ * @NFP_NET_CFG_VLAN_FILTER_PROTO:     VLAN proto to filter
+ * @NFP_NET_CFG_VXLAN_SZ:              Size of the VLAN filter mailbox in bytes
+ */
+#define NFP_NET_CFG_VLAN_FILTER                NFP_NET_CFG_MBOX_VAL
+#define  NFP_NET_CFG_VLAN_FILTER_VID   NFP_NET_CFG_VLAN_FILTER
+#define  NFP_NET_CFG_VLAN_FILTER_PROTO  (NFP_NET_CFG_VLAN_FILTER + 2)
+#define NFP_NET_CFG_VLAN_FILTER_SZ      0x0004
+
 #endif /* _NFP_NET_CTRL_H_ */
 /*
  * Local variables:
  * c-file-style: "Linux"
diff --git a/me/blocks/vnic/nfd_common.h b/me/blocks/vnic/nfd_common.h
--- a/me/blocks/vnic/nfd_common.h
+++ b/me/blocks/vnic/nfd_common.h
@@ -55,11 +55,11 @@
     #define NFD_CFG_MAJOR_VF_MAX        4
 #endif
 #define NFD_CFG_MAJOR_VF_MIN        3
 
-#define NFD_CFG_MINOR_PF            4
-#define NFD_CFG_MINOR_CTRL          4
-#define NFD_CFG_MINOR_VF_MAX        4
+#define NFD_CFG_MINOR_PF            5
+#define NFD_CFG_MINOR_CTRL          5
+#define NFD_CFG_MINOR_VF_MAX        5
 #define NFD_CFG_MINOR_VF_MIN        0
 
 #define NFD_CFG_CLASS_DEFAULT       0
 
